{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "23728a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import pickle\n",
    "from gensim.models import Word2Vec\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a4cbc00e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading the list of muslim related terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c392bca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "muslim_terms = pickle.load(open(\"muslim_terms.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "04a670e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#indentfying tweets about Muslims by going through every state, every day in the state, and saving the id of \n",
    "#every tweet that contains any word from our list of muslims terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b7249329",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cleaned Andhra_Pradesh completed\n",
      "time taken: 4.37 mins\n",
      "time taken: 4.37 mins\n"
     ]
    }
   ],
   "source": [
    "t = time()\n",
    "state_list = os.listdir(\"Cleaned Data\")\n",
    "for state in state_list:\n",
    "    t_1 = time()\n",
    "    _path = os.path.join(\"Cleaned Data\", state)\n",
    "    file_list = [file for file in os.listdir(_path) if \".csv\" in file]\n",
    "    muslim_ids = []\n",
    "    for file in file_list:\n",
    "        df = pickle.load(open(os.path.join(_path, file), \"rb\"))\n",
    "        for i in range(df.shape[0]):\n",
    "            if any([term in df.at[i, \"cleaned_tweet\"] for term in muslim_terms]) or any([term in df.at[i, \"hashtag\"] for term in muslim_terms]):\n",
    "                muslim_ids.append(df.at[i, \"id\"])\n",
    "    pickle.dump(list(set(muslim_ids)), open(os.path.join(_path, \"{} muslim_ids.pkl\".format(state.split()[-1])), \"wb\"))\n",
    "    print(\"{} completed\".format(state))\n",
    "    print(\"time taken: {} mins\".format(round((time() - t_1)/60, 2)))\n",
    "print(\"time taken: {} mins\".format(round((time() - t)/60, 2))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e9b5272c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#going through each state in \"Cleaned Data\". through each file in each state, load the file as a dataframe\n",
    "#load the list of muslim ids of each state\n",
    "#tag each tweet with a \"1\" in the newly created \"muslim\" column if its tweet id is in the above loaded list\n",
    "#save the dataframe with the same path as the loaded file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c8a60f68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Andhra_Pradesh completed\n",
      "time taken: 0.58 mins\n",
      "time taken: 0.58 mins\n"
     ]
    }
   ],
   "source": [
    "state_list = os.listdir(\"Cleaned Data\")\n",
    "t = time()\n",
    "for state in state_list:\n",
    "    t_1 = time()\n",
    "    _path = os.path.join(\"Cleaned Data\", state)\n",
    "    muslim_ids = pickle.load(open(os.path.join(_path, \"{} muslim_ids.pkl\".format(state.split()[-1])), \"rb\"))\n",
    "    file_list = [_file for _file in os.listdir(_path) if \".csv\" in _file]\n",
    "    for _file in file_list:\n",
    "        df = pickle.load(open(os.path.join(_path, _file), \"rb\"))\n",
    "        df[\"muslim\"] = df[\"id\"].apply(lambda x : 1 if x in muslim_ids else 0)\n",
    "        pickle.dump(df, open(os.path.join(_path, _file), \"wb\"))\n",
    "    print(\"{} completed\".format(state.split()[-1]))\n",
    "    print(\"time taken: {} mins\".format(round((time() - t_1)/60, 2)))\n",
    "print(\"time taken: {} mins\".format(round((time() - t)/60, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b4de248b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a dataframe for every state in \"Cleaned Data\" which will contain the columns \"Date\", \"State\",\n",
    "#\"total tweets\", \"total negative tweets\", \"muslim tweets\", \"muslim negative tweets\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0d150421",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Andhra_Pradesh completed\n",
      "time taken: 0.01 mins\n",
      "time taken: 0.01 mins\n"
     ]
    }
   ],
   "source": [
    "t = time()\n",
    "state_list = os.listdir(\"Cleaned Data\")\n",
    "for state in state_list:\n",
    "    t_1 = time()\n",
    "    _path = os.path.join(\"Cleaned Data\", state)\n",
    "    file_list = [file for file in os.listdir(_path) if \".csv\" in file]\n",
    "    state_details = []\n",
    "    for file in file_list:\n",
    "        day_details = {}\n",
    "        day_details[\"date\"] = re.search(r'2020-[0-9]{2}-[0-9]{2}', file)[0]\n",
    "        df = pickle.load(open(os.path.join(_path, file), \"rb\"))\n",
    "        day_details[\"total tweets\"] = df.shape[0]\n",
    "        try:\n",
    "            day_details[\"total negative tweets\"] = df.groupby(\"polarity_new\").count()[\"id\"][0]\n",
    "        except:\n",
    "            day_details[\"total negative tweets\"] = 0\n",
    "        muslim_df = df[df[\"muslim\"] == 1]\n",
    "        day_details[\"muslim tweets\"] = muslim_df.shape[0]\n",
    "        try:\n",
    "            day_details[\"muslim negative tweets\"] = muslim_df.groupby(\"polarity_new\").count()[\"id\"][0]\n",
    "        except:\n",
    "            day_details[\"muslim negative tweets\"] = 0\n",
    "        day_details[\"state\"] = state.split()[-1]\n",
    "        state_details.append(day_details)\n",
    "    state_df = pd.DataFrame.from_dict(state_details)\n",
    "    pickle.dump(state_df, open(os.path.join(_path, \"{} tweet_details.pkl\".format(state.split()[-1])), \"wb\"))\n",
    "    print(\"{} completed\".format(state.split()[-1]))\n",
    "    print(\"time taken: {} mins\".format(round((time() - t_1)/60, 2)))\n",
    "print(\"time taken: {} mins\".format(round((time() - t)/60, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "ff0c718c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#going through all states in the folder \"Cleaned Data\" and loading the dataframe that we made in the previous step\n",
    "#putting all the dataframes in one dataframe which will contain 130 days worth of data for each state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1c2e7d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_list = os.listdir(\"Cleaned Data\")\n",
    "df_list = []\n",
    "for state in state_list:\n",
    "    _path = os.path.join(\"Cleaned Data\", state)\n",
    "    df = pickle.load(open(os.path.join(_path, \"{} tweet_details.pkl\".format(state.split()[-1])), \"rb\"))\n",
    "    df_list.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0b382999",
   "metadata": {},
   "outputs": [],
   "source": [
    "national_tweets_df = pd.concat(df_list, ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "93f5636a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating column containing the day the tweet was made"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7251f2bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "national_tweets_df[\"datetime\"] = pd.to_datetime(national_tweets_df[\"date\"], format = \"%Y/%m/%d\")\n",
    "national_tweets_df[\"day\"] = national_tweets_df[\"datetime\"].apply(lambda x : x.day_name())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "772fff35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>total tweets</th>\n",
       "      <th>total negative tweets</th>\n",
       "      <th>muslim tweets</th>\n",
       "      <th>muslim negative tweets</th>\n",
       "      <th>state</th>\n",
       "      <th>datetime</th>\n",
       "      <th>day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-01-22</td>\n",
       "      <td>802</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>Andhra_Pradesh</td>\n",
       "      <td>2020-01-22</td>\n",
       "      <td>Wednesday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-01-23</td>\n",
       "      <td>880</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>Andhra_Pradesh</td>\n",
       "      <td>2020-01-23</td>\n",
       "      <td>Thursday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-01-24</td>\n",
       "      <td>874</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>Andhra_Pradesh</td>\n",
       "      <td>2020-01-24</td>\n",
       "      <td>Friday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-01-25</td>\n",
       "      <td>812</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>Andhra_Pradesh</td>\n",
       "      <td>2020-01-25</td>\n",
       "      <td>Saturday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-01-26</td>\n",
       "      <td>936</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>Andhra_Pradesh</td>\n",
       "      <td>2020-01-26</td>\n",
       "      <td>Sunday</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date  total tweets  total negative tweets  muslim tweets  \\\n",
       "0  2020-01-22           802                      1              5   \n",
       "1  2020-01-23           880                      1             16   \n",
       "2  2020-01-24           874                      0              7   \n",
       "3  2020-01-25           812                      1              7   \n",
       "4  2020-01-26           936                      1             16   \n",
       "\n",
       "   muslim negative tweets           state   datetime        day  \n",
       "0                       1  Andhra_Pradesh 2020-01-22  Wednesday  \n",
       "1                       1  Andhra_Pradesh 2020-01-23   Thursday  \n",
       "2                       0  Andhra_Pradesh 2020-01-24     Friday  \n",
       "3                       1  Andhra_Pradesh 2020-01-25   Saturday  \n",
       "4                       1  Andhra_Pradesh 2020-01-26     Sunday  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "national_tweets_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "e611fee3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(130, 8)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "national_tweets_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "5ac71340",
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving the national_tweets_df dataframe on disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "b9b60237",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(national_tweets_df, open(\"national tweet_details.pkl\", \"wb\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:thesis]",
   "language": "python",
   "name": "conda-env-thesis-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
