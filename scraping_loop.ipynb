{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from os import mkdir, path\n",
    "from datetime import timedelta\n",
    "import time\n",
    "import twint\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"C:\\\\Users\\\\rahul\\\\Complete thesis data\\\\Models\\\\august_covid_terms.pkl\", \"rb\") as f:\n",
    "    covid_terms = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "169"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(covid_terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['lockdwn',\n",
       " 'hantavirus',\n",
       " 'virus',\n",
       " 'quarintine',\n",
       " 'sars',\n",
       " 'pandemic',\n",
       " 'conora',\n",
       " 'lockdowm',\n",
       " 'luckdown',\n",
       " 'pandemics',\n",
       " 'pendamic',\n",
       " 'quarentine',\n",
       " 'lackdown',\n",
       " 'virous',\n",
       " 'outbreak',\n",
       " 'corana',\n",
       " 'cronavirus',\n",
       " 'infections',\n",
       " 'locdown',\n",
       " 'quarrantine',\n",
       " 'outbreaks',\n",
       " 'corontine',\n",
       " 'stay safe',\n",
       " 'masks',\n",
       " 'ncov',\n",
       " 'epidemics',\n",
       " 'viruses',\n",
       " 'quaratine',\n",
       " 'korona',\n",
       " 'cerfew',\n",
       " 'covit',\n",
       " 'chorona',\n",
       " 'cornona',\n",
       " 'shutdown',\n",
       " 'ppe',\n",
       " 'mask',\n",
       " 'gloves',\n",
       " 'lockedown',\n",
       " 'distancing',\n",
       " 'stay home',\n",
       " 'flue',\n",
       " 'coronavirous',\n",
       " 'covod',\n",
       " 'lokdown',\n",
       " 'distencing',\n",
       " 'lockout',\n",
       " 'desease',\n",
       " 'vaccines',\n",
       " 'fevers',\n",
       " 'kovid',\n",
       " 'viras',\n",
       " 'corna',\n",
       " 'coronovirus',\n",
       " 'carina',\n",
       " 'karona',\n",
       " 'epidemic',\n",
       " 'vaccination',\n",
       " 'corentine',\n",
       " 'mahamari',\n",
       " 'quartine',\n",
       " 'vires',\n",
       " 'facemasks',\n",
       " 'logdown',\n",
       " 'cornavirus',\n",
       " 'corrona',\n",
       " 'corona',\n",
       " 'coved',\n",
       " 'coronaviruses',\n",
       " 'panademic',\n",
       " 'quarantine',\n",
       " 'coronavirus',\n",
       " 'caronavirus',\n",
       " 'clampdown',\n",
       " 'qurantine',\n",
       " 'lockdowns',\n",
       " 'quarantined',\n",
       " 'covind',\n",
       " 'convid',\n",
       " 'pendemic',\n",
       " 'distanceing',\n",
       " 'cvirus',\n",
       " 'coruna',\n",
       " 'ncovid',\n",
       " 'covid',\n",
       " 'facemask',\n",
       " 'qurentine',\n",
       " 'corantine',\n",
       " 'vaccine',\n",
       " 'covi',\n",
       " 'coronvirus',\n",
       " 'cororna',\n",
       " 'staysafe',\n",
       " 'covd',\n",
       " 'carona',\n",
       " 'covoid',\n",
       " 'sanitizer',\n",
       " 'novel',\n",
       " 'korana',\n",
       " 'decease',\n",
       " 'cornovirus',\n",
       " 'corena',\n",
       " 'krona',\n",
       " 'lockdow',\n",
       " 'epedemic',\n",
       " 'handgloves',\n",
       " 'flu',\n",
       " 'cobid',\n",
       " 'pandamic',\n",
       " 'catastrophe',\n",
       " 'infection',\n",
       " 'lockdown',\n",
       " 'quarntine',\n",
       " 'coron',\n",
       " 'corono',\n",
       " 'viruse',\n",
       " 'socialdistancing',\n",
       " 'crona',\n",
       " 'distensing',\n",
       " 'corina',\n",
       " 'isolation',\n",
       " 'curfew',\n",
       " 'stayhome',\n",
       " 'jamats',\n",
       " 'tabliq',\n",
       " 'jamaat',\n",
       " 'tablig',\n",
       " 'jamath',\n",
       " 'jamaath',\n",
       " 'markaz',\n",
       " 'nizammudin',\n",
       " 'nijamuddin',\n",
       " 'tablegi',\n",
       " 'tableegi',\n",
       " 'jamatis',\n",
       " 'tabligh',\n",
       " 'jamad',\n",
       " 'nizzamudin',\n",
       " 'tabliki',\n",
       " 'tabliqi',\n",
       " 'tabhligi',\n",
       " 'nizamudin',\n",
       " 'tablighi',\n",
       " 'zamat',\n",
       " 'markaj',\n",
       " 'markas',\n",
       " 'tablique',\n",
       " 'jamaties',\n",
       " 'jamat',\n",
       " 'tabligi',\n",
       " 'nizamuddin',\n",
       " 'jahil',\n",
       " 'tabligis',\n",
       " 'tj',\n",
       " 'tablighis',\n",
       " 'tabhlighi',\n",
       " 'tablighijamaat',\n",
       " 'nizammuddin',\n",
       " 'jamaati',\n",
       " 'jahils',\n",
       " 'tableeghi',\n",
       " 'jamaatis',\n",
       " 'zamaat',\n",
       " 'jaamat',\n",
       " 'tabliqui',\n",
       " 'tableegh',\n",
       " 'jamati',\n",
       " 'zamati',\n",
       " 'jammat',\n",
       " 'nizzamuddin']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "covid_terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "terms_to_remove = [\"sars\", \"virous\", \"masks\", \"ncov\", \"epidemics\", \"cerfew\", \"covit\", \"ppe\", \"mask\", \"gloves\", \"flue\", \\\n",
    "                   \"covod\", \"lockout\", \"fevers\", \"viras\", \"carina\", \"clampdown\", \"covi\", \"novel\", \"flu\", \"catastrophe\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "for term in terms_to_remove:\n",
    "    try:\n",
    "        covid_terms.remove(term)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = \"OR b \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "a += \"OR c\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'OR b OR c'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_string = \"lockdwn \"\n",
    "for term in covid_terms[1:]:\n",
    "    search_string += \"OR {} \".format(term)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_string += \"OR biojihad \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_string += \"OR biologicaljihad\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'lockdwn OR hantavirus OR virus OR quarintine OR sars OR pandemic OR conora OR lockdowm OR luckdown OR pandemics OR pendamic OR quarentine OR lackdown OR virous OR outbreak OR corana OR cronavirus OR infections OR locdown OR quarrantine OR outbreaks OR corontine OR stay safe OR masks OR ncov OR epidemics OR viruses OR quaratine OR korona OR cerfew OR covit OR chorona OR cornona OR shutdown OR ppe OR mask OR gloves OR lockedown OR distancing OR stay home OR flue OR coronavirous OR covod OR lokdown OR distencing OR lockout OR desease OR vaccines OR fevers OR kovid OR viras OR corna OR coronovirus OR carina OR karona OR epidemic OR vaccination OR corentine OR mahamari OR quartine OR vires OR facemasks OR logdown OR cornavirus OR corrona OR corona OR coved OR coronaviruses OR panademic OR quarantine OR coronavirus OR caronavirus OR clampdown OR qurantine OR lockdowns OR quarantined OR covind OR convid OR pendemic OR distanceing OR cvirus OR coruna OR ncovid OR covid OR facemask OR qurentine OR corantine OR vaccine OR covi OR coronvirus OR cororna OR staysafe OR covd OR carona OR covoid OR sanitizer OR novel OR korana OR decease OR cornovirus OR corena OR krona OR lockdow OR epedemic OR handgloves OR flu OR cobid OR pandamic OR catastrophe OR infection OR lockdown OR quarntine OR coron OR corono OR viruse OR socialdistancing OR crona OR distensing OR corina OR isolation OR curfew OR stayhome OR jamats OR tabliq OR jamaat OR tablig OR jamath OR jamaath OR markaz OR nizammudin OR nijamuddin OR tablegi OR tableegi OR jamatis OR tabligh OR jamad OR nizzamudin OR tabliki OR tabliqi OR tabhligi OR nizamudin OR tablighi OR zamat OR markaj OR markas OR tablique OR jamaties OR jamat OR tabligi OR nizamuddin OR jahil OR tabligis OR tj OR tablighis OR tabhlighi OR tablighijamaat OR nizammuddin OR jamaati OR jahils OR tableeghi OR jamaatis OR zamaat OR jaamat OR tabliqui OR tableegh OR jamati OR zamati OR jammat OR nizzamuddin OR biojihad OR biologicaljihad'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def twint_search(since, until, csv_name, coordinate, search_string):\n",
    "    c = twint.Config()\n",
    "    c.Search = search_string\n",
    "    c.Utc = True\n",
    "    c.Full_text = True\n",
    "    c.Since = since\n",
    "    c.Until = until\n",
    "    c.Geo = coordinate\n",
    "    c.Count = True\n",
    "    c.Lang = \"en\"\n",
    "    c.Hide_output = True\n",
    "    c.Store_csv = True\n",
    "    c.Output = csv_name\n",
    "    c.Debug = True\n",
    "    \n",
    "    try:\n",
    "        twint.run.Search(c)\n",
    "    except(KeyboardInterrupt, SystemExit):\n",
    "        raise\n",
    "    except:\n",
    "        print(\"Problem with %s\"%since)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_scraper(since, until, state_name, coordinates, search_strings):\n",
    "    \n",
    "    dirname = \"new_%s\"%state_name\n",
    "    try:\n",
    "        mkdir(dirname)\n",
    "        print(\"Directory\", dirname, \"created\")\n",
    "    except FileExistsError:\n",
    "        print(\"Directory\", dirname, \"exists\")\n",
    "    \n",
    "    daterange = pd.date_range(since, until)\n",
    "    for start_date in daterange:\n",
    "        since = start_date.strftime(\"%Y-%m-%d\")\n",
    "        until = (start_date + timedelta(1)).strftime(\"%Y-%m-%d\")\n",
    "        \n",
    "        \n",
    "        print(\"Getting data for %s\"%since)\n",
    "        csv_name = \"%s.csv\"%since\n",
    "        csv_name = path.join(dirname, csv_name)\n",
    "        \n",
    "        for coordinate in coordinates:\n",
    "            for search_string in search_strings:\n",
    "                \n",
    "                twint_search(since, until, csv_name, coordinate, search_string)\n",
    "            \n",
    "        time.sleep(1)            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_coordinates = [\"28.519553,77.250906,40km\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_strings = [\"lockdwn OR hantavirus OR virus OR quarintine OR sars OR pandemic OR conora OR lockdowm OR luckdown OR pandemics\", \\\n",
    "                  \"pendamic OR quarentine OR lackdown OR virous OR outbreak OR corana\", \\\n",
    "                  \"cronavirus OR infections OR locdown OR quarrantine OR outbreaks OR corontine OR stay safe OR masks OR ncov\", \\\n",
    "                  \"epidemics OR viruses OR quaratine OR korona OR cerfew OR covit OR chorona OR cornona OR shutdown\", \\\n",
    "                  \"ppe OR mask OR gloves OR lockedown OR distancing OR stay home OR flue OR coronavirous OR covod OR lokdown OR distencing\", \\\n",
    "                  \"lockout OR desease OR vaccines OR fevers OR kovid OR viras OR corna OR coronovirus OR carina OR karona OR epidemic\", \\\n",
    "                  \"vaccination OR corentine OR mahamari OR quartine OR vires OR facemasks OR logdown OR cornavirus OR corrona OR corona\",\\\n",
    "                  \"coved OR coronaviruses OR panademic OR quarantine OR coronavirus OR caronavirus OR clampdown OR qurantine OR lockdowns\", \\\n",
    "                  \"quarantined OR covind OR convid OR pendemic OR distanceing OR cvirus OR coruna OR ncovid OR covid OR facemask\", \\\n",
    "                  \"novel OR korana OR decease OR cornovirus OR corena OR krona OR lockdow OR epedemic OR handgloves OR flu OR cobid OR pandamic\", \\\n",
    "                  \"catastrophe OR infection OR lockdown OR quarntine OR coron OR corono OR viruse OR socialdistancing OR crona OR distensing\", \\\n",
    "                  \"corina OR isolation OR curfew OR stayhome OR jamats OR tabliq OR jamaat OR tablig OR jamath OR jamaath OR markaz OR nizammudin\", \\\n",
    "                  \"nijamuddin OR tablegi OR tableegi OR jamatis OR tabligh OR jamad OR nizzamudin OR tabliki OR tabliqi OR tabhligi\", \\\n",
    "                  \"nizamudin OR tablighi OR zamat OR markaj OR markas OR tablique OR jamaties OR jamat OR tabligi OR nizamuddin OR jahil\", \\\n",
    "                  \"tabligis OR tj OR tablighis OR tabhlighi OR tablighijamaat OR nizammuddin OR jamaati OR jahils OR tableeghi\", \\\n",
    "                  \"jamaatis OR zamaat OR jaamat OR tabliqui OR tableegh OR jamati OR zamati OR jammat OR nizzamuddin OR biojihad OR biologicaljihad\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1659455385.8075886"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory new_Delhi created\n",
      "Getting data for 2020-01-22\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 7 Tweets.\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 3 Tweets.\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets.\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 1 Tweets.\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets.\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 1 Tweets.\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 1 Tweets.\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 8 Tweets.\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets.\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 5 Tweets.\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets.\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets.\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets.\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 2 Tweets.\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets.\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets.\n",
      "Getting data for 2020-01-23\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 6 Tweets.\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 7 Tweets.\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 2 Tweets.\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 2 Tweets.\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 1 Tweets.\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 4 Tweets.\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 4 Tweets.\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 12 Tweets.\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 1 Tweets.\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 4 Tweets.\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 3 Tweets.\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 2 Tweets.\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets.\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 7 Tweets.\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets.\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets.\n",
      "Getting data for 2020-01-24\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 13 Tweets.\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 5 Tweets.\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 2 Tweets.\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 4 Tweets.\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 1 Tweets.\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 11 Tweets.\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 4 Tweets.\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 7 Tweets.\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets.\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 6 Tweets.\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 1 Tweets.\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 2 Tweets.\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets.\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 2 Tweets.\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets.\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets.\n",
      "Getting data for 2020-01-25\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 11 Tweets.\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 3 Tweets.\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 4 Tweets.\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 2 Tweets.\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets.\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 4 Tweets.\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 4 Tweets.\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 7 Tweets.\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets.\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 2 Tweets.\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 3 Tweets.\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 4 Tweets.\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets.\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 1 Tweets.\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 1 Tweets.\n",
      "Getting data for 2020-01-26\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 6 Tweets.\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 2 Tweets.\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 2 Tweets.\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 1 Tweets.\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets.\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 2 Tweets.\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 2 Tweets.\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 9 Tweets.\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets.\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 4 Tweets.\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 1 Tweets.\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 2 Tweets.\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets.\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 10 Tweets.\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets.\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets.\n",
      "Getting data for 2020-01-27\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 11 Tweets.\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 7 Tweets.\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 1 Tweets.\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 3 Tweets.\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets.\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 2 Tweets.\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 5 Tweets.\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 15 Tweets.\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 2 Tweets.\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 3 Tweets.\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 3 Tweets.\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 1 Tweets.\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets.\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 10 Tweets.\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets.\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets.\n",
      "Getting data for 2020-01-28\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 18 Tweets.\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 4 Tweets.\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 2 Tweets.\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 2 Tweets.\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 1 Tweets.\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 1 Tweets.\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 8 Tweets.\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 41 Tweets.\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 1 Tweets.\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 5 Tweets.\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets.\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 2 Tweets.\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets.\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 1 Tweets.\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets.\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets.\n",
      "Getting data for 2020-01-29\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 35 Tweets.\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 5 Tweets.\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 1 Tweets.\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 4 Tweets.\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets.\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 7 Tweets.\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 18 Tweets.\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 44 Tweets.\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 1 Tweets.\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 10 Tweets.\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 3 Tweets.\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 2 Tweets.\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets.\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 10 Tweets.\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets.\n",
      "Getting data for 2020-01-30\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 58 Tweets.\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 9 Tweets.\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 2 Tweets.\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 2 Tweets.\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets.\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 1 Tweets.\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 31 Tweets.\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 55 Tweets.\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets.\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 11 Tweets.\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 2 Tweets.\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 5 Tweets.\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets.\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 10 Tweets.\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 1 Tweets.\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets.\n",
      "Getting data for 2020-01-31\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 29 Tweets.\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 12 Tweets.\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 8 Tweets.\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets.\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 1 Tweets.\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 5 Tweets.\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 14 Tweets.\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 62 Tweets.\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 6 Tweets.\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 6 Tweets.\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 3 Tweets.\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 2 Tweets.\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets.\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 4 Tweets.\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets.\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets.\n",
      "Getting data for 2020-02-01\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 26 Tweets.\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 7 Tweets.\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets.\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets.\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 3 Tweets.\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 4 Tweets.\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 16 Tweets.\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 40 Tweets.\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 1 Tweets.\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 1 Tweets.\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 1 Tweets.\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 6 Tweets.\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets.\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 6 Tweets.\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 1 Tweets.\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets.\n",
      "Getting data for 2020-02-02\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 160 Tweets.\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 7 Tweets.\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 2 Tweets.\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 20 Tweets.\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 2 Tweets.\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 3 Tweets.\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 158 Tweets.\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 66 Tweets.\n",
      "Problem with 2020-02-02\n",
      "Problem with 2020-02-02\n",
      "Problem with 2020-02-02\n",
      "Problem with 2020-02-02\n",
      "Problem with 2020-02-02\n",
      "Problem with 2020-02-02\n",
      "Problem with 2020-02-02\n",
      "Problem with 2020-02-02\n",
      "Getting data for 2020-02-03\n",
      "Problem with 2020-02-03\n",
      "Problem with 2020-02-03\n",
      "Problem with 2020-02-03\n",
      "Problem with 2020-02-03\n",
      "Problem with 2020-02-03\n",
      "Problem with 2020-02-03\n",
      "Problem with 2020-02-03\n",
      "Problem with 2020-02-03\n",
      "Problem with 2020-02-03\n",
      "Problem with 2020-02-03\n",
      "Problem with 2020-02-03\n",
      "Problem with 2020-02-03\n",
      "Problem with 2020-02-03\n",
      "Problem with 2020-02-03\n",
      "Problem with 2020-02-03\n",
      "Problem with 2020-02-03\n",
      "Getting data for 2020-02-04\n",
      "Problem with 2020-02-04\n",
      "Problem with 2020-02-04\n",
      "Problem with 2020-02-04\n",
      "Problem with 2020-02-04\n",
      "Problem with 2020-02-04\n",
      "Problem with 2020-02-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem with 2020-02-04\n",
      "Problem with 2020-02-04\n",
      "Problem with 2020-02-04\n",
      "Problem with 2020-02-04\n",
      "Problem with 2020-02-04\n",
      "Problem with 2020-02-04\n",
      "Problem with 2020-02-04\n",
      "Problem with 2020-02-04\n",
      "Problem with 2020-02-04\n",
      "Problem with 2020-02-04\n",
      "Getting data for 2020-02-05\n",
      "Problem with 2020-02-05\n",
      "Problem with 2020-02-05\n",
      "Problem with 2020-02-05\n",
      "Problem with 2020-02-05\n",
      "Problem with 2020-02-05\n",
      "Problem with 2020-02-05\n",
      "Problem with 2020-02-05\n",
      "Problem with 2020-02-05\n",
      "Problem with 2020-02-05\n",
      "Problem with 2020-02-05\n",
      "Problem with 2020-02-05\n",
      "Problem with 2020-02-05\n",
      "Problem with 2020-02-05\n",
      "Problem with 2020-02-05\n",
      "Problem with 2020-02-05\n",
      "Problem with 2020-02-05\n",
      "Getting data for 2020-02-06\n",
      "Problem with 2020-02-06\n",
      "Problem with 2020-02-06\n",
      "Problem with 2020-02-06\n",
      "Problem with 2020-02-06\n",
      "Problem with 2020-02-06\n",
      "Problem with 2020-02-06\n",
      "Problem with 2020-02-06\n",
      "Problem with 2020-02-06\n",
      "Problem with 2020-02-06\n",
      "Problem with 2020-02-06\n",
      "Problem with 2020-02-06\n",
      "Problem with 2020-02-06\n",
      "Problem with 2020-02-06\n",
      "Problem with 2020-02-06\n",
      "Problem with 2020-02-06\n",
      "Problem with 2020-02-06\n",
      "Getting data for 2020-02-07\n",
      "Problem with 2020-02-07\n",
      "Problem with 2020-02-07\n",
      "Problem with 2020-02-07\n",
      "Problem with 2020-02-07\n",
      "Problem with 2020-02-07\n",
      "Problem with 2020-02-07\n",
      "Problem with 2020-02-07\n",
      "Problem with 2020-02-07\n",
      "Problem with 2020-02-07\n",
      "Problem with 2020-02-07\n",
      "Problem with 2020-02-07\n",
      "Problem with 2020-02-07\n",
      "Problem with 2020-02-07\n",
      "Problem with 2020-02-07\n",
      "Problem with 2020-02-07\n",
      "Problem with 2020-02-07\n",
      "Getting data for 2020-02-08\n",
      "Problem with 2020-02-08\n",
      "Problem with 2020-02-08\n",
      "Problem with 2020-02-08\n",
      "Problem with 2020-02-08\n",
      "Problem with 2020-02-08\n",
      "Problem with 2020-02-08\n",
      "Problem with 2020-02-08\n",
      "Problem with 2020-02-08\n",
      "Problem with 2020-02-08\n",
      "Problem with 2020-02-08\n",
      "Problem with 2020-02-08\n",
      "Problem with 2020-02-08\n",
      "Problem with 2020-02-08\n",
      "Problem with 2020-02-08\n",
      "Problem with 2020-02-08\n",
      "Problem with 2020-02-08\n",
      "Getting data for 2020-02-09\n",
      "Problem with 2020-02-09\n",
      "Problem with 2020-02-09\n",
      "Problem with 2020-02-09\n",
      "Problem with 2020-02-09\n",
      "Problem with 2020-02-09\n",
      "Problem with 2020-02-09\n",
      "Problem with 2020-02-09\n",
      "Problem with 2020-02-09\n",
      "Problem with 2020-02-09\n",
      "Problem with 2020-02-09\n",
      "Problem with 2020-02-09\n",
      "Problem with 2020-02-09\n",
      "Problem with 2020-02-09\n",
      "Problem with 2020-02-09\n",
      "Problem with 2020-02-09\n",
      "Problem with 2020-02-09\n",
      "Getting data for 2020-02-10\n",
      "Problem with 2020-02-10\n",
      "Problem with 2020-02-10\n",
      "Problem with 2020-02-10\n",
      "Problem with 2020-02-10\n",
      "Problem with 2020-02-10\n",
      "Problem with 2020-02-10\n",
      "Problem with 2020-02-10\n",
      "Problem with 2020-02-10\n",
      "Problem with 2020-02-10\n",
      "Problem with 2020-02-10\n",
      "Problem with 2020-02-10\n",
      "Problem with 2020-02-10\n",
      "Problem with 2020-02-10\n",
      "Problem with 2020-02-10\n",
      "Problem with 2020-02-10\n",
      "Problem with 2020-02-10\n",
      "Getting data for 2020-02-11\n",
      "Problem with 2020-02-11\n",
      "Problem with 2020-02-11\n",
      "Problem with 2020-02-11\n",
      "Problem with 2020-02-11\n",
      "Problem with 2020-02-11\n",
      "Problem with 2020-02-11\n",
      "Problem with 2020-02-11\n",
      "Problem with 2020-02-11\n",
      "Problem with 2020-02-11\n",
      "Problem with 2020-02-11\n",
      "Problem with 2020-02-11\n",
      "Problem with 2020-02-11\n",
      "Problem with 2020-02-11\n",
      "Problem with 2020-02-11\n",
      "Problem with 2020-02-11\n",
      "Problem with 2020-02-11\n",
      "Getting data for 2020-02-12\n",
      "Problem with 2020-02-12\n",
      "Problem with 2020-02-12\n",
      "Problem with 2020-02-12\n",
      "Problem with 2020-02-12\n",
      "Problem with 2020-02-12\n",
      "Problem with 2020-02-12\n",
      "Problem with 2020-02-12\n",
      "Problem with 2020-02-12\n",
      "Problem with 2020-02-12\n",
      "Problem with 2020-02-12\n",
      "Problem with 2020-02-12\n",
      "Problem with 2020-02-12\n",
      "Problem with 2020-02-12\n",
      "Problem with 2020-02-12\n",
      "Problem with 2020-02-12\n",
      "Problem with 2020-02-12\n",
      "Getting data for 2020-02-13\n",
      "Problem with 2020-02-13\n",
      "Problem with 2020-02-13\n",
      "Problem with 2020-02-13\n",
      "Problem with 2020-02-13\n",
      "Problem with 2020-02-13\n",
      "Problem with 2020-02-13\n",
      "Problem with 2020-02-13\n",
      "Problem with 2020-02-13\n",
      "Problem with 2020-02-13\n",
      "Problem with 2020-02-13\n",
      "Problem with 2020-02-13\n",
      "Problem with 2020-02-13\n",
      "Problem with 2020-02-13\n",
      "Problem with 2020-02-13\n",
      "Problem with 2020-02-13\n",
      "Problem with 2020-02-13\n",
      "Getting data for 2020-02-14\n",
      "Problem with 2020-02-14\n",
      "Problem with 2020-02-14\n",
      "Problem with 2020-02-14\n",
      "Problem with 2020-02-14\n",
      "Problem with 2020-02-14\n",
      "Problem with 2020-02-14\n",
      "Problem with 2020-02-14\n",
      "Problem with 2020-02-14\n",
      "Problem with 2020-02-14\n",
      "Problem with 2020-02-14\n",
      "Problem with 2020-02-14\n",
      "Problem with 2020-02-14\n",
      "Problem with 2020-02-14\n",
      "Problem with 2020-02-14\n",
      "Problem with 2020-02-14\n",
      "Problem with 2020-02-14\n",
      "Getting data for 2020-02-15\n",
      "Problem with 2020-02-15\n",
      "Problem with 2020-02-15\n",
      "Problem with 2020-02-15\n",
      "Problem with 2020-02-15\n",
      "Problem with 2020-02-15\n",
      "Problem with 2020-02-15\n",
      "Problem with 2020-02-15\n",
      "Problem with 2020-02-15\n",
      "Problem with 2020-02-15\n",
      "Problem with 2020-02-15\n",
      "Problem with 2020-02-15\n",
      "Problem with 2020-02-15\n",
      "Problem with 2020-02-15\n",
      "Problem with 2020-02-15\n",
      "Problem with 2020-02-15\n",
      "Problem with 2020-02-15\n",
      "Getting data for 2020-02-16\n",
      "Problem with 2020-02-16\n",
      "Problem with 2020-02-16\n",
      "Problem with 2020-02-16\n",
      "Problem with 2020-02-16\n",
      "Problem with 2020-02-16\n",
      "Problem with 2020-02-16\n",
      "Problem with 2020-02-16\n",
      "Problem with 2020-02-16\n",
      "Problem with 2020-02-16\n",
      "Problem with 2020-02-16\n",
      "Problem with 2020-02-16\n",
      "Problem with 2020-02-16\n",
      "Problem with 2020-02-16\n",
      "Problem with 2020-02-16\n",
      "Problem with 2020-02-16\n",
      "Problem with 2020-02-16\n",
      "Getting data for 2020-02-17\n",
      "Problem with 2020-02-17\n",
      "Problem with 2020-02-17\n",
      "Problem with 2020-02-17\n",
      "Problem with 2020-02-17\n",
      "Problem with 2020-02-17\n",
      "Problem with 2020-02-17\n",
      "Problem with 2020-02-17\n",
      "Problem with 2020-02-17\n",
      "Problem with 2020-02-17\n",
      "Problem with 2020-02-17\n",
      "Problem with 2020-02-17\n",
      "Problem with 2020-02-17\n",
      "Problem with 2020-02-17\n",
      "Problem with 2020-02-17\n",
      "Problem with 2020-02-17\n",
      "Problem with 2020-02-17\n",
      "Getting data for 2020-02-18\n",
      "Problem with 2020-02-18\n",
      "Problem with 2020-02-18\n",
      "Problem with 2020-02-18\n",
      "Problem with 2020-02-18\n",
      "Problem with 2020-02-18\n",
      "Problem with 2020-02-18\n",
      "Problem with 2020-02-18\n",
      "Problem with 2020-02-18\n",
      "Problem with 2020-02-18\n",
      "Problem with 2020-02-18\n",
      "Problem with 2020-02-18\n",
      "Problem with 2020-02-18\n",
      "Problem with 2020-02-18\n",
      "Problem with 2020-02-18\n",
      "Problem with 2020-02-18\n",
      "Problem with 2020-02-18\n",
      "Getting data for 2020-02-19\n",
      "Problem with 2020-02-19\n",
      "Problem with 2020-02-19\n",
      "Problem with 2020-02-19\n",
      "Problem with 2020-02-19\n",
      "Problem with 2020-02-19\n",
      "Problem with 2020-02-19\n",
      "Problem with 2020-02-19\n",
      "Problem with 2020-02-19\n",
      "Problem with 2020-02-19\n",
      "Problem with 2020-02-19\n",
      "Problem with 2020-02-19\n",
      "Problem with 2020-02-19\n",
      "Problem with 2020-02-19\n",
      "Problem with 2020-02-19\n",
      "Problem with 2020-02-19\n",
      "Problem with 2020-02-19\n",
      "Getting data for 2020-02-20\n",
      "Problem with 2020-02-20\n",
      "Problem with 2020-02-20\n",
      "Problem with 2020-02-20\n",
      "Problem with 2020-02-20\n",
      "Problem with 2020-02-20\n",
      "Problem with 2020-02-20\n",
      "Problem with 2020-02-20\n",
      "Problem with 2020-02-20\n",
      "Problem with 2020-02-20\n",
      "Problem with 2020-02-20\n",
      "Problem with 2020-02-20\n",
      "Problem with 2020-02-20\n",
      "Problem with 2020-02-20\n",
      "Problem with 2020-02-20\n",
      "Problem with 2020-02-20\n",
      "Problem with 2020-02-20\n",
      "Getting data for 2020-02-21\n",
      "Problem with 2020-02-21\n",
      "Problem with 2020-02-21\n",
      "Problem with 2020-02-21\n",
      "Problem with 2020-02-21\n",
      "Problem with 2020-02-21\n",
      "Problem with 2020-02-21\n",
      "Problem with 2020-02-21\n",
      "Problem with 2020-02-21\n",
      "Problem with 2020-02-21\n",
      "Problem with 2020-02-21\n",
      "Problem with 2020-02-21\n",
      "Problem with 2020-02-21\n",
      "Problem with 2020-02-21\n",
      "Problem with 2020-02-21\n",
      "Problem with 2020-02-21\n",
      "Problem with 2020-02-21\n",
      "Getting data for 2020-02-22\n",
      "Problem with 2020-02-22\n",
      "Problem with 2020-02-22\n",
      "Problem with 2020-02-22\n",
      "Problem with 2020-02-22\n",
      "Problem with 2020-02-22\n",
      "Problem with 2020-02-22\n",
      "Problem with 2020-02-22\n",
      "Problem with 2020-02-22\n",
      "Problem with 2020-02-22\n",
      "Problem with 2020-02-22\n",
      "Problem with 2020-02-22\n",
      "Problem with 2020-02-22\n",
      "Problem with 2020-02-22\n",
      "Problem with 2020-02-22\n",
      "Problem with 2020-02-22\n"
     ]
    }
   ],
   "source": [
    "t = time.time()\n",
    "my_scraper(\"2020-01-22\",\"2020-05-30\",\"Delhi\",list_of_coordinates, search_strings)\n",
    "print(\"time taken: {}\".format(round((time.time() - t)/60, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv(\"C:\\\\Users\\\\rahul\\\\new_Delhi\\\\2020-04-01.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_en = test.where(test[\"language\"] == \"en\").dropna(subset = [\"language\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_en.drop_duplicates(subset = [\"id\"], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1801, 36)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_en.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"C:\\\\Users\\\\rahul\\\\Complete thesis data\\\\august cleaned data\\\\august cleaned Delhi\\\\Delhi covid_daily_details.pkl\", \"rb\") as f:\n",
    "    test_2 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_rows\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mpd\u001b[49m\u001b[38;5;241m.\u001b[39mset_option(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdisplay.max_rows\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "pd.set_option(\"display.max_rows\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>total_tweets</th>\n",
       "      <th>total_likes</th>\n",
       "      <th>total_retweets</th>\n",
       "      <th>total_replies</th>\n",
       "      <th>all_likes_avg</th>\n",
       "      <th>all_retweets_avg</th>\n",
       "      <th>all_replies_avg</th>\n",
       "      <th>all_neg_total</th>\n",
       "      <th>all_neg_likes</th>\n",
       "      <th>...</th>\n",
       "      <th>m_likes_avg</th>\n",
       "      <th>m_retweets_avg</th>\n",
       "      <th>m_replies_avg</th>\n",
       "      <th>m_neg_total</th>\n",
       "      <th>m_neg_likes</th>\n",
       "      <th>m_neg_retweets</th>\n",
       "      <th>m_neg_replies</th>\n",
       "      <th>m_neg_likes_avg</th>\n",
       "      <th>m_neg_retweets_avg</th>\n",
       "      <th>m_neg_replies_avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-01-22</td>\n",
       "      <td>914</td>\n",
       "      <td>43574.0</td>\n",
       "      <td>11883.0</td>\n",
       "      <td>3542.0</td>\n",
       "      <td>47.673961</td>\n",
       "      <td>13.001094</td>\n",
       "      <td>3.875274</td>\n",
       "      <td>75</td>\n",
       "      <td>244.0</td>\n",
       "      <td>...</td>\n",
       "      <td>18.245902</td>\n",
       "      <td>2.475410</td>\n",
       "      <td>1.852459</td>\n",
       "      <td>21</td>\n",
       "      <td>89.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.238095</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>0.190476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-01-23</td>\n",
       "      <td>1136</td>\n",
       "      <td>24367.0</td>\n",
       "      <td>6457.0</td>\n",
       "      <td>3196.0</td>\n",
       "      <td>21.449824</td>\n",
       "      <td>5.683979</td>\n",
       "      <td>2.813380</td>\n",
       "      <td>98</td>\n",
       "      <td>7517.0</td>\n",
       "      <td>...</td>\n",
       "      <td>35.598039</td>\n",
       "      <td>15.764706</td>\n",
       "      <td>2.098039</td>\n",
       "      <td>36</td>\n",
       "      <td>2470.0</td>\n",
       "      <td>992.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>68.611111</td>\n",
       "      <td>27.555556</td>\n",
       "      <td>3.555556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-01-24</td>\n",
       "      <td>1277</td>\n",
       "      <td>53227.0</td>\n",
       "      <td>13410.0</td>\n",
       "      <td>3459.0</td>\n",
       "      <td>41.681284</td>\n",
       "      <td>10.501175</td>\n",
       "      <td>2.708692</td>\n",
       "      <td>110</td>\n",
       "      <td>1652.0</td>\n",
       "      <td>...</td>\n",
       "      <td>371.255556</td>\n",
       "      <td>113.133333</td>\n",
       "      <td>25.300000</td>\n",
       "      <td>27</td>\n",
       "      <td>637.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>23.592593</td>\n",
       "      <td>4.370370</td>\n",
       "      <td>4.370370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-01-25</td>\n",
       "      <td>1131</td>\n",
       "      <td>52163.0</td>\n",
       "      <td>18937.0</td>\n",
       "      <td>9663.0</td>\n",
       "      <td>46.121132</td>\n",
       "      <td>16.743590</td>\n",
       "      <td>8.543767</td>\n",
       "      <td>132</td>\n",
       "      <td>26847.0</td>\n",
       "      <td>...</td>\n",
       "      <td>104.676190</td>\n",
       "      <td>76.676190</td>\n",
       "      <td>5.523810</td>\n",
       "      <td>51</td>\n",
       "      <td>9319.0</td>\n",
       "      <td>7308.0</td>\n",
       "      <td>541.0</td>\n",
       "      <td>182.725490</td>\n",
       "      <td>143.294118</td>\n",
       "      <td>10.607843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-01-26</td>\n",
       "      <td>1388</td>\n",
       "      <td>56400.0</td>\n",
       "      <td>12730.0</td>\n",
       "      <td>4363.0</td>\n",
       "      <td>40.634006</td>\n",
       "      <td>9.171470</td>\n",
       "      <td>3.143372</td>\n",
       "      <td>132</td>\n",
       "      <td>10504.0</td>\n",
       "      <td>...</td>\n",
       "      <td>188.964912</td>\n",
       "      <td>54.570175</td>\n",
       "      <td>23.359649</td>\n",
       "      <td>40</td>\n",
       "      <td>10145.0</td>\n",
       "      <td>2788.0</td>\n",
       "      <td>970.0</td>\n",
       "      <td>253.625000</td>\n",
       "      <td>69.700000</td>\n",
       "      <td>24.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2020-01-27</td>\n",
       "      <td>1274</td>\n",
       "      <td>48079.0</td>\n",
       "      <td>16058.0</td>\n",
       "      <td>3398.0</td>\n",
       "      <td>37.738619</td>\n",
       "      <td>12.604396</td>\n",
       "      <td>2.667190</td>\n",
       "      <td>132</td>\n",
       "      <td>10691.0</td>\n",
       "      <td>...</td>\n",
       "      <td>67.500000</td>\n",
       "      <td>18.246032</td>\n",
       "      <td>3.174603</td>\n",
       "      <td>48</td>\n",
       "      <td>279.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>5.812500</td>\n",
       "      <td>1.187500</td>\n",
       "      <td>0.583333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2020-01-28</td>\n",
       "      <td>1415</td>\n",
       "      <td>22811.0</td>\n",
       "      <td>5037.0</td>\n",
       "      <td>2219.0</td>\n",
       "      <td>16.120848</td>\n",
       "      <td>3.559717</td>\n",
       "      <td>1.568198</td>\n",
       "      <td>171</td>\n",
       "      <td>831.0</td>\n",
       "      <td>...</td>\n",
       "      <td>47.376000</td>\n",
       "      <td>7.400000</td>\n",
       "      <td>6.632000</td>\n",
       "      <td>46</td>\n",
       "      <td>95.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>2.065217</td>\n",
       "      <td>0.630435</td>\n",
       "      <td>0.521739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2020-01-29</td>\n",
       "      <td>1494</td>\n",
       "      <td>33373.0</td>\n",
       "      <td>6807.0</td>\n",
       "      <td>2979.0</td>\n",
       "      <td>22.338019</td>\n",
       "      <td>4.556225</td>\n",
       "      <td>1.993976</td>\n",
       "      <td>165</td>\n",
       "      <td>580.0</td>\n",
       "      <td>...</td>\n",
       "      <td>50.145455</td>\n",
       "      <td>14.009091</td>\n",
       "      <td>5.372727</td>\n",
       "      <td>31</td>\n",
       "      <td>90.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>2.903226</td>\n",
       "      <td>2.161290</td>\n",
       "      <td>0.612903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2020-01-30</td>\n",
       "      <td>1512</td>\n",
       "      <td>89417.0</td>\n",
       "      <td>26531.0</td>\n",
       "      <td>8989.0</td>\n",
       "      <td>59.138228</td>\n",
       "      <td>17.546958</td>\n",
       "      <td>5.945106</td>\n",
       "      <td>167</td>\n",
       "      <td>10563.0</td>\n",
       "      <td>...</td>\n",
       "      <td>129.358621</td>\n",
       "      <td>36.972414</td>\n",
       "      <td>18.668966</td>\n",
       "      <td>51</td>\n",
       "      <td>1555.0</td>\n",
       "      <td>695.0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>30.490196</td>\n",
       "      <td>13.627451</td>\n",
       "      <td>2.411765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2020-01-31</td>\n",
       "      <td>1240</td>\n",
       "      <td>18040.0</td>\n",
       "      <td>6119.0</td>\n",
       "      <td>1369.0</td>\n",
       "      <td>14.548387</td>\n",
       "      <td>4.934677</td>\n",
       "      <td>1.104032</td>\n",
       "      <td>127</td>\n",
       "      <td>5598.0</td>\n",
       "      <td>...</td>\n",
       "      <td>12.877193</td>\n",
       "      <td>4.640351</td>\n",
       "      <td>0.938596</td>\n",
       "      <td>42</td>\n",
       "      <td>36.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.380952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2020-02-01</td>\n",
       "      <td>1416</td>\n",
       "      <td>20888.0</td>\n",
       "      <td>5171.0</td>\n",
       "      <td>1679.0</td>\n",
       "      <td>14.751412</td>\n",
       "      <td>3.651836</td>\n",
       "      <td>1.185734</td>\n",
       "      <td>88</td>\n",
       "      <td>300.0</td>\n",
       "      <td>...</td>\n",
       "      <td>7.297030</td>\n",
       "      <td>2.712871</td>\n",
       "      <td>0.435644</td>\n",
       "      <td>25</td>\n",
       "      <td>55.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.200000</td>\n",
       "      <td>0.760000</td>\n",
       "      <td>0.320000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2020-02-02</td>\n",
       "      <td>1571</td>\n",
       "      <td>19363.0</td>\n",
       "      <td>8353.0</td>\n",
       "      <td>2480.0</td>\n",
       "      <td>12.325271</td>\n",
       "      <td>5.316996</td>\n",
       "      <td>1.578612</td>\n",
       "      <td>111</td>\n",
       "      <td>446.0</td>\n",
       "      <td>...</td>\n",
       "      <td>62.120000</td>\n",
       "      <td>20.066667</td>\n",
       "      <td>10.566667</td>\n",
       "      <td>38</td>\n",
       "      <td>96.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.526316</td>\n",
       "      <td>1.078947</td>\n",
       "      <td>0.473684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2020-02-03</td>\n",
       "      <td>1206</td>\n",
       "      <td>34691.0</td>\n",
       "      <td>9583.0</td>\n",
       "      <td>2267.0</td>\n",
       "      <td>28.765340</td>\n",
       "      <td>7.946103</td>\n",
       "      <td>1.879768</td>\n",
       "      <td>101</td>\n",
       "      <td>1878.0</td>\n",
       "      <td>...</td>\n",
       "      <td>38.687500</td>\n",
       "      <td>9.476562</td>\n",
       "      <td>1.062500</td>\n",
       "      <td>43</td>\n",
       "      <td>93.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.162791</td>\n",
       "      <td>0.906977</td>\n",
       "      <td>0.418605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2020-02-04</td>\n",
       "      <td>1410</td>\n",
       "      <td>15569.0</td>\n",
       "      <td>6087.0</td>\n",
       "      <td>1038.0</td>\n",
       "      <td>11.041844</td>\n",
       "      <td>4.317021</td>\n",
       "      <td>0.736170</td>\n",
       "      <td>98</td>\n",
       "      <td>424.0</td>\n",
       "      <td>...</td>\n",
       "      <td>9.508333</td>\n",
       "      <td>2.375000</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>33</td>\n",
       "      <td>36.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.090909</td>\n",
       "      <td>0.424242</td>\n",
       "      <td>0.393939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2020-02-05</td>\n",
       "      <td>1394</td>\n",
       "      <td>38268.0</td>\n",
       "      <td>13567.0</td>\n",
       "      <td>2110.0</td>\n",
       "      <td>27.451937</td>\n",
       "      <td>9.732425</td>\n",
       "      <td>1.513630</td>\n",
       "      <td>71</td>\n",
       "      <td>3060.0</td>\n",
       "      <td>...</td>\n",
       "      <td>35.472973</td>\n",
       "      <td>15.108108</td>\n",
       "      <td>2.364865</td>\n",
       "      <td>16</td>\n",
       "      <td>1040.0</td>\n",
       "      <td>572.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>35.750000</td>\n",
       "      <td>3.187500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2020-02-06</td>\n",
       "      <td>1391</td>\n",
       "      <td>14841.0</td>\n",
       "      <td>4242.0</td>\n",
       "      <td>1189.0</td>\n",
       "      <td>10.669303</td>\n",
       "      <td>3.049605</td>\n",
       "      <td>0.854781</td>\n",
       "      <td>125</td>\n",
       "      <td>460.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.299065</td>\n",
       "      <td>1.775701</td>\n",
       "      <td>0.672897</td>\n",
       "      <td>39</td>\n",
       "      <td>241.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>6.179487</td>\n",
       "      <td>2.615385</td>\n",
       "      <td>0.589744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2020-02-07</td>\n",
       "      <td>1148</td>\n",
       "      <td>33183.0</td>\n",
       "      <td>11217.0</td>\n",
       "      <td>2076.0</td>\n",
       "      <td>28.905052</td>\n",
       "      <td>9.770906</td>\n",
       "      <td>1.808362</td>\n",
       "      <td>85</td>\n",
       "      <td>275.0</td>\n",
       "      <td>...</td>\n",
       "      <td>45.867470</td>\n",
       "      <td>8.662651</td>\n",
       "      <td>2.253012</td>\n",
       "      <td>21</td>\n",
       "      <td>131.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.238095</td>\n",
       "      <td>1.904762</td>\n",
       "      <td>0.285714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2020-02-08</td>\n",
       "      <td>1105</td>\n",
       "      <td>25652.0</td>\n",
       "      <td>6180.0</td>\n",
       "      <td>2315.0</td>\n",
       "      <td>23.214480</td>\n",
       "      <td>5.592760</td>\n",
       "      <td>2.095023</td>\n",
       "      <td>61</td>\n",
       "      <td>512.0</td>\n",
       "      <td>...</td>\n",
       "      <td>35.163934</td>\n",
       "      <td>8.491803</td>\n",
       "      <td>20.229508</td>\n",
       "      <td>15</td>\n",
       "      <td>69.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>4.600000</td>\n",
       "      <td>1.866667</td>\n",
       "      <td>0.866667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2020-02-09</td>\n",
       "      <td>1235</td>\n",
       "      <td>30884.0</td>\n",
       "      <td>8144.0</td>\n",
       "      <td>2463.0</td>\n",
       "      <td>25.007287</td>\n",
       "      <td>6.594332</td>\n",
       "      <td>1.994332</td>\n",
       "      <td>103</td>\n",
       "      <td>7639.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.887640</td>\n",
       "      <td>0.820225</td>\n",
       "      <td>0.629213</td>\n",
       "      <td>33</td>\n",
       "      <td>245.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>7.424242</td>\n",
       "      <td>1.484848</td>\n",
       "      <td>1.181818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2020-02-10</td>\n",
       "      <td>1172</td>\n",
       "      <td>11604.0</td>\n",
       "      <td>3938.0</td>\n",
       "      <td>759.0</td>\n",
       "      <td>9.901024</td>\n",
       "      <td>3.360068</td>\n",
       "      <td>0.647611</td>\n",
       "      <td>86</td>\n",
       "      <td>95.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.727273</td>\n",
       "      <td>2.227273</td>\n",
       "      <td>0.511364</td>\n",
       "      <td>22</td>\n",
       "      <td>15.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.681818</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.590909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2020-02-11</td>\n",
       "      <td>1353</td>\n",
       "      <td>63225.0</td>\n",
       "      <td>8061.0</td>\n",
       "      <td>3113.0</td>\n",
       "      <td>46.729490</td>\n",
       "      <td>5.957871</td>\n",
       "      <td>2.300813</td>\n",
       "      <td>84</td>\n",
       "      <td>301.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.183099</td>\n",
       "      <td>1.380282</td>\n",
       "      <td>0.323944</td>\n",
       "      <td>16</td>\n",
       "      <td>18.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.125000</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2020-02-12</td>\n",
       "      <td>1429</td>\n",
       "      <td>22324.0</td>\n",
       "      <td>7921.0</td>\n",
       "      <td>1930.0</td>\n",
       "      <td>15.622113</td>\n",
       "      <td>5.543037</td>\n",
       "      <td>1.350595</td>\n",
       "      <td>114</td>\n",
       "      <td>359.0</td>\n",
       "      <td>...</td>\n",
       "      <td>14.666667</td>\n",
       "      <td>5.883333</td>\n",
       "      <td>0.983333</td>\n",
       "      <td>20</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2020-02-13</td>\n",
       "      <td>1184</td>\n",
       "      <td>11870.0</td>\n",
       "      <td>3241.0</td>\n",
       "      <td>1033.0</td>\n",
       "      <td>10.025338</td>\n",
       "      <td>2.737331</td>\n",
       "      <td>0.872466</td>\n",
       "      <td>84</td>\n",
       "      <td>632.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.246377</td>\n",
       "      <td>0.608696</td>\n",
       "      <td>0.318841</td>\n",
       "      <td>22</td>\n",
       "      <td>105.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.772727</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.318182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2020-02-14</td>\n",
       "      <td>1371</td>\n",
       "      <td>15227.0</td>\n",
       "      <td>4995.0</td>\n",
       "      <td>1585.0</td>\n",
       "      <td>11.106492</td>\n",
       "      <td>3.643326</td>\n",
       "      <td>1.156090</td>\n",
       "      <td>58</td>\n",
       "      <td>155.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6.507246</td>\n",
       "      <td>1.782609</td>\n",
       "      <td>0.768116</td>\n",
       "      <td>11</td>\n",
       "      <td>24.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.181818</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.545455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2020-02-15</td>\n",
       "      <td>382</td>\n",
       "      <td>3818.0</td>\n",
       "      <td>1281.0</td>\n",
       "      <td>216.0</td>\n",
       "      <td>9.994764</td>\n",
       "      <td>3.353403</td>\n",
       "      <td>0.565445</td>\n",
       "      <td>19</td>\n",
       "      <td>26.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.555556</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>3</td>\n",
       "      <td>15.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2020-02-16</td>\n",
       "      <td>1214</td>\n",
       "      <td>27947.0</td>\n",
       "      <td>8567.0</td>\n",
       "      <td>1408.0</td>\n",
       "      <td>23.020593</td>\n",
       "      <td>7.056837</td>\n",
       "      <td>1.159802</td>\n",
       "      <td>85</td>\n",
       "      <td>386.0</td>\n",
       "      <td>...</td>\n",
       "      <td>13.805195</td>\n",
       "      <td>3.480519</td>\n",
       "      <td>0.935065</td>\n",
       "      <td>23</td>\n",
       "      <td>32.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.391304</td>\n",
       "      <td>0.391304</td>\n",
       "      <td>0.652174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2020-02-17</td>\n",
       "      <td>1194</td>\n",
       "      <td>10044.0</td>\n",
       "      <td>3608.0</td>\n",
       "      <td>945.0</td>\n",
       "      <td>8.412060</td>\n",
       "      <td>3.021776</td>\n",
       "      <td>0.791457</td>\n",
       "      <td>77</td>\n",
       "      <td>598.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.525641</td>\n",
       "      <td>1.179487</td>\n",
       "      <td>0.525641</td>\n",
       "      <td>22</td>\n",
       "      <td>143.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>6.500000</td>\n",
       "      <td>1.727273</td>\n",
       "      <td>0.681818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2020-02-18</td>\n",
       "      <td>1191</td>\n",
       "      <td>10269.0</td>\n",
       "      <td>2623.0</td>\n",
       "      <td>847.0</td>\n",
       "      <td>8.622166</td>\n",
       "      <td>2.202351</td>\n",
       "      <td>0.711167</td>\n",
       "      <td>73</td>\n",
       "      <td>119.0</td>\n",
       "      <td>...</td>\n",
       "      <td>37.432099</td>\n",
       "      <td>10.209877</td>\n",
       "      <td>1.135802</td>\n",
       "      <td>24</td>\n",
       "      <td>31.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.291667</td>\n",
       "      <td>0.208333</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2020-02-19</td>\n",
       "      <td>1198</td>\n",
       "      <td>14977.0</td>\n",
       "      <td>5291.0</td>\n",
       "      <td>1274.0</td>\n",
       "      <td>12.501669</td>\n",
       "      <td>4.416528</td>\n",
       "      <td>1.063439</td>\n",
       "      <td>88</td>\n",
       "      <td>2040.0</td>\n",
       "      <td>...</td>\n",
       "      <td>10.777778</td>\n",
       "      <td>3.530864</td>\n",
       "      <td>0.604938</td>\n",
       "      <td>30</td>\n",
       "      <td>14.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.233333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2020-02-20</td>\n",
       "      <td>1149</td>\n",
       "      <td>14931.0</td>\n",
       "      <td>3784.0</td>\n",
       "      <td>990.0</td>\n",
       "      <td>12.994778</td>\n",
       "      <td>3.293299</td>\n",
       "      <td>0.861619</td>\n",
       "      <td>88</td>\n",
       "      <td>857.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.532258</td>\n",
       "      <td>2.322581</td>\n",
       "      <td>0.983871</td>\n",
       "      <td>22</td>\n",
       "      <td>70.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>3.181818</td>\n",
       "      <td>1.136364</td>\n",
       "      <td>0.772727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>2020-02-21</td>\n",
       "      <td>1246</td>\n",
       "      <td>13324.0</td>\n",
       "      <td>2452.0</td>\n",
       "      <td>1184.0</td>\n",
       "      <td>10.693419</td>\n",
       "      <td>1.967897</td>\n",
       "      <td>0.950241</td>\n",
       "      <td>87</td>\n",
       "      <td>3805.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.469027</td>\n",
       "      <td>0.876106</td>\n",
       "      <td>2.106195</td>\n",
       "      <td>34</td>\n",
       "      <td>13.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.382353</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.294118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>2020-02-22</td>\n",
       "      <td>1232</td>\n",
       "      <td>21155.0</td>\n",
       "      <td>4665.0</td>\n",
       "      <td>1212.0</td>\n",
       "      <td>17.171266</td>\n",
       "      <td>3.786526</td>\n",
       "      <td>0.983766</td>\n",
       "      <td>85</td>\n",
       "      <td>651.0</td>\n",
       "      <td>...</td>\n",
       "      <td>42.920792</td>\n",
       "      <td>12.217822</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>25</td>\n",
       "      <td>532.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>21.280000</td>\n",
       "      <td>5.920000</td>\n",
       "      <td>1.040000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>2020-02-23</td>\n",
       "      <td>1253</td>\n",
       "      <td>22025.0</td>\n",
       "      <td>7919.0</td>\n",
       "      <td>1944.0</td>\n",
       "      <td>17.577813</td>\n",
       "      <td>6.320032</td>\n",
       "      <td>1.551476</td>\n",
       "      <td>111</td>\n",
       "      <td>2302.0</td>\n",
       "      <td>...</td>\n",
       "      <td>120.329670</td>\n",
       "      <td>67.637363</td>\n",
       "      <td>8.428571</td>\n",
       "      <td>35</td>\n",
       "      <td>2131.0</td>\n",
       "      <td>1009.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>60.885714</td>\n",
       "      <td>28.828571</td>\n",
       "      <td>3.542857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>2020-02-24</td>\n",
       "      <td>1634</td>\n",
       "      <td>17342.0</td>\n",
       "      <td>6902.0</td>\n",
       "      <td>1367.0</td>\n",
       "      <td>10.613219</td>\n",
       "      <td>4.223990</td>\n",
       "      <td>0.836597</td>\n",
       "      <td>185</td>\n",
       "      <td>4075.0</td>\n",
       "      <td>...</td>\n",
       "      <td>16.855491</td>\n",
       "      <td>8.601156</td>\n",
       "      <td>1.289017</td>\n",
       "      <td>73</td>\n",
       "      <td>490.0</td>\n",
       "      <td>209.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>6.712329</td>\n",
       "      <td>2.863014</td>\n",
       "      <td>0.547945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>2020-02-25</td>\n",
       "      <td>1931</td>\n",
       "      <td>63945.0</td>\n",
       "      <td>26417.0</td>\n",
       "      <td>4315.0</td>\n",
       "      <td>33.114966</td>\n",
       "      <td>13.680476</td>\n",
       "      <td>2.234593</td>\n",
       "      <td>271</td>\n",
       "      <td>15148.0</td>\n",
       "      <td>...</td>\n",
       "      <td>88.875000</td>\n",
       "      <td>36.125000</td>\n",
       "      <td>3.410714</td>\n",
       "      <td>115</td>\n",
       "      <td>14113.0</td>\n",
       "      <td>5426.0</td>\n",
       "      <td>504.0</td>\n",
       "      <td>122.721739</td>\n",
       "      <td>47.182609</td>\n",
       "      <td>4.382609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>2020-02-26</td>\n",
       "      <td>1878</td>\n",
       "      <td>27829.0</td>\n",
       "      <td>11796.0</td>\n",
       "      <td>1725.0</td>\n",
       "      <td>14.818424</td>\n",
       "      <td>6.281150</td>\n",
       "      <td>0.918530</td>\n",
       "      <td>224</td>\n",
       "      <td>1672.0</td>\n",
       "      <td>...</td>\n",
       "      <td>36.180905</td>\n",
       "      <td>22.527638</td>\n",
       "      <td>2.110553</td>\n",
       "      <td>59</td>\n",
       "      <td>245.0</td>\n",
       "      <td>171.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>4.152542</td>\n",
       "      <td>2.898305</td>\n",
       "      <td>0.779661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>2020-02-27</td>\n",
       "      <td>1682</td>\n",
       "      <td>28901.0</td>\n",
       "      <td>12170.0</td>\n",
       "      <td>2379.0</td>\n",
       "      <td>17.182521</td>\n",
       "      <td>7.235434</td>\n",
       "      <td>1.414388</td>\n",
       "      <td>181</td>\n",
       "      <td>584.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.248908</td>\n",
       "      <td>2.235808</td>\n",
       "      <td>0.589520</td>\n",
       "      <td>69</td>\n",
       "      <td>472.0</td>\n",
       "      <td>185.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>6.840580</td>\n",
       "      <td>2.681159</td>\n",
       "      <td>0.971014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>2020-02-28</td>\n",
       "      <td>1611</td>\n",
       "      <td>67370.0</td>\n",
       "      <td>18037.0</td>\n",
       "      <td>7293.0</td>\n",
       "      <td>41.818746</td>\n",
       "      <td>11.196151</td>\n",
       "      <td>4.527002</td>\n",
       "      <td>167</td>\n",
       "      <td>46630.0</td>\n",
       "      <td>...</td>\n",
       "      <td>272.207547</td>\n",
       "      <td>69.995283</td>\n",
       "      <td>29.858491</td>\n",
       "      <td>70</td>\n",
       "      <td>46522.0</td>\n",
       "      <td>11982.0</td>\n",
       "      <td>5178.0</td>\n",
       "      <td>664.600000</td>\n",
       "      <td>171.171429</td>\n",
       "      <td>73.971429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>2020-02-29</td>\n",
       "      <td>1399</td>\n",
       "      <td>33949.0</td>\n",
       "      <td>10825.0</td>\n",
       "      <td>2396.0</td>\n",
       "      <td>24.266619</td>\n",
       "      <td>7.737670</td>\n",
       "      <td>1.712652</td>\n",
       "      <td>130</td>\n",
       "      <td>16540.0</td>\n",
       "      <td>...</td>\n",
       "      <td>110.082192</td>\n",
       "      <td>34.424658</td>\n",
       "      <td>6.438356</td>\n",
       "      <td>39</td>\n",
       "      <td>14969.0</td>\n",
       "      <td>4627.0</td>\n",
       "      <td>816.0</td>\n",
       "      <td>383.820513</td>\n",
       "      <td>118.641026</td>\n",
       "      <td>20.923077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>2020-03-01</td>\n",
       "      <td>1416</td>\n",
       "      <td>12963.0</td>\n",
       "      <td>3984.0</td>\n",
       "      <td>891.0</td>\n",
       "      <td>9.154661</td>\n",
       "      <td>2.813559</td>\n",
       "      <td>0.629237</td>\n",
       "      <td>115</td>\n",
       "      <td>120.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.987342</td>\n",
       "      <td>1.620253</td>\n",
       "      <td>0.632911</td>\n",
       "      <td>47</td>\n",
       "      <td>30.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.638298</td>\n",
       "      <td>0.085106</td>\n",
       "      <td>0.234043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>2020-03-02</td>\n",
       "      <td>1721</td>\n",
       "      <td>15818.0</td>\n",
       "      <td>2670.0</td>\n",
       "      <td>1281.0</td>\n",
       "      <td>9.191168</td>\n",
       "      <td>1.551424</td>\n",
       "      <td>0.744335</td>\n",
       "      <td>124</td>\n",
       "      <td>262.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.722628</td>\n",
       "      <td>1.233577</td>\n",
       "      <td>0.423358</td>\n",
       "      <td>41</td>\n",
       "      <td>184.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>4.487805</td>\n",
       "      <td>2.536585</td>\n",
       "      <td>0.268293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>2020-03-03</td>\n",
       "      <td>1644</td>\n",
       "      <td>17279.0</td>\n",
       "      <td>4289.0</td>\n",
       "      <td>1304.0</td>\n",
       "      <td>10.510341</td>\n",
       "      <td>2.608881</td>\n",
       "      <td>0.793187</td>\n",
       "      <td>107</td>\n",
       "      <td>232.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.548148</td>\n",
       "      <td>1.555556</td>\n",
       "      <td>0.622222</td>\n",
       "      <td>30</td>\n",
       "      <td>36.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.200000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>2020-03-04</td>\n",
       "      <td>1550</td>\n",
       "      <td>11367.0</td>\n",
       "      <td>2992.0</td>\n",
       "      <td>1178.0</td>\n",
       "      <td>7.333548</td>\n",
       "      <td>1.930323</td>\n",
       "      <td>0.760000</td>\n",
       "      <td>102</td>\n",
       "      <td>734.0</td>\n",
       "      <td>...</td>\n",
       "      <td>10.386364</td>\n",
       "      <td>5.863636</td>\n",
       "      <td>1.022727</td>\n",
       "      <td>25</td>\n",
       "      <td>388.0</td>\n",
       "      <td>251.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>15.520000</td>\n",
       "      <td>10.040000</td>\n",
       "      <td>1.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>2020-03-05</td>\n",
       "      <td>1576</td>\n",
       "      <td>16721.0</td>\n",
       "      <td>4813.0</td>\n",
       "      <td>1064.0</td>\n",
       "      <td>10.609772</td>\n",
       "      <td>3.053934</td>\n",
       "      <td>0.675127</td>\n",
       "      <td>78</td>\n",
       "      <td>185.0</td>\n",
       "      <td>...</td>\n",
       "      <td>48.637363</td>\n",
       "      <td>9.087912</td>\n",
       "      <td>1.340659</td>\n",
       "      <td>19</td>\n",
       "      <td>84.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>4.421053</td>\n",
       "      <td>2.315789</td>\n",
       "      <td>0.631579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>2020-03-06</td>\n",
       "      <td>1601</td>\n",
       "      <td>15452.0</td>\n",
       "      <td>3476.0</td>\n",
       "      <td>1089.0</td>\n",
       "      <td>9.651468</td>\n",
       "      <td>2.171143</td>\n",
       "      <td>0.680200</td>\n",
       "      <td>105</td>\n",
       "      <td>1796.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.425000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>40</td>\n",
       "      <td>61.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>1.525000</td>\n",
       "      <td>0.225000</td>\n",
       "      <td>0.475000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>2020-03-07</td>\n",
       "      <td>1349</td>\n",
       "      <td>24428.0</td>\n",
       "      <td>5517.0</td>\n",
       "      <td>1170.0</td>\n",
       "      <td>18.108228</td>\n",
       "      <td>4.089696</td>\n",
       "      <td>0.867309</td>\n",
       "      <td>88</td>\n",
       "      <td>1244.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.252747</td>\n",
       "      <td>1.010989</td>\n",
       "      <td>0.406593</td>\n",
       "      <td>31</td>\n",
       "      <td>39.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.258065</td>\n",
       "      <td>0.225806</td>\n",
       "      <td>0.258065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>2020-03-08</td>\n",
       "      <td>1587</td>\n",
       "      <td>15916.0</td>\n",
       "      <td>3670.0</td>\n",
       "      <td>1319.0</td>\n",
       "      <td>10.028986</td>\n",
       "      <td>2.312539</td>\n",
       "      <td>0.831128</td>\n",
       "      <td>108</td>\n",
       "      <td>94.0</td>\n",
       "      <td>...</td>\n",
       "      <td>10.834862</td>\n",
       "      <td>4.541284</td>\n",
       "      <td>0.935780</td>\n",
       "      <td>44</td>\n",
       "      <td>42.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.954545</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.590909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>2020-03-09</td>\n",
       "      <td>1199</td>\n",
       "      <td>10629.0</td>\n",
       "      <td>2550.0</td>\n",
       "      <td>950.0</td>\n",
       "      <td>8.864887</td>\n",
       "      <td>2.126772</td>\n",
       "      <td>0.792327</td>\n",
       "      <td>74</td>\n",
       "      <td>74.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.075000</td>\n",
       "      <td>0.725000</td>\n",
       "      <td>0.362500</td>\n",
       "      <td>24</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>2020-03-10</td>\n",
       "      <td>1404</td>\n",
       "      <td>14463.0</td>\n",
       "      <td>2392.0</td>\n",
       "      <td>1090.0</td>\n",
       "      <td>10.301282</td>\n",
       "      <td>1.703704</td>\n",
       "      <td>0.776353</td>\n",
       "      <td>85</td>\n",
       "      <td>1105.0</td>\n",
       "      <td>...</td>\n",
       "      <td>19.367089</td>\n",
       "      <td>6.835443</td>\n",
       "      <td>0.898734</td>\n",
       "      <td>23</td>\n",
       "      <td>754.0</td>\n",
       "      <td>299.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>32.782609</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>1.478261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>2020-03-11</td>\n",
       "      <td>1331</td>\n",
       "      <td>10606.0</td>\n",
       "      <td>2324.0</td>\n",
       "      <td>951.0</td>\n",
       "      <td>7.968445</td>\n",
       "      <td>1.746056</td>\n",
       "      <td>0.714500</td>\n",
       "      <td>74</td>\n",
       "      <td>100.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.050000</td>\n",
       "      <td>2.087500</td>\n",
       "      <td>0.525000</td>\n",
       "      <td>19</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.368421</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>0.368421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>2020-03-12</td>\n",
       "      <td>1845</td>\n",
       "      <td>27978.0</td>\n",
       "      <td>5632.0</td>\n",
       "      <td>1699.0</td>\n",
       "      <td>15.164228</td>\n",
       "      <td>3.052575</td>\n",
       "      <td>0.920867</td>\n",
       "      <td>64</td>\n",
       "      <td>109.0</td>\n",
       "      <td>...</td>\n",
       "      <td>12.301075</td>\n",
       "      <td>2.903226</td>\n",
       "      <td>0.946237</td>\n",
       "      <td>13</td>\n",
       "      <td>16.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.230769</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.307692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>2020-03-13</td>\n",
       "      <td>1932</td>\n",
       "      <td>26414.0</td>\n",
       "      <td>6477.0</td>\n",
       "      <td>1546.0</td>\n",
       "      <td>13.671843</td>\n",
       "      <td>3.352484</td>\n",
       "      <td>0.800207</td>\n",
       "      <td>83</td>\n",
       "      <td>397.0</td>\n",
       "      <td>...</td>\n",
       "      <td>9.861111</td>\n",
       "      <td>3.018519</td>\n",
       "      <td>2.175926</td>\n",
       "      <td>20</td>\n",
       "      <td>337.0</td>\n",
       "      <td>105.0</td>\n",
       "      <td>176.0</td>\n",
       "      <td>16.850000</td>\n",
       "      <td>5.250000</td>\n",
       "      <td>8.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>2020-03-14</td>\n",
       "      <td>2038</td>\n",
       "      <td>29328.0</td>\n",
       "      <td>7012.0</td>\n",
       "      <td>1808.0</td>\n",
       "      <td>14.390579</td>\n",
       "      <td>3.440628</td>\n",
       "      <td>0.887144</td>\n",
       "      <td>112</td>\n",
       "      <td>148.0</td>\n",
       "      <td>...</td>\n",
       "      <td>30.791946</td>\n",
       "      <td>11.926174</td>\n",
       "      <td>1.322148</td>\n",
       "      <td>18</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.277778</td>\n",
       "      <td>0.277778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>2020-03-15</td>\n",
       "      <td>1927</td>\n",
       "      <td>64749.0</td>\n",
       "      <td>16166.0</td>\n",
       "      <td>3065.0</td>\n",
       "      <td>33.600934</td>\n",
       "      <td>8.389206</td>\n",
       "      <td>1.590555</td>\n",
       "      <td>121</td>\n",
       "      <td>401.0</td>\n",
       "      <td>...</td>\n",
       "      <td>120.736196</td>\n",
       "      <td>36.711656</td>\n",
       "      <td>6.730061</td>\n",
       "      <td>29</td>\n",
       "      <td>237.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>8.172414</td>\n",
       "      <td>1.206897</td>\n",
       "      <td>0.862069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>2020-03-16</td>\n",
       "      <td>2209</td>\n",
       "      <td>19104.0</td>\n",
       "      <td>4858.0</td>\n",
       "      <td>1761.0</td>\n",
       "      <td>8.648257</td>\n",
       "      <td>2.199185</td>\n",
       "      <td>0.797193</td>\n",
       "      <td>112</td>\n",
       "      <td>425.0</td>\n",
       "      <td>...</td>\n",
       "      <td>18.922619</td>\n",
       "      <td>5.125000</td>\n",
       "      <td>1.678571</td>\n",
       "      <td>28</td>\n",
       "      <td>263.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>9.392857</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.535714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>2020-03-17</td>\n",
       "      <td>2393</td>\n",
       "      <td>28549.0</td>\n",
       "      <td>6314.0</td>\n",
       "      <td>1752.0</td>\n",
       "      <td>11.930213</td>\n",
       "      <td>2.638529</td>\n",
       "      <td>0.732135</td>\n",
       "      <td>119</td>\n",
       "      <td>581.0</td>\n",
       "      <td>...</td>\n",
       "      <td>11.108808</td>\n",
       "      <td>2.341969</td>\n",
       "      <td>0.735751</td>\n",
       "      <td>24</td>\n",
       "      <td>198.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>8.250000</td>\n",
       "      <td>3.583333</td>\n",
       "      <td>1.458333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>2020-03-18</td>\n",
       "      <td>2465</td>\n",
       "      <td>52161.0</td>\n",
       "      <td>10214.0</td>\n",
       "      <td>2359.0</td>\n",
       "      <td>21.160649</td>\n",
       "      <td>4.143611</td>\n",
       "      <td>0.956998</td>\n",
       "      <td>112</td>\n",
       "      <td>157.0</td>\n",
       "      <td>...</td>\n",
       "      <td>16.090909</td>\n",
       "      <td>5.406417</td>\n",
       "      <td>1.112299</td>\n",
       "      <td>28</td>\n",
       "      <td>56.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.535714</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>2020-03-19</td>\n",
       "      <td>3581</td>\n",
       "      <td>38664.0</td>\n",
       "      <td>5759.0</td>\n",
       "      <td>3135.0</td>\n",
       "      <td>10.796984</td>\n",
       "      <td>1.608210</td>\n",
       "      <td>0.875454</td>\n",
       "      <td>123</td>\n",
       "      <td>511.0</td>\n",
       "      <td>...</td>\n",
       "      <td>10.195876</td>\n",
       "      <td>2.654639</td>\n",
       "      <td>0.675258</td>\n",
       "      <td>21</td>\n",
       "      <td>83.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.952381</td>\n",
       "      <td>1.238095</td>\n",
       "      <td>0.428571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>2020-03-20</td>\n",
       "      <td>3421</td>\n",
       "      <td>96732.0</td>\n",
       "      <td>17312.0</td>\n",
       "      <td>4896.0</td>\n",
       "      <td>28.275943</td>\n",
       "      <td>5.060509</td>\n",
       "      <td>1.431160</td>\n",
       "      <td>166</td>\n",
       "      <td>2011.0</td>\n",
       "      <td>...</td>\n",
       "      <td>10.887500</td>\n",
       "      <td>4.562500</td>\n",
       "      <td>0.887500</td>\n",
       "      <td>14</td>\n",
       "      <td>63.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.785714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>2020-03-21</td>\n",
       "      <td>3911</td>\n",
       "      <td>33643.0</td>\n",
       "      <td>8644.0</td>\n",
       "      <td>2832.0</td>\n",
       "      <td>8.602148</td>\n",
       "      <td>2.210176</td>\n",
       "      <td>0.724111</td>\n",
       "      <td>146</td>\n",
       "      <td>618.0</td>\n",
       "      <td>...</td>\n",
       "      <td>13.972222</td>\n",
       "      <td>4.047619</td>\n",
       "      <td>1.246032</td>\n",
       "      <td>16</td>\n",
       "      <td>98.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>6.125000</td>\n",
       "      <td>1.625000</td>\n",
       "      <td>0.875000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>2020-03-22</td>\n",
       "      <td>7349</td>\n",
       "      <td>84439.0</td>\n",
       "      <td>19844.0</td>\n",
       "      <td>3994.0</td>\n",
       "      <td>11.489863</td>\n",
       "      <td>2.700231</td>\n",
       "      <td>0.543475</td>\n",
       "      <td>198</td>\n",
       "      <td>485.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.505263</td>\n",
       "      <td>1.218421</td>\n",
       "      <td>0.405263</td>\n",
       "      <td>18</td>\n",
       "      <td>12.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.055556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>2020-03-23</td>\n",
       "      <td>4727</td>\n",
       "      <td>152183.0</td>\n",
       "      <td>17249.0</td>\n",
       "      <td>7609.0</td>\n",
       "      <td>32.194415</td>\n",
       "      <td>3.649037</td>\n",
       "      <td>1.609689</td>\n",
       "      <td>202</td>\n",
       "      <td>359.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.665198</td>\n",
       "      <td>1.788546</td>\n",
       "      <td>0.449339</td>\n",
       "      <td>23</td>\n",
       "      <td>49.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.130435</td>\n",
       "      <td>0.478261</td>\n",
       "      <td>0.260870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>2020-03-24</td>\n",
       "      <td>6078</td>\n",
       "      <td>43407.0</td>\n",
       "      <td>10107.0</td>\n",
       "      <td>4044.0</td>\n",
       "      <td>7.141658</td>\n",
       "      <td>1.662883</td>\n",
       "      <td>0.665350</td>\n",
       "      <td>223</td>\n",
       "      <td>1300.0</td>\n",
       "      <td>...</td>\n",
       "      <td>9.436482</td>\n",
       "      <td>2.996743</td>\n",
       "      <td>0.931596</td>\n",
       "      <td>27</td>\n",
       "      <td>879.0</td>\n",
       "      <td>408.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>32.555556</td>\n",
       "      <td>15.111111</td>\n",
       "      <td>2.037037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>2020-03-25</td>\n",
       "      <td>5351</td>\n",
       "      <td>56496.0</td>\n",
       "      <td>12290.0</td>\n",
       "      <td>3979.0</td>\n",
       "      <td>10.558027</td>\n",
       "      <td>2.296767</td>\n",
       "      <td>0.743599</td>\n",
       "      <td>147</td>\n",
       "      <td>1325.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6.129412</td>\n",
       "      <td>1.584314</td>\n",
       "      <td>0.592157</td>\n",
       "      <td>16</td>\n",
       "      <td>85.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>5.312500</td>\n",
       "      <td>3.062500</td>\n",
       "      <td>0.937500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>2020-03-26</td>\n",
       "      <td>5027</td>\n",
       "      <td>92106.0</td>\n",
       "      <td>12839.0</td>\n",
       "      <td>3735.0</td>\n",
       "      <td>18.322260</td>\n",
       "      <td>2.554008</td>\n",
       "      <td>0.742988</td>\n",
       "      <td>220</td>\n",
       "      <td>935.0</td>\n",
       "      <td>...</td>\n",
       "      <td>186.323333</td>\n",
       "      <td>11.083333</td>\n",
       "      <td>3.696667</td>\n",
       "      <td>34</td>\n",
       "      <td>28.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>0.882353</td>\n",
       "      <td>0.911765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>2020-03-27</td>\n",
       "      <td>4714</td>\n",
       "      <td>49241.0</td>\n",
       "      <td>13023.0</td>\n",
       "      <td>4071.0</td>\n",
       "      <td>10.445694</td>\n",
       "      <td>2.762622</td>\n",
       "      <td>0.863598</td>\n",
       "      <td>196</td>\n",
       "      <td>638.0</td>\n",
       "      <td>...</td>\n",
       "      <td>7.034364</td>\n",
       "      <td>2.604811</td>\n",
       "      <td>0.852234</td>\n",
       "      <td>30</td>\n",
       "      <td>62.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.066667</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.266667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>2020-03-28</td>\n",
       "      <td>5109</td>\n",
       "      <td>182990.0</td>\n",
       "      <td>32469.0</td>\n",
       "      <td>9074.0</td>\n",
       "      <td>35.817185</td>\n",
       "      <td>6.355255</td>\n",
       "      <td>1.776081</td>\n",
       "      <td>232</td>\n",
       "      <td>1215.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.300380</td>\n",
       "      <td>1.513308</td>\n",
       "      <td>0.653992</td>\n",
       "      <td>34</td>\n",
       "      <td>78.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.294118</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>0.235294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>2020-03-29</td>\n",
       "      <td>4694</td>\n",
       "      <td>49044.0</td>\n",
       "      <td>9993.0</td>\n",
       "      <td>4513.0</td>\n",
       "      <td>10.448232</td>\n",
       "      <td>2.128888</td>\n",
       "      <td>0.961440</td>\n",
       "      <td>222</td>\n",
       "      <td>973.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.854093</td>\n",
       "      <td>1.096085</td>\n",
       "      <td>0.295374</td>\n",
       "      <td>23</td>\n",
       "      <td>13.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.565217</td>\n",
       "      <td>0.260870</td>\n",
       "      <td>0.434783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>2020-03-30</td>\n",
       "      <td>3913</td>\n",
       "      <td>97068.0</td>\n",
       "      <td>41715.0</td>\n",
       "      <td>5828.0</td>\n",
       "      <td>24.806542</td>\n",
       "      <td>10.660618</td>\n",
       "      <td>1.489394</td>\n",
       "      <td>175</td>\n",
       "      <td>1558.0</td>\n",
       "      <td>...</td>\n",
       "      <td>24.619433</td>\n",
       "      <td>11.161943</td>\n",
       "      <td>1.376518</td>\n",
       "      <td>19</td>\n",
       "      <td>50.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2.631579</td>\n",
       "      <td>1.263158</td>\n",
       "      <td>0.842105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>2020-03-31</td>\n",
       "      <td>4026</td>\n",
       "      <td>50401.0</td>\n",
       "      <td>9689.0</td>\n",
       "      <td>2771.0</td>\n",
       "      <td>12.518877</td>\n",
       "      <td>2.406607</td>\n",
       "      <td>0.688276</td>\n",
       "      <td>288</td>\n",
       "      <td>1662.0</td>\n",
       "      <td>...</td>\n",
       "      <td>16.116477</td>\n",
       "      <td>4.815341</td>\n",
       "      <td>0.842330</td>\n",
       "      <td>127</td>\n",
       "      <td>1524.0</td>\n",
       "      <td>584.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>4.598425</td>\n",
       "      <td>0.582677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>2020-04-01</td>\n",
       "      <td>3924</td>\n",
       "      <td>37633.0</td>\n",
       "      <td>9299.0</td>\n",
       "      <td>3296.0</td>\n",
       "      <td>9.590469</td>\n",
       "      <td>2.369776</td>\n",
       "      <td>0.839959</td>\n",
       "      <td>324</td>\n",
       "      <td>633.0</td>\n",
       "      <td>...</td>\n",
       "      <td>11.585831</td>\n",
       "      <td>3.931880</td>\n",
       "      <td>1.051771</td>\n",
       "      <td>149</td>\n",
       "      <td>431.0</td>\n",
       "      <td>194.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>2.892617</td>\n",
       "      <td>1.302013</td>\n",
       "      <td>0.496644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>2020-04-02</td>\n",
       "      <td>3799</td>\n",
       "      <td>29942.0</td>\n",
       "      <td>9539.0</td>\n",
       "      <td>2347.0</td>\n",
       "      <td>7.881548</td>\n",
       "      <td>2.510924</td>\n",
       "      <td>0.617794</td>\n",
       "      <td>375</td>\n",
       "      <td>2511.0</td>\n",
       "      <td>...</td>\n",
       "      <td>18.350224</td>\n",
       "      <td>7.517139</td>\n",
       "      <td>1.007452</td>\n",
       "      <td>182</td>\n",
       "      <td>622.0</td>\n",
       "      <td>215.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>3.417582</td>\n",
       "      <td>1.181319</td>\n",
       "      <td>0.324176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>2020-04-03</td>\n",
       "      <td>3812</td>\n",
       "      <td>38690.0</td>\n",
       "      <td>10784.0</td>\n",
       "      <td>3270.0</td>\n",
       "      <td>10.149528</td>\n",
       "      <td>2.828961</td>\n",
       "      <td>0.857817</td>\n",
       "      <td>283</td>\n",
       "      <td>1694.0</td>\n",
       "      <td>...</td>\n",
       "      <td>12.387218</td>\n",
       "      <td>2.881579</td>\n",
       "      <td>1.389098</td>\n",
       "      <td>123</td>\n",
       "      <td>237.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>1.926829</td>\n",
       "      <td>0.463415</td>\n",
       "      <td>0.430894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>2020-04-04</td>\n",
       "      <td>3424</td>\n",
       "      <td>36596.0</td>\n",
       "      <td>12188.0</td>\n",
       "      <td>2981.0</td>\n",
       "      <td>10.688084</td>\n",
       "      <td>3.559579</td>\n",
       "      <td>0.870619</td>\n",
       "      <td>208</td>\n",
       "      <td>582.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.938272</td>\n",
       "      <td>1.832099</td>\n",
       "      <td>0.520988</td>\n",
       "      <td>69</td>\n",
       "      <td>281.0</td>\n",
       "      <td>136.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>4.072464</td>\n",
       "      <td>1.971014</td>\n",
       "      <td>0.463768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>2020-04-05</td>\n",
       "      <td>3954</td>\n",
       "      <td>149360.0</td>\n",
       "      <td>20020.0</td>\n",
       "      <td>19187.0</td>\n",
       "      <td>37.774406</td>\n",
       "      <td>5.063227</td>\n",
       "      <td>4.852554</td>\n",
       "      <td>208</td>\n",
       "      <td>37321.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.467213</td>\n",
       "      <td>1.297814</td>\n",
       "      <td>0.393443</td>\n",
       "      <td>79</td>\n",
       "      <td>113.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>1.430380</td>\n",
       "      <td>0.531646</td>\n",
       "      <td>0.354430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>2020-04-06</td>\n",
       "      <td>3731</td>\n",
       "      <td>30889.0</td>\n",
       "      <td>6283.0</td>\n",
       "      <td>1724.0</td>\n",
       "      <td>8.279014</td>\n",
       "      <td>1.683999</td>\n",
       "      <td>0.462075</td>\n",
       "      <td>231</td>\n",
       "      <td>580.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.174419</td>\n",
       "      <td>0.741279</td>\n",
       "      <td>0.284884</td>\n",
       "      <td>56</td>\n",
       "      <td>31.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.553571</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.339286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>2020-04-07</td>\n",
       "      <td>3313</td>\n",
       "      <td>25892.0</td>\n",
       "      <td>7489.0</td>\n",
       "      <td>2231.0</td>\n",
       "      <td>7.815273</td>\n",
       "      <td>2.260489</td>\n",
       "      <td>0.673408</td>\n",
       "      <td>190</td>\n",
       "      <td>972.0</td>\n",
       "      <td>...</td>\n",
       "      <td>15.235616</td>\n",
       "      <td>5.172603</td>\n",
       "      <td>0.876712</td>\n",
       "      <td>79</td>\n",
       "      <td>795.0</td>\n",
       "      <td>294.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>10.063291</td>\n",
       "      <td>3.721519</td>\n",
       "      <td>0.784810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>2020-04-08</td>\n",
       "      <td>3276</td>\n",
       "      <td>18247.0</td>\n",
       "      <td>4397.0</td>\n",
       "      <td>2082.0</td>\n",
       "      <td>5.569902</td>\n",
       "      <td>1.342186</td>\n",
       "      <td>0.635531</td>\n",
       "      <td>154</td>\n",
       "      <td>242.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.437086</td>\n",
       "      <td>1.692053</td>\n",
       "      <td>0.649007</td>\n",
       "      <td>55</td>\n",
       "      <td>39.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.709091</td>\n",
       "      <td>0.072727</td>\n",
       "      <td>0.254545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>2020-04-09</td>\n",
       "      <td>3524</td>\n",
       "      <td>27576.0</td>\n",
       "      <td>8402.0</td>\n",
       "      <td>2475.0</td>\n",
       "      <td>7.825199</td>\n",
       "      <td>2.384222</td>\n",
       "      <td>0.702327</td>\n",
       "      <td>169</td>\n",
       "      <td>341.0</td>\n",
       "      <td>...</td>\n",
       "      <td>10.958904</td>\n",
       "      <td>3.024658</td>\n",
       "      <td>0.693151</td>\n",
       "      <td>64</td>\n",
       "      <td>108.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.687500</td>\n",
       "      <td>0.437500</td>\n",
       "      <td>0.187500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>2020-04-10</td>\n",
       "      <td>3400</td>\n",
       "      <td>33638.0</td>\n",
       "      <td>7836.0</td>\n",
       "      <td>2582.0</td>\n",
       "      <td>9.893529</td>\n",
       "      <td>2.304706</td>\n",
       "      <td>0.759412</td>\n",
       "      <td>156</td>\n",
       "      <td>207.0</td>\n",
       "      <td>...</td>\n",
       "      <td>12.319885</td>\n",
       "      <td>3.988473</td>\n",
       "      <td>0.951009</td>\n",
       "      <td>58</td>\n",
       "      <td>55.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.948276</td>\n",
       "      <td>0.310345</td>\n",
       "      <td>0.362069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>2020-04-11</td>\n",
       "      <td>3717</td>\n",
       "      <td>29775.0</td>\n",
       "      <td>6387.0</td>\n",
       "      <td>2858.0</td>\n",
       "      <td>8.010492</td>\n",
       "      <td>1.718321</td>\n",
       "      <td>0.768900</td>\n",
       "      <td>172</td>\n",
       "      <td>867.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.796875</td>\n",
       "      <td>0.987500</td>\n",
       "      <td>0.521875</td>\n",
       "      <td>54</td>\n",
       "      <td>153.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>2.833333</td>\n",
       "      <td>0.537037</td>\n",
       "      <td>0.592593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>2020-04-12</td>\n",
       "      <td>3590</td>\n",
       "      <td>26986.0</td>\n",
       "      <td>6724.0</td>\n",
       "      <td>2626.0</td>\n",
       "      <td>7.516992</td>\n",
       "      <td>1.872981</td>\n",
       "      <td>0.731476</td>\n",
       "      <td>204</td>\n",
       "      <td>1268.0</td>\n",
       "      <td>...</td>\n",
       "      <td>14.189112</td>\n",
       "      <td>4.839542</td>\n",
       "      <td>0.782235</td>\n",
       "      <td>65</td>\n",
       "      <td>1124.0</td>\n",
       "      <td>455.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>17.292308</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.692308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>2020-04-13</td>\n",
       "      <td>3307</td>\n",
       "      <td>15862.0</td>\n",
       "      <td>4162.0</td>\n",
       "      <td>1796.0</td>\n",
       "      <td>4.796492</td>\n",
       "      <td>1.258542</td>\n",
       "      <td>0.543090</td>\n",
       "      <td>166</td>\n",
       "      <td>145.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.784091</td>\n",
       "      <td>1.454545</td>\n",
       "      <td>0.443182</td>\n",
       "      <td>48</td>\n",
       "      <td>49.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.020833</td>\n",
       "      <td>0.104167</td>\n",
       "      <td>0.229167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>2020-04-14</td>\n",
       "      <td>4214</td>\n",
       "      <td>24653.0</td>\n",
       "      <td>5651.0</td>\n",
       "      <td>2796.0</td>\n",
       "      <td>5.850261</td>\n",
       "      <td>1.341006</td>\n",
       "      <td>0.663503</td>\n",
       "      <td>158</td>\n",
       "      <td>613.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.014164</td>\n",
       "      <td>1.155807</td>\n",
       "      <td>0.371105</td>\n",
       "      <td>37</td>\n",
       "      <td>41.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.108108</td>\n",
       "      <td>0.297297</td>\n",
       "      <td>0.270270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>2020-04-15</td>\n",
       "      <td>3417</td>\n",
       "      <td>18882.0</td>\n",
       "      <td>5044.0</td>\n",
       "      <td>2187.0</td>\n",
       "      <td>5.525900</td>\n",
       "      <td>1.476149</td>\n",
       "      <td>0.640035</td>\n",
       "      <td>187</td>\n",
       "      <td>336.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.691756</td>\n",
       "      <td>1.301075</td>\n",
       "      <td>0.516129</td>\n",
       "      <td>46</td>\n",
       "      <td>59.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.282609</td>\n",
       "      <td>0.260870</td>\n",
       "      <td>0.239130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>2020-04-16</td>\n",
       "      <td>3307</td>\n",
       "      <td>15228.0</td>\n",
       "      <td>4173.0</td>\n",
       "      <td>1664.0</td>\n",
       "      <td>4.604778</td>\n",
       "      <td>1.261869</td>\n",
       "      <td>0.503175</td>\n",
       "      <td>212</td>\n",
       "      <td>516.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.426523</td>\n",
       "      <td>1.455197</td>\n",
       "      <td>0.437276</td>\n",
       "      <td>60</td>\n",
       "      <td>55.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>0.183333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>2020-04-17</td>\n",
       "      <td>3065</td>\n",
       "      <td>31639.0</td>\n",
       "      <td>6814.0</td>\n",
       "      <td>2478.0</td>\n",
       "      <td>10.322675</td>\n",
       "      <td>2.223165</td>\n",
       "      <td>0.808483</td>\n",
       "      <td>168</td>\n",
       "      <td>359.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.036585</td>\n",
       "      <td>1.203252</td>\n",
       "      <td>0.402439</td>\n",
       "      <td>48</td>\n",
       "      <td>29.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.604167</td>\n",
       "      <td>0.187500</td>\n",
       "      <td>0.375000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>2020-04-18</td>\n",
       "      <td>3150</td>\n",
       "      <td>40877.0</td>\n",
       "      <td>5331.0</td>\n",
       "      <td>2098.0</td>\n",
       "      <td>12.976825</td>\n",
       "      <td>1.692381</td>\n",
       "      <td>0.666032</td>\n",
       "      <td>167</td>\n",
       "      <td>290.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.161290</td>\n",
       "      <td>1.057348</td>\n",
       "      <td>0.408602</td>\n",
       "      <td>61</td>\n",
       "      <td>54.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.885246</td>\n",
       "      <td>0.213115</td>\n",
       "      <td>0.278689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>2020-04-19</td>\n",
       "      <td>3180</td>\n",
       "      <td>17864.0</td>\n",
       "      <td>4789.0</td>\n",
       "      <td>1933.0</td>\n",
       "      <td>5.617610</td>\n",
       "      <td>1.505975</td>\n",
       "      <td>0.607862</td>\n",
       "      <td>210</td>\n",
       "      <td>977.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.315068</td>\n",
       "      <td>1.356164</td>\n",
       "      <td>0.493151</td>\n",
       "      <td>74</td>\n",
       "      <td>169.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>2.283784</td>\n",
       "      <td>0.918919</td>\n",
       "      <td>0.337838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>2020-04-20</td>\n",
       "      <td>3381</td>\n",
       "      <td>23548.0</td>\n",
       "      <td>6871.0</td>\n",
       "      <td>2558.0</td>\n",
       "      <td>6.964803</td>\n",
       "      <td>2.032239</td>\n",
       "      <td>0.756581</td>\n",
       "      <td>299</td>\n",
       "      <td>3670.0</td>\n",
       "      <td>...</td>\n",
       "      <td>15.636923</td>\n",
       "      <td>6.470769</td>\n",
       "      <td>0.996923</td>\n",
       "      <td>84</td>\n",
       "      <td>3345.0</td>\n",
       "      <td>1538.0</td>\n",
       "      <td>203.0</td>\n",
       "      <td>39.821429</td>\n",
       "      <td>18.309524</td>\n",
       "      <td>2.416667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>2020-04-21</td>\n",
       "      <td>3282</td>\n",
       "      <td>25028.0</td>\n",
       "      <td>6252.0</td>\n",
       "      <td>2571.0</td>\n",
       "      <td>7.625838</td>\n",
       "      <td>1.904936</td>\n",
       "      <td>0.783364</td>\n",
       "      <td>231</td>\n",
       "      <td>491.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.870504</td>\n",
       "      <td>1.618705</td>\n",
       "      <td>0.456835</td>\n",
       "      <td>74</td>\n",
       "      <td>151.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>2.040541</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>0.445946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>2020-04-22</td>\n",
       "      <td>3389</td>\n",
       "      <td>20321.0</td>\n",
       "      <td>4986.0</td>\n",
       "      <td>1968.0</td>\n",
       "      <td>5.996164</td>\n",
       "      <td>1.471230</td>\n",
       "      <td>0.580702</td>\n",
       "      <td>290</td>\n",
       "      <td>1557.0</td>\n",
       "      <td>...</td>\n",
       "      <td>7.005682</td>\n",
       "      <td>3.156250</td>\n",
       "      <td>0.784091</td>\n",
       "      <td>109</td>\n",
       "      <td>914.0</td>\n",
       "      <td>573.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>8.385321</td>\n",
       "      <td>5.256881</td>\n",
       "      <td>0.743119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>2020-04-23</td>\n",
       "      <td>3272</td>\n",
       "      <td>19678.0</td>\n",
       "      <td>5404.0</td>\n",
       "      <td>2445.0</td>\n",
       "      <td>6.014059</td>\n",
       "      <td>1.651589</td>\n",
       "      <td>0.747249</td>\n",
       "      <td>334</td>\n",
       "      <td>1504.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.945833</td>\n",
       "      <td>1.508333</td>\n",
       "      <td>0.645833</td>\n",
       "      <td>65</td>\n",
       "      <td>129.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>1.984615</td>\n",
       "      <td>1.169231</td>\n",
       "      <td>0.492308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>2020-04-24</td>\n",
       "      <td>2972</td>\n",
       "      <td>28444.0</td>\n",
       "      <td>6264.0</td>\n",
       "      <td>2267.0</td>\n",
       "      <td>9.570659</td>\n",
       "      <td>2.107672</td>\n",
       "      <td>0.762786</td>\n",
       "      <td>168</td>\n",
       "      <td>523.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.328638</td>\n",
       "      <td>0.924883</td>\n",
       "      <td>0.352113</td>\n",
       "      <td>43</td>\n",
       "      <td>103.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>2.395349</td>\n",
       "      <td>0.651163</td>\n",
       "      <td>0.465116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>2020-04-25</td>\n",
       "      <td>2919</td>\n",
       "      <td>32508.0</td>\n",
       "      <td>8679.0</td>\n",
       "      <td>2537.0</td>\n",
       "      <td>11.136691</td>\n",
       "      <td>2.973279</td>\n",
       "      <td>0.869133</td>\n",
       "      <td>150</td>\n",
       "      <td>763.0</td>\n",
       "      <td>...</td>\n",
       "      <td>54.517857</td>\n",
       "      <td>17.334821</td>\n",
       "      <td>1.669643</td>\n",
       "      <td>34</td>\n",
       "      <td>29.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.852941</td>\n",
       "      <td>0.441176</td>\n",
       "      <td>0.264706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>2020-04-26</td>\n",
       "      <td>3144</td>\n",
       "      <td>25369.0</td>\n",
       "      <td>6470.0</td>\n",
       "      <td>2886.0</td>\n",
       "      <td>8.069020</td>\n",
       "      <td>2.057888</td>\n",
       "      <td>0.917939</td>\n",
       "      <td>162</td>\n",
       "      <td>675.0</td>\n",
       "      <td>...</td>\n",
       "      <td>16.619910</td>\n",
       "      <td>5.316742</td>\n",
       "      <td>0.954751</td>\n",
       "      <td>39</td>\n",
       "      <td>66.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.692308</td>\n",
       "      <td>0.564103</td>\n",
       "      <td>0.282051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>2020-04-27</td>\n",
       "      <td>2798</td>\n",
       "      <td>33638.0</td>\n",
       "      <td>9595.0</td>\n",
       "      <td>2378.0</td>\n",
       "      <td>12.022159</td>\n",
       "      <td>3.429235</td>\n",
       "      <td>0.849893</td>\n",
       "      <td>191</td>\n",
       "      <td>789.0</td>\n",
       "      <td>...</td>\n",
       "      <td>10.955645</td>\n",
       "      <td>4.673387</td>\n",
       "      <td>1.125000</td>\n",
       "      <td>51</td>\n",
       "      <td>63.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1.235294</td>\n",
       "      <td>0.529412</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>2020-04-28</td>\n",
       "      <td>2934</td>\n",
       "      <td>29567.0</td>\n",
       "      <td>5628.0</td>\n",
       "      <td>2575.0</td>\n",
       "      <td>10.077369</td>\n",
       "      <td>1.918200</td>\n",
       "      <td>0.877641</td>\n",
       "      <td>173</td>\n",
       "      <td>495.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.306220</td>\n",
       "      <td>1.755981</td>\n",
       "      <td>0.488038</td>\n",
       "      <td>40</td>\n",
       "      <td>286.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>7.150000</td>\n",
       "      <td>2.125000</td>\n",
       "      <td>0.775000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>2020-04-29</td>\n",
       "      <td>2756</td>\n",
       "      <td>35077.0</td>\n",
       "      <td>6725.0</td>\n",
       "      <td>2139.0</td>\n",
       "      <td>12.727504</td>\n",
       "      <td>2.440131</td>\n",
       "      <td>0.776125</td>\n",
       "      <td>166</td>\n",
       "      <td>846.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6.333333</td>\n",
       "      <td>1.987179</td>\n",
       "      <td>0.572650</td>\n",
       "      <td>56</td>\n",
       "      <td>757.0</td>\n",
       "      <td>301.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>13.517857</td>\n",
       "      <td>5.375000</td>\n",
       "      <td>1.178571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>2020-04-30</td>\n",
       "      <td>2566</td>\n",
       "      <td>40562.0</td>\n",
       "      <td>6957.0</td>\n",
       "      <td>1973.0</td>\n",
       "      <td>15.807482</td>\n",
       "      <td>2.711224</td>\n",
       "      <td>0.768901</td>\n",
       "      <td>130</td>\n",
       "      <td>318.0</td>\n",
       "      <td>...</td>\n",
       "      <td>40.288557</td>\n",
       "      <td>3.422886</td>\n",
       "      <td>1.208955</td>\n",
       "      <td>35</td>\n",
       "      <td>33.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.942857</td>\n",
       "      <td>0.171429</td>\n",
       "      <td>0.285714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>2020-05-01</td>\n",
       "      <td>3139</td>\n",
       "      <td>27006.0</td>\n",
       "      <td>6523.0</td>\n",
       "      <td>2351.0</td>\n",
       "      <td>8.603377</td>\n",
       "      <td>2.078050</td>\n",
       "      <td>0.748965</td>\n",
       "      <td>111</td>\n",
       "      <td>1618.0</td>\n",
       "      <td>...</td>\n",
       "      <td>15.136792</td>\n",
       "      <td>5.575472</td>\n",
       "      <td>1.155660</td>\n",
       "      <td>44</td>\n",
       "      <td>1360.0</td>\n",
       "      <td>682.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>30.909091</td>\n",
       "      <td>15.500000</td>\n",
       "      <td>2.045455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>2020-05-02</td>\n",
       "      <td>3099</td>\n",
       "      <td>70224.0</td>\n",
       "      <td>9457.0</td>\n",
       "      <td>2990.0</td>\n",
       "      <td>22.660213</td>\n",
       "      <td>3.051630</td>\n",
       "      <td>0.964827</td>\n",
       "      <td>150</td>\n",
       "      <td>859.0</td>\n",
       "      <td>...</td>\n",
       "      <td>39.794737</td>\n",
       "      <td>9.221053</td>\n",
       "      <td>1.878947</td>\n",
       "      <td>42</td>\n",
       "      <td>680.0</td>\n",
       "      <td>330.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>16.190476</td>\n",
       "      <td>7.857143</td>\n",
       "      <td>0.952381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>2020-05-03</td>\n",
       "      <td>3570</td>\n",
       "      <td>59944.0</td>\n",
       "      <td>16441.0</td>\n",
       "      <td>3212.0</td>\n",
       "      <td>16.791036</td>\n",
       "      <td>4.605322</td>\n",
       "      <td>0.899720</td>\n",
       "      <td>199</td>\n",
       "      <td>18878.0</td>\n",
       "      <td>...</td>\n",
       "      <td>47.357595</td>\n",
       "      <td>12.848101</td>\n",
       "      <td>2.132911</td>\n",
       "      <td>63</td>\n",
       "      <td>4509.0</td>\n",
       "      <td>1710.0</td>\n",
       "      <td>251.0</td>\n",
       "      <td>71.571429</td>\n",
       "      <td>27.142857</td>\n",
       "      <td>3.984127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>2020-05-04</td>\n",
       "      <td>3443</td>\n",
       "      <td>40825.0</td>\n",
       "      <td>11535.0</td>\n",
       "      <td>3510.0</td>\n",
       "      <td>11.857392</td>\n",
       "      <td>3.350276</td>\n",
       "      <td>1.019460</td>\n",
       "      <td>230</td>\n",
       "      <td>8893.0</td>\n",
       "      <td>...</td>\n",
       "      <td>51.155172</td>\n",
       "      <td>18.422414</td>\n",
       "      <td>2.581897</td>\n",
       "      <td>54</td>\n",
       "      <td>5296.0</td>\n",
       "      <td>1690.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>98.074074</td>\n",
       "      <td>31.296296</td>\n",
       "      <td>1.907407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>2020-05-05</td>\n",
       "      <td>3166</td>\n",
       "      <td>29879.0</td>\n",
       "      <td>7778.0</td>\n",
       "      <td>2067.0</td>\n",
       "      <td>9.437461</td>\n",
       "      <td>2.456728</td>\n",
       "      <td>0.652874</td>\n",
       "      <td>192</td>\n",
       "      <td>1186.0</td>\n",
       "      <td>...</td>\n",
       "      <td>14.345992</td>\n",
       "      <td>6.371308</td>\n",
       "      <td>1.350211</td>\n",
       "      <td>45</td>\n",
       "      <td>898.0</td>\n",
       "      <td>270.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>19.955556</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.355556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>2020-05-06</td>\n",
       "      <td>2960</td>\n",
       "      <td>23372.0</td>\n",
       "      <td>5045.0</td>\n",
       "      <td>1824.0</td>\n",
       "      <td>7.895946</td>\n",
       "      <td>1.704392</td>\n",
       "      <td>0.616216</td>\n",
       "      <td>190</td>\n",
       "      <td>683.0</td>\n",
       "      <td>...</td>\n",
       "      <td>26.975806</td>\n",
       "      <td>4.931452</td>\n",
       "      <td>1.221774</td>\n",
       "      <td>56</td>\n",
       "      <td>445.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>7.946429</td>\n",
       "      <td>2.232143</td>\n",
       "      <td>0.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>2020-05-07</td>\n",
       "      <td>2837</td>\n",
       "      <td>30804.0</td>\n",
       "      <td>11907.0</td>\n",
       "      <td>3890.0</td>\n",
       "      <td>10.857949</td>\n",
       "      <td>4.197039</td>\n",
       "      <td>1.371167</td>\n",
       "      <td>183</td>\n",
       "      <td>13761.0</td>\n",
       "      <td>...</td>\n",
       "      <td>53.494071</td>\n",
       "      <td>25.996047</td>\n",
       "      <td>8.664032</td>\n",
       "      <td>66</td>\n",
       "      <td>12968.0</td>\n",
       "      <td>6452.0</td>\n",
       "      <td>2144.0</td>\n",
       "      <td>196.484848</td>\n",
       "      <td>97.757576</td>\n",
       "      <td>32.484848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>2020-05-08</td>\n",
       "      <td>3007</td>\n",
       "      <td>13967.0</td>\n",
       "      <td>3898.0</td>\n",
       "      <td>1558.0</td>\n",
       "      <td>4.644829</td>\n",
       "      <td>1.296309</td>\n",
       "      <td>0.518124</td>\n",
       "      <td>182</td>\n",
       "      <td>350.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.635417</td>\n",
       "      <td>1.609375</td>\n",
       "      <td>0.661458</td>\n",
       "      <td>40</td>\n",
       "      <td>56.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1.400000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.550000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>2020-05-09</td>\n",
       "      <td>2651</td>\n",
       "      <td>32561.0</td>\n",
       "      <td>7326.0</td>\n",
       "      <td>1940.0</td>\n",
       "      <td>12.282535</td>\n",
       "      <td>2.763485</td>\n",
       "      <td>0.731799</td>\n",
       "      <td>156</td>\n",
       "      <td>492.0</td>\n",
       "      <td>...</td>\n",
       "      <td>64.214008</td>\n",
       "      <td>12.743191</td>\n",
       "      <td>1.552529</td>\n",
       "      <td>44</td>\n",
       "      <td>102.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>2.318182</td>\n",
       "      <td>0.681818</td>\n",
       "      <td>0.522727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>2020-05-10</td>\n",
       "      <td>2530</td>\n",
       "      <td>17498.0</td>\n",
       "      <td>3728.0</td>\n",
       "      <td>1291.0</td>\n",
       "      <td>6.916206</td>\n",
       "      <td>1.473518</td>\n",
       "      <td>0.510277</td>\n",
       "      <td>139</td>\n",
       "      <td>1769.0</td>\n",
       "      <td>...</td>\n",
       "      <td>11.072222</td>\n",
       "      <td>3.644444</td>\n",
       "      <td>0.622222</td>\n",
       "      <td>44</td>\n",
       "      <td>1307.0</td>\n",
       "      <td>446.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>29.704545</td>\n",
       "      <td>10.136364</td>\n",
       "      <td>1.113636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>2020-05-11</td>\n",
       "      <td>2379</td>\n",
       "      <td>27277.0</td>\n",
       "      <td>7659.0</td>\n",
       "      <td>2359.0</td>\n",
       "      <td>11.465742</td>\n",
       "      <td>3.219420</td>\n",
       "      <td>0.991593</td>\n",
       "      <td>128</td>\n",
       "      <td>1398.0</td>\n",
       "      <td>...</td>\n",
       "      <td>20.213836</td>\n",
       "      <td>4.578616</td>\n",
       "      <td>1.012579</td>\n",
       "      <td>30</td>\n",
       "      <td>28.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.366667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>2020-05-12</td>\n",
       "      <td>3044</td>\n",
       "      <td>29965.0</td>\n",
       "      <td>5089.0</td>\n",
       "      <td>2177.0</td>\n",
       "      <td>9.843955</td>\n",
       "      <td>1.671813</td>\n",
       "      <td>0.715177</td>\n",
       "      <td>115</td>\n",
       "      <td>346.0</td>\n",
       "      <td>...</td>\n",
       "      <td>8.220930</td>\n",
       "      <td>2.127907</td>\n",
       "      <td>0.709302</td>\n",
       "      <td>25</td>\n",
       "      <td>31.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.240000</td>\n",
       "      <td>0.360000</td>\n",
       "      <td>0.280000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>2020-05-13</td>\n",
       "      <td>2568</td>\n",
       "      <td>12542.0</td>\n",
       "      <td>3678.0</td>\n",
       "      <td>1392.0</td>\n",
       "      <td>4.883956</td>\n",
       "      <td>1.432243</td>\n",
       "      <td>0.542056</td>\n",
       "      <td>99</td>\n",
       "      <td>1196.0</td>\n",
       "      <td>...</td>\n",
       "      <td>12.932836</td>\n",
       "      <td>2.962687</td>\n",
       "      <td>0.611940</td>\n",
       "      <td>18</td>\n",
       "      <td>1071.0</td>\n",
       "      <td>265.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>59.500000</td>\n",
       "      <td>14.722222</td>\n",
       "      <td>1.888889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>2020-05-14</td>\n",
       "      <td>2416</td>\n",
       "      <td>36242.0</td>\n",
       "      <td>8848.0</td>\n",
       "      <td>2076.0</td>\n",
       "      <td>15.000828</td>\n",
       "      <td>3.662252</td>\n",
       "      <td>0.859272</td>\n",
       "      <td>118</td>\n",
       "      <td>394.0</td>\n",
       "      <td>...</td>\n",
       "      <td>15.506494</td>\n",
       "      <td>4.220779</td>\n",
       "      <td>0.688312</td>\n",
       "      <td>20</td>\n",
       "      <td>37.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.850000</td>\n",
       "      <td>1.550000</td>\n",
       "      <td>0.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>2020-05-15</td>\n",
       "      <td>2543</td>\n",
       "      <td>20769.0</td>\n",
       "      <td>6434.0</td>\n",
       "      <td>1868.0</td>\n",
       "      <td>8.167125</td>\n",
       "      <td>2.530083</td>\n",
       "      <td>0.734565</td>\n",
       "      <td>126</td>\n",
       "      <td>359.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.136905</td>\n",
       "      <td>0.797619</td>\n",
       "      <td>0.380952</td>\n",
       "      <td>31</td>\n",
       "      <td>74.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.387097</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.290323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>2020-05-16</td>\n",
       "      <td>2488</td>\n",
       "      <td>16187.0</td>\n",
       "      <td>4779.0</td>\n",
       "      <td>1472.0</td>\n",
       "      <td>6.506029</td>\n",
       "      <td>1.920820</td>\n",
       "      <td>0.591640</td>\n",
       "      <td>109</td>\n",
       "      <td>390.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.724832</td>\n",
       "      <td>1.456376</td>\n",
       "      <td>0.704698</td>\n",
       "      <td>21</td>\n",
       "      <td>117.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>5.571429</td>\n",
       "      <td>2.523810</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>2020-05-17</td>\n",
       "      <td>2919</td>\n",
       "      <td>21807.0</td>\n",
       "      <td>7651.0</td>\n",
       "      <td>1962.0</td>\n",
       "      <td>7.470709</td>\n",
       "      <td>2.621103</td>\n",
       "      <td>0.672148</td>\n",
       "      <td>166</td>\n",
       "      <td>216.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.786517</td>\n",
       "      <td>2.151685</td>\n",
       "      <td>0.438202</td>\n",
       "      <td>41</td>\n",
       "      <td>73.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.780488</td>\n",
       "      <td>1.097561</td>\n",
       "      <td>0.365854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>2020-05-18</td>\n",
       "      <td>2589</td>\n",
       "      <td>38398.0</td>\n",
       "      <td>10300.0</td>\n",
       "      <td>3276.0</td>\n",
       "      <td>14.831209</td>\n",
       "      <td>3.978370</td>\n",
       "      <td>1.265353</td>\n",
       "      <td>174</td>\n",
       "      <td>3339.0</td>\n",
       "      <td>...</td>\n",
       "      <td>25.038835</td>\n",
       "      <td>12.592233</td>\n",
       "      <td>2.563107</td>\n",
       "      <td>59</td>\n",
       "      <td>3253.0</td>\n",
       "      <td>1941.0</td>\n",
       "      <td>424.0</td>\n",
       "      <td>55.135593</td>\n",
       "      <td>32.898305</td>\n",
       "      <td>7.186441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>2020-05-19</td>\n",
       "      <td>2477</td>\n",
       "      <td>41151.0</td>\n",
       "      <td>13558.0</td>\n",
       "      <td>3323.0</td>\n",
       "      <td>16.613242</td>\n",
       "      <td>5.473557</td>\n",
       "      <td>1.341542</td>\n",
       "      <td>150</td>\n",
       "      <td>1357.0</td>\n",
       "      <td>...</td>\n",
       "      <td>18.004975</td>\n",
       "      <td>5.174129</td>\n",
       "      <td>1.019900</td>\n",
       "      <td>41</td>\n",
       "      <td>949.0</td>\n",
       "      <td>284.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>23.146341</td>\n",
       "      <td>6.926829</td>\n",
       "      <td>1.341463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>2020-05-20</td>\n",
       "      <td>2702</td>\n",
       "      <td>39802.0</td>\n",
       "      <td>10561.0</td>\n",
       "      <td>3156.0</td>\n",
       "      <td>14.730570</td>\n",
       "      <td>3.908586</td>\n",
       "      <td>1.168024</td>\n",
       "      <td>132</td>\n",
       "      <td>6675.0</td>\n",
       "      <td>...</td>\n",
       "      <td>34.777778</td>\n",
       "      <td>10.845679</td>\n",
       "      <td>0.814815</td>\n",
       "      <td>30</td>\n",
       "      <td>4989.0</td>\n",
       "      <td>1505.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>166.300000</td>\n",
       "      <td>50.166667</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>2020-05-21</td>\n",
       "      <td>2268</td>\n",
       "      <td>37783.0</td>\n",
       "      <td>11704.0</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>16.659171</td>\n",
       "      <td>5.160494</td>\n",
       "      <td>0.753527</td>\n",
       "      <td>104</td>\n",
       "      <td>2540.0</td>\n",
       "      <td>...</td>\n",
       "      <td>64.687500</td>\n",
       "      <td>24.312500</td>\n",
       "      <td>2.812500</td>\n",
       "      <td>13</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.153846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>2020-05-22</td>\n",
       "      <td>2210</td>\n",
       "      <td>43464.0</td>\n",
       "      <td>8846.0</td>\n",
       "      <td>2296.0</td>\n",
       "      <td>19.666968</td>\n",
       "      <td>4.002715</td>\n",
       "      <td>1.038914</td>\n",
       "      <td>110</td>\n",
       "      <td>1629.0</td>\n",
       "      <td>...</td>\n",
       "      <td>123.429577</td>\n",
       "      <td>30.816901</td>\n",
       "      <td>2.422535</td>\n",
       "      <td>19</td>\n",
       "      <td>975.0</td>\n",
       "      <td>566.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>51.315789</td>\n",
       "      <td>29.789474</td>\n",
       "      <td>3.368421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>2020-05-23</td>\n",
       "      <td>595</td>\n",
       "      <td>17040.0</td>\n",
       "      <td>1551.0</td>\n",
       "      <td>935.0</td>\n",
       "      <td>28.638655</td>\n",
       "      <td>2.606723</td>\n",
       "      <td>1.571429</td>\n",
       "      <td>37</td>\n",
       "      <td>272.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.837209</td>\n",
       "      <td>0.930233</td>\n",
       "      <td>0.325581</td>\n",
       "      <td>9</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>2020-05-24</td>\n",
       "      <td>2407</td>\n",
       "      <td>15440.0</td>\n",
       "      <td>3362.0</td>\n",
       "      <td>1434.0</td>\n",
       "      <td>6.414624</td>\n",
       "      <td>1.396759</td>\n",
       "      <td>0.595762</td>\n",
       "      <td>114</td>\n",
       "      <td>806.0</td>\n",
       "      <td>...</td>\n",
       "      <td>9.508876</td>\n",
       "      <td>3.136095</td>\n",
       "      <td>0.544379</td>\n",
       "      <td>22</td>\n",
       "      <td>145.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>6.590909</td>\n",
       "      <td>1.727273</td>\n",
       "      <td>0.727273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>2020-05-25</td>\n",
       "      <td>2236</td>\n",
       "      <td>23937.0</td>\n",
       "      <td>6846.0</td>\n",
       "      <td>2369.0</td>\n",
       "      <td>10.705277</td>\n",
       "      <td>3.061717</td>\n",
       "      <td>1.059481</td>\n",
       "      <td>99</td>\n",
       "      <td>375.0</td>\n",
       "      <td>...</td>\n",
       "      <td>12.071429</td>\n",
       "      <td>4.015873</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>20</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.450000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>2020-05-26</td>\n",
       "      <td>2230</td>\n",
       "      <td>22669.0</td>\n",
       "      <td>6198.0</td>\n",
       "      <td>2095.0</td>\n",
       "      <td>10.165471</td>\n",
       "      <td>2.779372</td>\n",
       "      <td>0.939462</td>\n",
       "      <td>108</td>\n",
       "      <td>296.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.974790</td>\n",
       "      <td>1.521008</td>\n",
       "      <td>0.453782</td>\n",
       "      <td>16</td>\n",
       "      <td>26.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.625000</td>\n",
       "      <td>0.437500</td>\n",
       "      <td>0.562500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>2020-05-27</td>\n",
       "      <td>2501</td>\n",
       "      <td>21259.0</td>\n",
       "      <td>5458.0</td>\n",
       "      <td>1829.0</td>\n",
       "      <td>8.500200</td>\n",
       "      <td>2.182327</td>\n",
       "      <td>0.731307</td>\n",
       "      <td>132</td>\n",
       "      <td>429.0</td>\n",
       "      <td>...</td>\n",
       "      <td>28.153374</td>\n",
       "      <td>9.220859</td>\n",
       "      <td>1.380368</td>\n",
       "      <td>27</td>\n",
       "      <td>42.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.555556</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.296296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>2020-05-28</td>\n",
       "      <td>2197</td>\n",
       "      <td>10548.0</td>\n",
       "      <td>3539.0</td>\n",
       "      <td>1313.0</td>\n",
       "      <td>4.801092</td>\n",
       "      <td>1.610833</td>\n",
       "      <td>0.597633</td>\n",
       "      <td>117</td>\n",
       "      <td>850.0</td>\n",
       "      <td>...</td>\n",
       "      <td>15.882353</td>\n",
       "      <td>7.901961</td>\n",
       "      <td>1.235294</td>\n",
       "      <td>17</td>\n",
       "      <td>605.0</td>\n",
       "      <td>161.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>35.588235</td>\n",
       "      <td>9.470588</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>2020-05-29</td>\n",
       "      <td>2334</td>\n",
       "      <td>15219.0</td>\n",
       "      <td>3842.0</td>\n",
       "      <td>1342.0</td>\n",
       "      <td>6.520566</td>\n",
       "      <td>1.646101</td>\n",
       "      <td>0.574979</td>\n",
       "      <td>130</td>\n",
       "      <td>140.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.932039</td>\n",
       "      <td>1.728155</td>\n",
       "      <td>0.368932</td>\n",
       "      <td>17</td>\n",
       "      <td>18.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.058824</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.176471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>2020-05-30</td>\n",
       "      <td>3037</td>\n",
       "      <td>19552.0</td>\n",
       "      <td>4643.0</td>\n",
       "      <td>1984.0</td>\n",
       "      <td>6.437932</td>\n",
       "      <td>1.528811</td>\n",
       "      <td>0.653276</td>\n",
       "      <td>163</td>\n",
       "      <td>749.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.926829</td>\n",
       "      <td>3.341463</td>\n",
       "      <td>0.420732</td>\n",
       "      <td>28</td>\n",
       "      <td>243.0</td>\n",
       "      <td>169.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>8.678571</td>\n",
       "      <td>6.035714</td>\n",
       "      <td>0.714286</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>130 rows  29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           date  total_tweets  total_likes  total_retweets  total_replies  \\\n",
       "0    2020-01-22           914      43574.0         11883.0         3542.0   \n",
       "1    2020-01-23          1136      24367.0          6457.0         3196.0   \n",
       "2    2020-01-24          1277      53227.0         13410.0         3459.0   \n",
       "3    2020-01-25          1131      52163.0         18937.0         9663.0   \n",
       "4    2020-01-26          1388      56400.0         12730.0         4363.0   \n",
       "5    2020-01-27          1274      48079.0         16058.0         3398.0   \n",
       "6    2020-01-28          1415      22811.0          5037.0         2219.0   \n",
       "7    2020-01-29          1494      33373.0          6807.0         2979.0   \n",
       "8    2020-01-30          1512      89417.0         26531.0         8989.0   \n",
       "9    2020-01-31          1240      18040.0          6119.0         1369.0   \n",
       "10   2020-02-01          1416      20888.0          5171.0         1679.0   \n",
       "11   2020-02-02          1571      19363.0          8353.0         2480.0   \n",
       "12   2020-02-03          1206      34691.0          9583.0         2267.0   \n",
       "13   2020-02-04          1410      15569.0          6087.0         1038.0   \n",
       "14   2020-02-05          1394      38268.0         13567.0         2110.0   \n",
       "15   2020-02-06          1391      14841.0          4242.0         1189.0   \n",
       "16   2020-02-07          1148      33183.0         11217.0         2076.0   \n",
       "17   2020-02-08          1105      25652.0          6180.0         2315.0   \n",
       "18   2020-02-09          1235      30884.0          8144.0         2463.0   \n",
       "19   2020-02-10          1172      11604.0          3938.0          759.0   \n",
       "20   2020-02-11          1353      63225.0          8061.0         3113.0   \n",
       "21   2020-02-12          1429      22324.0          7921.0         1930.0   \n",
       "22   2020-02-13          1184      11870.0          3241.0         1033.0   \n",
       "23   2020-02-14          1371      15227.0          4995.0         1585.0   \n",
       "24   2020-02-15           382       3818.0          1281.0          216.0   \n",
       "25   2020-02-16          1214      27947.0          8567.0         1408.0   \n",
       "26   2020-02-17          1194      10044.0          3608.0          945.0   \n",
       "27   2020-02-18          1191      10269.0          2623.0          847.0   \n",
       "28   2020-02-19          1198      14977.0          5291.0         1274.0   \n",
       "29   2020-02-20          1149      14931.0          3784.0          990.0   \n",
       "30   2020-02-21          1246      13324.0          2452.0         1184.0   \n",
       "31   2020-02-22          1232      21155.0          4665.0         1212.0   \n",
       "32   2020-02-23          1253      22025.0          7919.0         1944.0   \n",
       "33   2020-02-24          1634      17342.0          6902.0         1367.0   \n",
       "34   2020-02-25          1931      63945.0         26417.0         4315.0   \n",
       "35   2020-02-26          1878      27829.0         11796.0         1725.0   \n",
       "36   2020-02-27          1682      28901.0         12170.0         2379.0   \n",
       "37   2020-02-28          1611      67370.0         18037.0         7293.0   \n",
       "38   2020-02-29          1399      33949.0         10825.0         2396.0   \n",
       "39   2020-03-01          1416      12963.0          3984.0          891.0   \n",
       "40   2020-03-02          1721      15818.0          2670.0         1281.0   \n",
       "41   2020-03-03          1644      17279.0          4289.0         1304.0   \n",
       "42   2020-03-04          1550      11367.0          2992.0         1178.0   \n",
       "43   2020-03-05          1576      16721.0          4813.0         1064.0   \n",
       "44   2020-03-06          1601      15452.0          3476.0         1089.0   \n",
       "45   2020-03-07          1349      24428.0          5517.0         1170.0   \n",
       "46   2020-03-08          1587      15916.0          3670.0         1319.0   \n",
       "47   2020-03-09          1199      10629.0          2550.0          950.0   \n",
       "48   2020-03-10          1404      14463.0          2392.0         1090.0   \n",
       "49   2020-03-11          1331      10606.0          2324.0          951.0   \n",
       "50   2020-03-12          1845      27978.0          5632.0         1699.0   \n",
       "51   2020-03-13          1932      26414.0          6477.0         1546.0   \n",
       "52   2020-03-14          2038      29328.0          7012.0         1808.0   \n",
       "53   2020-03-15          1927      64749.0         16166.0         3065.0   \n",
       "54   2020-03-16          2209      19104.0          4858.0         1761.0   \n",
       "55   2020-03-17          2393      28549.0          6314.0         1752.0   \n",
       "56   2020-03-18          2465      52161.0         10214.0         2359.0   \n",
       "57   2020-03-19          3581      38664.0          5759.0         3135.0   \n",
       "58   2020-03-20          3421      96732.0         17312.0         4896.0   \n",
       "59   2020-03-21          3911      33643.0          8644.0         2832.0   \n",
       "60   2020-03-22          7349      84439.0         19844.0         3994.0   \n",
       "61   2020-03-23          4727     152183.0         17249.0         7609.0   \n",
       "62   2020-03-24          6078      43407.0         10107.0         4044.0   \n",
       "63   2020-03-25          5351      56496.0         12290.0         3979.0   \n",
       "64   2020-03-26          5027      92106.0         12839.0         3735.0   \n",
       "65   2020-03-27          4714      49241.0         13023.0         4071.0   \n",
       "66   2020-03-28          5109     182990.0         32469.0         9074.0   \n",
       "67   2020-03-29          4694      49044.0          9993.0         4513.0   \n",
       "68   2020-03-30          3913      97068.0         41715.0         5828.0   \n",
       "69   2020-03-31          4026      50401.0          9689.0         2771.0   \n",
       "70   2020-04-01          3924      37633.0          9299.0         3296.0   \n",
       "71   2020-04-02          3799      29942.0          9539.0         2347.0   \n",
       "72   2020-04-03          3812      38690.0         10784.0         3270.0   \n",
       "73   2020-04-04          3424      36596.0         12188.0         2981.0   \n",
       "74   2020-04-05          3954     149360.0         20020.0        19187.0   \n",
       "75   2020-04-06          3731      30889.0          6283.0         1724.0   \n",
       "76   2020-04-07          3313      25892.0          7489.0         2231.0   \n",
       "77   2020-04-08          3276      18247.0          4397.0         2082.0   \n",
       "78   2020-04-09          3524      27576.0          8402.0         2475.0   \n",
       "79   2020-04-10          3400      33638.0          7836.0         2582.0   \n",
       "80   2020-04-11          3717      29775.0          6387.0         2858.0   \n",
       "81   2020-04-12          3590      26986.0          6724.0         2626.0   \n",
       "82   2020-04-13          3307      15862.0          4162.0         1796.0   \n",
       "83   2020-04-14          4214      24653.0          5651.0         2796.0   \n",
       "84   2020-04-15          3417      18882.0          5044.0         2187.0   \n",
       "85   2020-04-16          3307      15228.0          4173.0         1664.0   \n",
       "86   2020-04-17          3065      31639.0          6814.0         2478.0   \n",
       "87   2020-04-18          3150      40877.0          5331.0         2098.0   \n",
       "88   2020-04-19          3180      17864.0          4789.0         1933.0   \n",
       "89   2020-04-20          3381      23548.0          6871.0         2558.0   \n",
       "90   2020-04-21          3282      25028.0          6252.0         2571.0   \n",
       "91   2020-04-22          3389      20321.0          4986.0         1968.0   \n",
       "92   2020-04-23          3272      19678.0          5404.0         2445.0   \n",
       "93   2020-04-24          2972      28444.0          6264.0         2267.0   \n",
       "94   2020-04-25          2919      32508.0          8679.0         2537.0   \n",
       "95   2020-04-26          3144      25369.0          6470.0         2886.0   \n",
       "96   2020-04-27          2798      33638.0          9595.0         2378.0   \n",
       "97   2020-04-28          2934      29567.0          5628.0         2575.0   \n",
       "98   2020-04-29          2756      35077.0          6725.0         2139.0   \n",
       "99   2020-04-30          2566      40562.0          6957.0         1973.0   \n",
       "100  2020-05-01          3139      27006.0          6523.0         2351.0   \n",
       "101  2020-05-02          3099      70224.0          9457.0         2990.0   \n",
       "102  2020-05-03          3570      59944.0         16441.0         3212.0   \n",
       "103  2020-05-04          3443      40825.0         11535.0         3510.0   \n",
       "104  2020-05-05          3166      29879.0          7778.0         2067.0   \n",
       "105  2020-05-06          2960      23372.0          5045.0         1824.0   \n",
       "106  2020-05-07          2837      30804.0         11907.0         3890.0   \n",
       "107  2020-05-08          3007      13967.0          3898.0         1558.0   \n",
       "108  2020-05-09          2651      32561.0          7326.0         1940.0   \n",
       "109  2020-05-10          2530      17498.0          3728.0         1291.0   \n",
       "110  2020-05-11          2379      27277.0          7659.0         2359.0   \n",
       "111  2020-05-12          3044      29965.0          5089.0         2177.0   \n",
       "112  2020-05-13          2568      12542.0          3678.0         1392.0   \n",
       "113  2020-05-14          2416      36242.0          8848.0         2076.0   \n",
       "114  2020-05-15          2543      20769.0          6434.0         1868.0   \n",
       "115  2020-05-16          2488      16187.0          4779.0         1472.0   \n",
       "116  2020-05-17          2919      21807.0          7651.0         1962.0   \n",
       "117  2020-05-18          2589      38398.0         10300.0         3276.0   \n",
       "118  2020-05-19          2477      41151.0         13558.0         3323.0   \n",
       "119  2020-05-20          2702      39802.0         10561.0         3156.0   \n",
       "120  2020-05-21          2268      37783.0         11704.0         1709.0   \n",
       "121  2020-05-22          2210      43464.0          8846.0         2296.0   \n",
       "122  2020-05-23           595      17040.0          1551.0          935.0   \n",
       "123  2020-05-24          2407      15440.0          3362.0         1434.0   \n",
       "124  2020-05-25          2236      23937.0          6846.0         2369.0   \n",
       "125  2020-05-26          2230      22669.0          6198.0         2095.0   \n",
       "126  2020-05-27          2501      21259.0          5458.0         1829.0   \n",
       "127  2020-05-28          2197      10548.0          3539.0         1313.0   \n",
       "128  2020-05-29          2334      15219.0          3842.0         1342.0   \n",
       "129  2020-05-30          3037      19552.0          4643.0         1984.0   \n",
       "\n",
       "     all_likes_avg  all_retweets_avg  all_replies_avg  all_neg_total  \\\n",
       "0        47.673961         13.001094         3.875274             75   \n",
       "1        21.449824          5.683979         2.813380             98   \n",
       "2        41.681284         10.501175         2.708692            110   \n",
       "3        46.121132         16.743590         8.543767            132   \n",
       "4        40.634006          9.171470         3.143372            132   \n",
       "5        37.738619         12.604396         2.667190            132   \n",
       "6        16.120848          3.559717         1.568198            171   \n",
       "7        22.338019          4.556225         1.993976            165   \n",
       "8        59.138228         17.546958         5.945106            167   \n",
       "9        14.548387          4.934677         1.104032            127   \n",
       "10       14.751412          3.651836         1.185734             88   \n",
       "11       12.325271          5.316996         1.578612            111   \n",
       "12       28.765340          7.946103         1.879768            101   \n",
       "13       11.041844          4.317021         0.736170             98   \n",
       "14       27.451937          9.732425         1.513630             71   \n",
       "15       10.669303          3.049605         0.854781            125   \n",
       "16       28.905052          9.770906         1.808362             85   \n",
       "17       23.214480          5.592760         2.095023             61   \n",
       "18       25.007287          6.594332         1.994332            103   \n",
       "19        9.901024          3.360068         0.647611             86   \n",
       "20       46.729490          5.957871         2.300813             84   \n",
       "21       15.622113          5.543037         1.350595            114   \n",
       "22       10.025338          2.737331         0.872466             84   \n",
       "23       11.106492          3.643326         1.156090             58   \n",
       "24        9.994764          3.353403         0.565445             19   \n",
       "25       23.020593          7.056837         1.159802             85   \n",
       "26        8.412060          3.021776         0.791457             77   \n",
       "27        8.622166          2.202351         0.711167             73   \n",
       "28       12.501669          4.416528         1.063439             88   \n",
       "29       12.994778          3.293299         0.861619             88   \n",
       "30       10.693419          1.967897         0.950241             87   \n",
       "31       17.171266          3.786526         0.983766             85   \n",
       "32       17.577813          6.320032         1.551476            111   \n",
       "33       10.613219          4.223990         0.836597            185   \n",
       "34       33.114966         13.680476         2.234593            271   \n",
       "35       14.818424          6.281150         0.918530            224   \n",
       "36       17.182521          7.235434         1.414388            181   \n",
       "37       41.818746         11.196151         4.527002            167   \n",
       "38       24.266619          7.737670         1.712652            130   \n",
       "39        9.154661          2.813559         0.629237            115   \n",
       "40        9.191168          1.551424         0.744335            124   \n",
       "41       10.510341          2.608881         0.793187            107   \n",
       "42        7.333548          1.930323         0.760000            102   \n",
       "43       10.609772          3.053934         0.675127             78   \n",
       "44        9.651468          2.171143         0.680200            105   \n",
       "45       18.108228          4.089696         0.867309             88   \n",
       "46       10.028986          2.312539         0.831128            108   \n",
       "47        8.864887          2.126772         0.792327             74   \n",
       "48       10.301282          1.703704         0.776353             85   \n",
       "49        7.968445          1.746056         0.714500             74   \n",
       "50       15.164228          3.052575         0.920867             64   \n",
       "51       13.671843          3.352484         0.800207             83   \n",
       "52       14.390579          3.440628         0.887144            112   \n",
       "53       33.600934          8.389206         1.590555            121   \n",
       "54        8.648257          2.199185         0.797193            112   \n",
       "55       11.930213          2.638529         0.732135            119   \n",
       "56       21.160649          4.143611         0.956998            112   \n",
       "57       10.796984          1.608210         0.875454            123   \n",
       "58       28.275943          5.060509         1.431160            166   \n",
       "59        8.602148          2.210176         0.724111            146   \n",
       "60       11.489863          2.700231         0.543475            198   \n",
       "61       32.194415          3.649037         1.609689            202   \n",
       "62        7.141658          1.662883         0.665350            223   \n",
       "63       10.558027          2.296767         0.743599            147   \n",
       "64       18.322260          2.554008         0.742988            220   \n",
       "65       10.445694          2.762622         0.863598            196   \n",
       "66       35.817185          6.355255         1.776081            232   \n",
       "67       10.448232          2.128888         0.961440            222   \n",
       "68       24.806542         10.660618         1.489394            175   \n",
       "69       12.518877          2.406607         0.688276            288   \n",
       "70        9.590469          2.369776         0.839959            324   \n",
       "71        7.881548          2.510924         0.617794            375   \n",
       "72       10.149528          2.828961         0.857817            283   \n",
       "73       10.688084          3.559579         0.870619            208   \n",
       "74       37.774406          5.063227         4.852554            208   \n",
       "75        8.279014          1.683999         0.462075            231   \n",
       "76        7.815273          2.260489         0.673408            190   \n",
       "77        5.569902          1.342186         0.635531            154   \n",
       "78        7.825199          2.384222         0.702327            169   \n",
       "79        9.893529          2.304706         0.759412            156   \n",
       "80        8.010492          1.718321         0.768900            172   \n",
       "81        7.516992          1.872981         0.731476            204   \n",
       "82        4.796492          1.258542         0.543090            166   \n",
       "83        5.850261          1.341006         0.663503            158   \n",
       "84        5.525900          1.476149         0.640035            187   \n",
       "85        4.604778          1.261869         0.503175            212   \n",
       "86       10.322675          2.223165         0.808483            168   \n",
       "87       12.976825          1.692381         0.666032            167   \n",
       "88        5.617610          1.505975         0.607862            210   \n",
       "89        6.964803          2.032239         0.756581            299   \n",
       "90        7.625838          1.904936         0.783364            231   \n",
       "91        5.996164          1.471230         0.580702            290   \n",
       "92        6.014059          1.651589         0.747249            334   \n",
       "93        9.570659          2.107672         0.762786            168   \n",
       "94       11.136691          2.973279         0.869133            150   \n",
       "95        8.069020          2.057888         0.917939            162   \n",
       "96       12.022159          3.429235         0.849893            191   \n",
       "97       10.077369          1.918200         0.877641            173   \n",
       "98       12.727504          2.440131         0.776125            166   \n",
       "99       15.807482          2.711224         0.768901            130   \n",
       "100       8.603377          2.078050         0.748965            111   \n",
       "101      22.660213          3.051630         0.964827            150   \n",
       "102      16.791036          4.605322         0.899720            199   \n",
       "103      11.857392          3.350276         1.019460            230   \n",
       "104       9.437461          2.456728         0.652874            192   \n",
       "105       7.895946          1.704392         0.616216            190   \n",
       "106      10.857949          4.197039         1.371167            183   \n",
       "107       4.644829          1.296309         0.518124            182   \n",
       "108      12.282535          2.763485         0.731799            156   \n",
       "109       6.916206          1.473518         0.510277            139   \n",
       "110      11.465742          3.219420         0.991593            128   \n",
       "111       9.843955          1.671813         0.715177            115   \n",
       "112       4.883956          1.432243         0.542056             99   \n",
       "113      15.000828          3.662252         0.859272            118   \n",
       "114       8.167125          2.530083         0.734565            126   \n",
       "115       6.506029          1.920820         0.591640            109   \n",
       "116       7.470709          2.621103         0.672148            166   \n",
       "117      14.831209          3.978370         1.265353            174   \n",
       "118      16.613242          5.473557         1.341542            150   \n",
       "119      14.730570          3.908586         1.168024            132   \n",
       "120      16.659171          5.160494         0.753527            104   \n",
       "121      19.666968          4.002715         1.038914            110   \n",
       "122      28.638655          2.606723         1.571429             37   \n",
       "123       6.414624          1.396759         0.595762            114   \n",
       "124      10.705277          3.061717         1.059481             99   \n",
       "125      10.165471          2.779372         0.939462            108   \n",
       "126       8.500200          2.182327         0.731307            132   \n",
       "127       4.801092          1.610833         0.597633            117   \n",
       "128       6.520566          1.646101         0.574979            130   \n",
       "129       6.437932          1.528811         0.653276            163   \n",
       "\n",
       "     all_neg_likes  ...  m_likes_avg  m_retweets_avg  m_replies_avg  \\\n",
       "0            244.0  ...    18.245902        2.475410       1.852459   \n",
       "1           7517.0  ...    35.598039       15.764706       2.098039   \n",
       "2           1652.0  ...   371.255556      113.133333      25.300000   \n",
       "3          26847.0  ...   104.676190       76.676190       5.523810   \n",
       "4          10504.0  ...   188.964912       54.570175      23.359649   \n",
       "5          10691.0  ...    67.500000       18.246032       3.174603   \n",
       "6            831.0  ...    47.376000        7.400000       6.632000   \n",
       "7            580.0  ...    50.145455       14.009091       5.372727   \n",
       "8          10563.0  ...   129.358621       36.972414      18.668966   \n",
       "9           5598.0  ...    12.877193        4.640351       0.938596   \n",
       "10           300.0  ...     7.297030        2.712871       0.435644   \n",
       "11           446.0  ...    62.120000       20.066667      10.566667   \n",
       "12          1878.0  ...    38.687500        9.476562       1.062500   \n",
       "13           424.0  ...     9.508333        2.375000       0.458333   \n",
       "14          3060.0  ...    35.472973       15.108108       2.364865   \n",
       "15           460.0  ...     5.299065        1.775701       0.672897   \n",
       "16           275.0  ...    45.867470        8.662651       2.253012   \n",
       "17           512.0  ...    35.163934        8.491803      20.229508   \n",
       "18          7639.0  ...     3.887640        0.820225       0.629213   \n",
       "19            95.0  ...     4.727273        2.227273       0.511364   \n",
       "20           301.0  ...     4.183099        1.380282       0.323944   \n",
       "21           359.0  ...    14.666667        5.883333       0.983333   \n",
       "22           632.0  ...     2.246377        0.608696       0.318841   \n",
       "23           155.0  ...     6.507246        1.782609       0.768116   \n",
       "24            26.0  ...     2.555556        0.555556       0.555556   \n",
       "25           386.0  ...    13.805195        3.480519       0.935065   \n",
       "26           598.0  ...     3.525641        1.179487       0.525641   \n",
       "27           119.0  ...    37.432099       10.209877       1.135802   \n",
       "28          2040.0  ...    10.777778        3.530864       0.604938   \n",
       "29           857.0  ...     5.532258        2.322581       0.983871   \n",
       "30          3805.0  ...     2.469027        0.876106       2.106195   \n",
       "31           651.0  ...    42.920792       12.217822       1.000000   \n",
       "32          2302.0  ...   120.329670       67.637363       8.428571   \n",
       "33          4075.0  ...    16.855491        8.601156       1.289017   \n",
       "34         15148.0  ...    88.875000       36.125000       3.410714   \n",
       "35          1672.0  ...    36.180905       22.527638       2.110553   \n",
       "36           584.0  ...     5.248908        2.235808       0.589520   \n",
       "37         46630.0  ...   272.207547       69.995283      29.858491   \n",
       "38         16540.0  ...   110.082192       34.424658       6.438356   \n",
       "39           120.0  ...     3.987342        1.620253       0.632911   \n",
       "40           262.0  ...     2.722628        1.233577       0.423358   \n",
       "41           232.0  ...     5.548148        1.555556       0.622222   \n",
       "42           734.0  ...    10.386364        5.863636       1.022727   \n",
       "43           185.0  ...    48.637363        9.087912       1.340659   \n",
       "44          1796.0  ...     3.425000        0.900000       0.500000   \n",
       "45          1244.0  ...     3.252747        1.010989       0.406593   \n",
       "46            94.0  ...    10.834862        4.541284       0.935780   \n",
       "47            74.0  ...     2.075000        0.725000       0.362500   \n",
       "48          1105.0  ...    19.367089        6.835443       0.898734   \n",
       "49           100.0  ...     5.050000        2.087500       0.525000   \n",
       "50           109.0  ...    12.301075        2.903226       0.946237   \n",
       "51           397.0  ...     9.861111        3.018519       2.175926   \n",
       "52           148.0  ...    30.791946       11.926174       1.322148   \n",
       "53           401.0  ...   120.736196       36.711656       6.730061   \n",
       "54           425.0  ...    18.922619        5.125000       1.678571   \n",
       "55           581.0  ...    11.108808        2.341969       0.735751   \n",
       "56           157.0  ...    16.090909        5.406417       1.112299   \n",
       "57           511.0  ...    10.195876        2.654639       0.675258   \n",
       "58          2011.0  ...    10.887500        4.562500       0.887500   \n",
       "59           618.0  ...    13.972222        4.047619       1.246032   \n",
       "60           485.0  ...     4.505263        1.218421       0.405263   \n",
       "61           359.0  ...     4.665198        1.788546       0.449339   \n",
       "62          1300.0  ...     9.436482        2.996743       0.931596   \n",
       "63          1325.0  ...     6.129412        1.584314       0.592157   \n",
       "64           935.0  ...   186.323333       11.083333       3.696667   \n",
       "65           638.0  ...     7.034364        2.604811       0.852234   \n",
       "66          1215.0  ...     5.300380        1.513308       0.653992   \n",
       "67           973.0  ...     3.854093        1.096085       0.295374   \n",
       "68          1558.0  ...    24.619433       11.161943       1.376518   \n",
       "69          1662.0  ...    16.116477        4.815341       0.842330   \n",
       "70           633.0  ...    11.585831        3.931880       1.051771   \n",
       "71          2511.0  ...    18.350224        7.517139       1.007452   \n",
       "72          1694.0  ...    12.387218        2.881579       1.389098   \n",
       "73           582.0  ...     4.938272        1.832099       0.520988   \n",
       "74         37321.0  ...     3.467213        1.297814       0.393443   \n",
       "75           580.0  ...     2.174419        0.741279       0.284884   \n",
       "76           972.0  ...    15.235616        5.172603       0.876712   \n",
       "77           242.0  ...     4.437086        1.692053       0.649007   \n",
       "78           341.0  ...    10.958904        3.024658       0.693151   \n",
       "79           207.0  ...    12.319885        3.988473       0.951009   \n",
       "80           867.0  ...     3.796875        0.987500       0.521875   \n",
       "81          1268.0  ...    14.189112        4.839542       0.782235   \n",
       "82           145.0  ...     3.784091        1.454545       0.443182   \n",
       "83           613.0  ...     3.014164        1.155807       0.371105   \n",
       "84           336.0  ...     3.691756        1.301075       0.516129   \n",
       "85           516.0  ...     4.426523        1.455197       0.437276   \n",
       "86           359.0  ...     4.036585        1.203252       0.402439   \n",
       "87           290.0  ...     3.161290        1.057348       0.408602   \n",
       "88           977.0  ...     4.315068        1.356164       0.493151   \n",
       "89          3670.0  ...    15.636923        6.470769       0.996923   \n",
       "90           491.0  ...     3.870504        1.618705       0.456835   \n",
       "91          1557.0  ...     7.005682        3.156250       0.784091   \n",
       "92          1504.0  ...     4.945833        1.508333       0.645833   \n",
       "93           523.0  ...     3.328638        0.924883       0.352113   \n",
       "94           763.0  ...    54.517857       17.334821       1.669643   \n",
       "95           675.0  ...    16.619910        5.316742       0.954751   \n",
       "96           789.0  ...    10.955645        4.673387       1.125000   \n",
       "97           495.0  ...     5.306220        1.755981       0.488038   \n",
       "98           846.0  ...     6.333333        1.987179       0.572650   \n",
       "99           318.0  ...    40.288557        3.422886       1.208955   \n",
       "100         1618.0  ...    15.136792        5.575472       1.155660   \n",
       "101          859.0  ...    39.794737        9.221053       1.878947   \n",
       "102        18878.0  ...    47.357595       12.848101       2.132911   \n",
       "103         8893.0  ...    51.155172       18.422414       2.581897   \n",
       "104         1186.0  ...    14.345992        6.371308       1.350211   \n",
       "105          683.0  ...    26.975806        4.931452       1.221774   \n",
       "106        13761.0  ...    53.494071       25.996047       8.664032   \n",
       "107          350.0  ...     4.635417        1.609375       0.661458   \n",
       "108          492.0  ...    64.214008       12.743191       1.552529   \n",
       "109         1769.0  ...    11.072222        3.644444       0.622222   \n",
       "110         1398.0  ...    20.213836        4.578616       1.012579   \n",
       "111          346.0  ...     8.220930        2.127907       0.709302   \n",
       "112         1196.0  ...    12.932836        2.962687       0.611940   \n",
       "113          394.0  ...    15.506494        4.220779       0.688312   \n",
       "114          359.0  ...     2.136905        0.797619       0.380952   \n",
       "115          390.0  ...     4.724832        1.456376       0.704698   \n",
       "116          216.0  ...     3.786517        2.151685       0.438202   \n",
       "117         3339.0  ...    25.038835       12.592233       2.563107   \n",
       "118         1357.0  ...    18.004975        5.174129       1.019900   \n",
       "119         6675.0  ...    34.777778       10.845679       0.814815   \n",
       "120         2540.0  ...    64.687500       24.312500       2.812500   \n",
       "121         1629.0  ...   123.429577       30.816901       2.422535   \n",
       "122          272.0  ...     2.837209        0.930233       0.325581   \n",
       "123          806.0  ...     9.508876        3.136095       0.544379   \n",
       "124          375.0  ...    12.071429        4.015873       0.952381   \n",
       "125          296.0  ...     3.974790        1.521008       0.453782   \n",
       "126          429.0  ...    28.153374        9.220859       1.380368   \n",
       "127          850.0  ...    15.882353        7.901961       1.235294   \n",
       "128          140.0  ...     4.932039        1.728155       0.368932   \n",
       "129          749.0  ...     5.926829        3.341463       0.420732   \n",
       "\n",
       "     m_neg_total  m_neg_likes  m_neg_retweets  m_neg_replies  m_neg_likes_avg  \\\n",
       "0             21         89.0            35.0            4.0         4.238095   \n",
       "1             36       2470.0           992.0          128.0        68.611111   \n",
       "2             27        637.0           118.0          118.0        23.592593   \n",
       "3             51       9319.0          7308.0          541.0       182.725490   \n",
       "4             40      10145.0          2788.0          970.0       253.625000   \n",
       "5             48        279.0            57.0           28.0         5.812500   \n",
       "6             46         95.0            29.0           24.0         2.065217   \n",
       "7             31         90.0            67.0           19.0         2.903226   \n",
       "8             51       1555.0           695.0          123.0        30.490196   \n",
       "9             42         36.0            18.0           16.0         0.857143   \n",
       "10            25         55.0            19.0            8.0         2.200000   \n",
       "11            38         96.0            41.0           18.0         2.526316   \n",
       "12            43         93.0            39.0           18.0         2.162791   \n",
       "13            33         36.0            14.0           13.0         1.090909   \n",
       "14            16       1040.0           572.0           51.0        65.000000   \n",
       "15            39        241.0           102.0           23.0         6.179487   \n",
       "16            21        131.0            40.0            6.0         6.238095   \n",
       "17            15         69.0            28.0           13.0         4.600000   \n",
       "18            33        245.0            49.0           39.0         7.424242   \n",
       "19            22         15.0             6.0           13.0         0.681818   \n",
       "20            16         18.0             6.0            0.0         1.125000   \n",
       "21            20          7.0             1.0            4.0         0.350000   \n",
       "22            22        105.0            20.0            7.0         4.772727   \n",
       "23            11         24.0             9.0            6.0         2.181818   \n",
       "24             3         15.0             2.0            3.0         5.000000   \n",
       "25            23         32.0             9.0           15.0         1.391304   \n",
       "26            22        143.0            38.0           15.0         6.500000   \n",
       "27            24         31.0             5.0           12.0         1.291667   \n",
       "28            30         14.0             9.0            7.0         0.466667   \n",
       "29            22         70.0            25.0           17.0         3.181818   \n",
       "30            34         13.0             6.0           10.0         0.382353   \n",
       "31            25        532.0           148.0           26.0        21.280000   \n",
       "32            35       2131.0          1009.0          124.0        60.885714   \n",
       "33            73        490.0           209.0           40.0         6.712329   \n",
       "34           115      14113.0          5426.0          504.0       122.721739   \n",
       "35            59        245.0           171.0           46.0         4.152542   \n",
       "36            69        472.0           185.0           67.0         6.840580   \n",
       "37            70      46522.0         11982.0         5178.0       664.600000   \n",
       "38            39      14969.0          4627.0          816.0       383.820513   \n",
       "39            47         30.0             4.0           11.0         0.638298   \n",
       "40            41        184.0           104.0           11.0         4.487805   \n",
       "41            30         36.0             9.0           10.0         1.200000   \n",
       "42            25        388.0           251.0           35.0        15.520000   \n",
       "43            19         84.0            44.0           12.0         4.421053   \n",
       "44            40         61.0             9.0           19.0         1.525000   \n",
       "45            31         39.0             7.0            8.0         1.258065   \n",
       "46            44         42.0            11.0           26.0         0.954545   \n",
       "47            24          4.0             2.0            4.0         0.166667   \n",
       "48            23        754.0           299.0           34.0        32.782609   \n",
       "49            19          7.0             1.0            7.0         0.368421   \n",
       "50            13         16.0            10.0            4.0         1.230769   \n",
       "51            20        337.0           105.0          176.0        16.850000   \n",
       "52            18          4.0             5.0            5.0         0.222222   \n",
       "53            29        237.0            35.0           25.0         8.172414   \n",
       "54            28        263.0            16.0           15.0         9.392857   \n",
       "55            24        198.0            86.0           35.0         8.250000   \n",
       "56            28         56.0            15.0            7.0         2.000000   \n",
       "57            21         83.0            26.0            9.0         3.952381   \n",
       "58            14         63.0            12.0           11.0         4.500000   \n",
       "59            16         98.0            26.0           14.0         6.125000   \n",
       "60            18         12.0             8.0            1.0         0.666667   \n",
       "61            23         49.0            11.0            6.0         2.130435   \n",
       "62            27        879.0           408.0           55.0        32.555556   \n",
       "63            16         85.0            49.0           15.0         5.312500   \n",
       "64            34         28.0            30.0           31.0         0.823529   \n",
       "65            30         62.0            12.0            8.0         2.066667   \n",
       "66            34         78.0            28.0            8.0         2.294118   \n",
       "67            23         13.0             6.0           10.0         0.565217   \n",
       "68            19         50.0            24.0           16.0         2.631579   \n",
       "69           127       1524.0           584.0           74.0        12.000000   \n",
       "70           149        431.0           194.0           74.0         2.892617   \n",
       "71           182        622.0           215.0           59.0         3.417582   \n",
       "72           123        237.0            57.0           53.0         1.926829   \n",
       "73            69        281.0           136.0           32.0         4.072464   \n",
       "74            79        113.0            42.0           28.0         1.430380   \n",
       "75            56         31.0             8.0           19.0         0.553571   \n",
       "76            79        795.0           294.0           62.0        10.063291   \n",
       "77            55         39.0             4.0           14.0         0.709091   \n",
       "78            64        108.0            28.0           12.0         1.687500   \n",
       "79            58         55.0            18.0           21.0         0.948276   \n",
       "80            54        153.0            29.0           32.0         2.833333   \n",
       "81            65       1124.0           455.0           45.0        17.292308   \n",
       "82            48         49.0             5.0           11.0         1.020833   \n",
       "83            37         41.0            11.0           10.0         1.108108   \n",
       "84            46         59.0            12.0           11.0         1.282609   \n",
       "85            60         55.0            21.0           11.0         0.916667   \n",
       "86            48         29.0             9.0           18.0         0.604167   \n",
       "87            61         54.0            13.0           17.0         0.885246   \n",
       "88            74        169.0            68.0           25.0         2.283784   \n",
       "89            84       3345.0          1538.0          203.0        39.821429   \n",
       "90            74        151.0           111.0           33.0         2.040541   \n",
       "91           109        914.0           573.0           81.0         8.385321   \n",
       "92            65        129.0            76.0           32.0         1.984615   \n",
       "93            43        103.0            28.0           20.0         2.395349   \n",
       "94            34         29.0            15.0            9.0         0.852941   \n",
       "95            39         66.0            22.0           11.0         1.692308   \n",
       "96            51         63.0            27.0           17.0         1.235294   \n",
       "97            40        286.0            85.0           31.0         7.150000   \n",
       "98            56        757.0           301.0           66.0        13.517857   \n",
       "99            35         33.0             6.0           10.0         0.942857   \n",
       "100           44       1360.0           682.0           90.0        30.909091   \n",
       "101           42        680.0           330.0           40.0        16.190476   \n",
       "102           63       4509.0          1710.0          251.0        71.571429   \n",
       "103           54       5296.0          1690.0          103.0        98.074074   \n",
       "104           45        898.0           270.0           61.0        19.955556   \n",
       "105           56        445.0           125.0           35.0         7.946429   \n",
       "106           66      12968.0          6452.0         2144.0       196.484848   \n",
       "107           40         56.0            10.0           22.0         1.400000   \n",
       "108           44        102.0            30.0           23.0         2.318182   \n",
       "109           44       1307.0           446.0           49.0        29.704545   \n",
       "110           30         28.0             5.0           11.0         0.933333   \n",
       "111           25         31.0             9.0            7.0         1.240000   \n",
       "112           18       1071.0           265.0           34.0        59.500000   \n",
       "113           20         37.0            31.0            6.0         1.850000   \n",
       "114           31         74.0            21.0            9.0         2.387097   \n",
       "115           21        117.0            53.0           14.0         5.571429   \n",
       "116           41         73.0            45.0           15.0         1.780488   \n",
       "117           59       3253.0          1941.0          424.0        55.135593   \n",
       "118           41        949.0           284.0           55.0        23.146341   \n",
       "119           30       4989.0          1505.0           90.0       166.300000   \n",
       "120           13         10.0             3.0            2.0         0.769231   \n",
       "121           19        975.0           566.0           64.0        51.315789   \n",
       "122            9          4.0             0.0            3.0         0.444444   \n",
       "123           22        145.0            38.0           16.0         6.590909   \n",
       "124           20          7.0             1.0            9.0         0.350000   \n",
       "125           16         26.0             7.0            9.0         1.625000   \n",
       "126           27         42.0            24.0            8.0         1.555556   \n",
       "127           17        605.0           161.0           51.0        35.588235   \n",
       "128           17         18.0             3.0            3.0         1.058824   \n",
       "129           28        243.0           169.0           20.0         8.678571   \n",
       "\n",
       "     m_neg_retweets_avg  m_neg_replies_avg  \n",
       "0              1.666667           0.190476  \n",
       "1             27.555556           3.555556  \n",
       "2              4.370370           4.370370  \n",
       "3            143.294118          10.607843  \n",
       "4             69.700000          24.250000  \n",
       "5              1.187500           0.583333  \n",
       "6              0.630435           0.521739  \n",
       "7              2.161290           0.612903  \n",
       "8             13.627451           2.411765  \n",
       "9              0.428571           0.380952  \n",
       "10             0.760000           0.320000  \n",
       "11             1.078947           0.473684  \n",
       "12             0.906977           0.418605  \n",
       "13             0.424242           0.393939  \n",
       "14            35.750000           3.187500  \n",
       "15             2.615385           0.589744  \n",
       "16             1.904762           0.285714  \n",
       "17             1.866667           0.866667  \n",
       "18             1.484848           1.181818  \n",
       "19             0.272727           0.590909  \n",
       "20             0.375000           0.000000  \n",
       "21             0.050000           0.200000  \n",
       "22             0.909091           0.318182  \n",
       "23             0.818182           0.545455  \n",
       "24             0.666667           1.000000  \n",
       "25             0.391304           0.652174  \n",
       "26             1.727273           0.681818  \n",
       "27             0.208333           0.500000  \n",
       "28             0.300000           0.233333  \n",
       "29             1.136364           0.772727  \n",
       "30             0.176471           0.294118  \n",
       "31             5.920000           1.040000  \n",
       "32            28.828571           3.542857  \n",
       "33             2.863014           0.547945  \n",
       "34            47.182609           4.382609  \n",
       "35             2.898305           0.779661  \n",
       "36             2.681159           0.971014  \n",
       "37           171.171429          73.971429  \n",
       "38           118.641026          20.923077  \n",
       "39             0.085106           0.234043  \n",
       "40             2.536585           0.268293  \n",
       "41             0.300000           0.333333  \n",
       "42            10.040000           1.400000  \n",
       "43             2.315789           0.631579  \n",
       "44             0.225000           0.475000  \n",
       "45             0.225806           0.258065  \n",
       "46             0.250000           0.590909  \n",
       "47             0.083333           0.166667  \n",
       "48            13.000000           1.478261  \n",
       "49             0.052632           0.368421  \n",
       "50             0.769231           0.307692  \n",
       "51             5.250000           8.800000  \n",
       "52             0.277778           0.277778  \n",
       "53             1.206897           0.862069  \n",
       "54             0.571429           0.535714  \n",
       "55             3.583333           1.458333  \n",
       "56             0.535714           0.250000  \n",
       "57             1.238095           0.428571  \n",
       "58             0.857143           0.785714  \n",
       "59             1.625000           0.875000  \n",
       "60             0.444444           0.055556  \n",
       "61             0.478261           0.260870  \n",
       "62            15.111111           2.037037  \n",
       "63             3.062500           0.937500  \n",
       "64             0.882353           0.911765  \n",
       "65             0.400000           0.266667  \n",
       "66             0.823529           0.235294  \n",
       "67             0.260870           0.434783  \n",
       "68             1.263158           0.842105  \n",
       "69             4.598425           0.582677  \n",
       "70             1.302013           0.496644  \n",
       "71             1.181319           0.324176  \n",
       "72             0.463415           0.430894  \n",
       "73             1.971014           0.463768  \n",
       "74             0.531646           0.354430  \n",
       "75             0.142857           0.339286  \n",
       "76             3.721519           0.784810  \n",
       "77             0.072727           0.254545  \n",
       "78             0.437500           0.187500  \n",
       "79             0.310345           0.362069  \n",
       "80             0.537037           0.592593  \n",
       "81             7.000000           0.692308  \n",
       "82             0.104167           0.229167  \n",
       "83             0.297297           0.270270  \n",
       "84             0.260870           0.239130  \n",
       "85             0.350000           0.183333  \n",
       "86             0.187500           0.375000  \n",
       "87             0.213115           0.278689  \n",
       "88             0.918919           0.337838  \n",
       "89            18.309524           2.416667  \n",
       "90             1.500000           0.445946  \n",
       "91             5.256881           0.743119  \n",
       "92             1.169231           0.492308  \n",
       "93             0.651163           0.465116  \n",
       "94             0.441176           0.264706  \n",
       "95             0.564103           0.282051  \n",
       "96             0.529412           0.333333  \n",
       "97             2.125000           0.775000  \n",
       "98             5.375000           1.178571  \n",
       "99             0.171429           0.285714  \n",
       "100           15.500000           2.045455  \n",
       "101            7.857143           0.952381  \n",
       "102           27.142857           3.984127  \n",
       "103           31.296296           1.907407  \n",
       "104            6.000000           1.355556  \n",
       "105            2.232143           0.625000  \n",
       "106           97.757576          32.484848  \n",
       "107            0.250000           0.550000  \n",
       "108            0.681818           0.522727  \n",
       "109           10.136364           1.113636  \n",
       "110            0.166667           0.366667  \n",
       "111            0.360000           0.280000  \n",
       "112           14.722222           1.888889  \n",
       "113            1.550000           0.300000  \n",
       "114            0.677419           0.290323  \n",
       "115            2.523810           0.666667  \n",
       "116            1.097561           0.365854  \n",
       "117           32.898305           7.186441  \n",
       "118            6.926829           1.341463  \n",
       "119           50.166667           3.000000  \n",
       "120            0.230769           0.153846  \n",
       "121           29.789474           3.368421  \n",
       "122            0.000000           0.333333  \n",
       "123            1.727273           0.727273  \n",
       "124            0.050000           0.450000  \n",
       "125            0.437500           0.562500  \n",
       "126            0.888889           0.296296  \n",
       "127            9.470588           3.000000  \n",
       "128            0.176471           0.176471  \n",
       "129            6.035714           0.714286  \n",
       "\n",
       "[130 rows x 29 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def twint_search(since, until, csv_name, username):\n",
    "    c = twint.Config()\n",
    "    c.Utc = True\n",
    "    c.Full_text = True\n",
    "    c.Since = since\n",
    "    c.Until = until\n",
    "    c.Username = username\n",
    "    c.Count = True\n",
    "    c.Lang = \"en\"\n",
    "    c.Hide_output = True\n",
    "    c.Store_csv = True\n",
    "    c.Output = csv_name\n",
    "    c.Debug = True\n",
    "    \n",
    "    twint.run.Search(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_scraper(since, until, username):\n",
    "    \n",
    "    dirname = \"C:\\\\Users\\\\rahul\\\\News channels data\\\\%s\"%username\n",
    "    try:\n",
    "        mkdir(dirname)\n",
    "        print(\"Directory\", dirname, \"created\")\n",
    "    except FileExistsError:\n",
    "        print(\"Directory\", dirname, \"exists\")\n",
    "    \n",
    "    daterange = pd.date_range(since, until)\n",
    "    for start_date in daterange:\n",
    "        since = start_date.strftime(\"%Y-%m-%d\")\n",
    "        until = (start_date + timedelta(1)).strftime(\"%Y-%m-%d\")\n",
    "        \n",
    "        \n",
    "        print(\"Getting data for %s\"%since)\n",
    "        csv_name = \"%s.csv\"%since\n",
    "        csv_name = path.join(dirname, csv_name)\n",
    "        \n",
    "        twint_search(since, until, csv_name, username)\n",
    "        \n",
    "        time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory C:\\Users\\rahul\\News channels data\\indiatoday created\n",
      "Getting data for 2020-01-22\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 201 Tweets from @indiatoday.\n",
      "Getting data for 2020-01-23\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 208 Tweets from @indiatoday.\n",
      "Getting data for 2020-01-24\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 237 Tweets from @indiatoday.\n",
      "Getting data for 2020-01-25\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 178 Tweets from @indiatoday.\n",
      "Getting data for 2020-01-26\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 167 Tweets from @indiatoday.\n",
      "Getting data for 2020-01-27\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 249 Tweets from @indiatoday.\n",
      "Getting data for 2020-01-28\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 197 Tweets from @indiatoday.\n",
      "Getting data for 2020-01-29\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 214 Tweets from @indiatoday.\n",
      "Getting data for 2020-01-30\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 228 Tweets from @indiatoday.\n",
      "Getting data for 2020-01-31\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 235 Tweets from @indiatoday.\n",
      "Getting data for 2020-02-01\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 292 Tweets from @indiatoday.\n",
      "Getting data for 2020-02-02\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 177 Tweets from @indiatoday.\n",
      "Getting data for 2020-02-03\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 264 Tweets from @indiatoday.\n",
      "Getting data for 2020-02-04\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 217 Tweets from @indiatoday.\n",
      "Getting data for 2020-02-05\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 235 Tweets from @indiatoday.\n",
      "Getting data for 2020-02-06\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 260 Tweets from @indiatoday.\n",
      "Getting data for 2020-02-07\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 228 Tweets from @indiatoday.\n",
      "Getting data for 2020-02-08\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 247 Tweets from @indiatoday.\n",
      "Getting data for 2020-02-09\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 164 Tweets from @indiatoday.\n",
      "Getting data for 2020-02-10\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 226 Tweets from @indiatoday.\n",
      "Getting data for 2020-02-11\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 382 Tweets from @indiatoday.\n",
      "Getting data for 2020-02-12\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 206 Tweets from @indiatoday.\n",
      "Getting data for 2020-02-13\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 286 Tweets from @indiatoday.\n",
      "Getting data for 2020-02-14\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 193 Tweets from @indiatoday.\n",
      "Getting data for 2020-02-15\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 204 Tweets from @indiatoday.\n",
      "Getting data for 2020-02-16\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 165 Tweets from @indiatoday.\n",
      "Getting data for 2020-02-17\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 224 Tweets from @indiatoday.\n",
      "Getting data for 2020-02-18\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 202 Tweets from @indiatoday.\n",
      "Getting data for 2020-02-19\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 243 Tweets from @indiatoday.\n",
      "Getting data for 2020-02-20\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 233 Tweets from @indiatoday.\n",
      "Getting data for 2020-02-21\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 265 Tweets from @indiatoday.\n",
      "Getting data for 2020-02-22\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 188 Tweets from @indiatoday.\n",
      "Getting data for 2020-02-23\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 165 Tweets from @indiatoday.\n",
      "Getting data for 2020-02-24\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 286 Tweets from @indiatoday.\n",
      "Getting data for 2020-02-25\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 269 Tweets from @indiatoday.\n",
      "Getting data for 2020-02-26\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 266 Tweets from @indiatoday.\n",
      "Getting data for 2020-02-27\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 253 Tweets from @indiatoday.\n",
      "Getting data for 2020-02-28\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 229 Tweets from @indiatoday.\n",
      "Getting data for 2020-02-29\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 142 Tweets from @indiatoday.\n",
      "Getting data for 2020-03-01\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 143 Tweets from @indiatoday.\n",
      "Getting data for 2020-03-02\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 253 Tweets from @indiatoday.\n",
      "Getting data for 2020-03-03\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 294 Tweets from @indiatoday.\n",
      "Getting data for 2020-03-04\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 282 Tweets from @indiatoday.\n",
      "Getting data for 2020-03-05\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 276 Tweets from @indiatoday.\n",
      "Getting data for 2020-03-06\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 308 Tweets from @indiatoday.\n",
      "Getting data for 2020-03-07\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 208 Tweets from @indiatoday.\n",
      "Getting data for 2020-03-08\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 167 Tweets from @indiatoday.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting data for 2020-03-09\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 243 Tweets from @indiatoday.\n",
      "Getting data for 2020-03-10\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 140 Tweets from @indiatoday.\n",
      "Getting data for 2020-03-11\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 270 Tweets from @indiatoday.\n",
      "Getting data for 2020-03-12\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 245 Tweets from @indiatoday.\n",
      "Getting data for 2020-03-13\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 264 Tweets from @indiatoday.\n",
      "Getting data for 2020-03-14\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 274 Tweets from @indiatoday.\n",
      "Getting data for 2020-03-15\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 167 Tweets from @indiatoday.\n",
      "Getting data for 2020-03-16\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 254 Tweets from @indiatoday.\n",
      "Getting data for 2020-03-17\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 329 Tweets from @indiatoday.\n",
      "Getting data for 2020-03-18\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 346 Tweets from @indiatoday.\n",
      "Getting data for 2020-03-19\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 304 Tweets from @indiatoday.\n",
      "Getting data for 2020-03-20\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 303 Tweets from @indiatoday.\n",
      "Getting data for 2020-03-21\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 274 Tweets from @indiatoday.\n",
      "Getting data for 2020-03-22\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 240 Tweets from @indiatoday.\n",
      "Getting data for 2020-03-23\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 264 Tweets from @indiatoday.\n",
      "Getting data for 2020-03-24\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 334 Tweets from @indiatoday.\n",
      "Getting data for 2020-03-25\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 282 Tweets from @indiatoday.\n",
      "Getting data for 2020-03-26\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 253 Tweets from @indiatoday.\n",
      "Getting data for 2020-03-27\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 309 Tweets from @indiatoday.\n",
      "Getting data for 2020-03-28\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 210 Tweets from @indiatoday.\n",
      "Getting data for 2020-03-29\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 243 Tweets from @indiatoday.\n",
      "Getting data for 2020-03-30\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 319 Tweets from @indiatoday.\n",
      "Getting data for 2020-03-31\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 280 Tweets from @indiatoday.\n",
      "Getting data for 2020-04-01\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 326 Tweets from @indiatoday.\n",
      "Getting data for 2020-04-02\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 299 Tweets from @indiatoday.\n",
      "Getting data for 2020-04-03\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 315 Tweets from @indiatoday.\n",
      "Getting data for 2020-04-04\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 244 Tweets from @indiatoday.\n",
      "Getting data for 2020-04-05\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 204 Tweets from @indiatoday.\n",
      "Getting data for 2020-04-06\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 297 Tweets from @indiatoday.\n",
      "Getting data for 2020-04-07\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 322 Tweets from @indiatoday.\n",
      "Getting data for 2020-04-08\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 342 Tweets from @indiatoday.\n",
      "Getting data for 2020-04-09\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 304 Tweets from @indiatoday.\n",
      "Getting data for 2020-04-10\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 309 Tweets from @indiatoday.\n",
      "Getting data for 2020-04-11\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 229 Tweets from @indiatoday.\n",
      "Getting data for 2020-04-12\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 215 Tweets from @indiatoday.\n",
      "Getting data for 2020-04-13\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 305 Tweets from @indiatoday.\n",
      "Getting data for 2020-04-14\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 316 Tweets from @indiatoday.\n",
      "Getting data for 2020-04-15\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 273 Tweets from @indiatoday.\n",
      "Getting data for 2020-04-16\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 297 Tweets from @indiatoday.\n",
      "Getting data for 2020-04-17\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 316 Tweets from @indiatoday.\n",
      "Getting data for 2020-04-18\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 271 Tweets from @indiatoday.\n",
      "Getting data for 2020-04-19\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 225 Tweets from @indiatoday.\n",
      "Getting data for 2020-04-20\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 327 Tweets from @indiatoday.\n",
      "Getting data for 2020-04-21\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 288 Tweets from @indiatoday.\n",
      "Getting data for 2020-04-22\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 273 Tweets from @indiatoday.\n",
      "Getting data for 2020-04-23\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 272 Tweets from @indiatoday.\n",
      "Getting data for 2020-04-24\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 346 Tweets from @indiatoday.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting data for 2020-04-25\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 246 Tweets from @indiatoday.\n",
      "Getting data for 2020-04-26\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 256 Tweets from @indiatoday.\n",
      "Getting data for 2020-04-27\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 313 Tweets from @indiatoday.\n",
      "Getting data for 2020-04-28\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 310 Tweets from @indiatoday.\n",
      "Getting data for 2020-04-29\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 306 Tweets from @indiatoday.\n",
      "Getting data for 2020-04-30\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 325 Tweets from @indiatoday.\n",
      "Getting data for 2020-05-01\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 342 Tweets from @indiatoday.\n",
      "Getting data for 2020-05-02\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 275 Tweets from @indiatoday.\n",
      "Getting data for 2020-05-03\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 222 Tweets from @indiatoday.\n",
      "Getting data for 2020-05-04\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 315 Tweets from @indiatoday.\n",
      "Getting data for 2020-05-05\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 292 Tweets from @indiatoday.\n",
      "Getting data for 2020-05-06\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 274 Tweets from @indiatoday.\n",
      "Getting data for 2020-05-07\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 309 Tweets from @indiatoday.\n",
      "Getting data for 2020-05-08\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 362 Tweets from @indiatoday.\n",
      "Getting data for 2020-05-09\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 261 Tweets from @indiatoday.\n",
      "Getting data for 2020-05-10\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 211 Tweets from @indiatoday.\n",
      "Getting data for 2020-05-11\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 330 Tweets from @indiatoday.\n",
      "Getting data for 2020-05-12\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 296 Tweets from @indiatoday.\n",
      "Getting data for 2020-05-13\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 358 Tweets from @indiatoday.\n",
      "Getting data for 2020-05-14\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 323 Tweets from @indiatoday.\n",
      "Getting data for 2020-05-15\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 322 Tweets from @indiatoday.\n",
      "Getting data for 2020-05-16\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 190 Tweets from @indiatoday.\n",
      "Getting data for 2020-05-17\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 221 Tweets from @indiatoday.\n",
      "Getting data for 2020-05-18\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 313 Tweets from @indiatoday.\n",
      "Getting data for 2020-05-19\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 299 Tweets from @indiatoday.\n",
      "Getting data for 2020-05-20\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 258 Tweets from @indiatoday.\n",
      "Getting data for 2020-05-21\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 272 Tweets from @indiatoday.\n",
      "Getting data for 2020-05-22\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 264 Tweets from @indiatoday.\n",
      "Getting data for 2020-05-23\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 226 Tweets from @indiatoday.\n",
      "Getting data for 2020-05-24\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 165 Tweets from @indiatoday.\n",
      "Getting data for 2020-05-25\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 296 Tweets from @indiatoday.\n",
      "Getting data for 2020-05-26\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 324 Tweets from @indiatoday.\n",
      "Getting data for 2020-05-27\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 274 Tweets from @indiatoday.\n",
      "Getting data for 2020-05-28\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 285 Tweets from @indiatoday.\n",
      "Getting data for 2020-05-29\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 279 Tweets from @indiatoday.\n",
      "Getting data for 2020-05-30\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 247 Tweets from @indiatoday.\n",
      "time taken: 26.41 mins\n",
      "Directory C:\\Users\\rahul\\News channels data\\ndtv created\n",
      "Getting data for 2020-01-22\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 215 Tweets from @ndtv.\n",
      "Getting data for 2020-01-23\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 200 Tweets from @ndtv.\n",
      "Getting data for 2020-01-24\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 208 Tweets from @ndtv.\n",
      "Getting data for 2020-01-25\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 199 Tweets from @ndtv.\n",
      "Getting data for 2020-01-26\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 221 Tweets from @ndtv.\n",
      "Getting data for 2020-01-27\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 172 Tweets from @ndtv.\n",
      "Getting data for 2020-01-28\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 222 Tweets from @ndtv.\n",
      "Getting data for 2020-01-29\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 203 Tweets from @ndtv.\n",
      "Getting data for 2020-01-30\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 216 Tweets from @ndtv.\n",
      "Getting data for 2020-01-31\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 244 Tweets from @ndtv.\n",
      "Getting data for 2020-02-01\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 377 Tweets from @ndtv.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting data for 2020-02-02\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 153 Tweets from @ndtv.\n",
      "Getting data for 2020-02-03\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 218 Tweets from @ndtv.\n",
      "Getting data for 2020-02-04\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 247 Tweets from @ndtv.\n",
      "Getting data for 2020-02-05\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 301 Tweets from @ndtv.\n",
      "Getting data for 2020-02-06\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 208 Tweets from @ndtv.\n",
      "Getting data for 2020-02-07\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 216 Tweets from @ndtv.\n",
      "Getting data for 2020-02-08\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 289 Tweets from @ndtv.\n",
      "Getting data for 2020-02-09\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 136 Tweets from @ndtv.\n",
      "Getting data for 2020-02-10\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 159 Tweets from @ndtv.\n",
      "Getting data for 2020-02-11\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 400 Tweets from @ndtv.\n",
      "Getting data for 2020-02-12\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 179 Tweets from @ndtv.\n",
      "Getting data for 2020-02-13\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 205 Tweets from @ndtv.\n",
      "Getting data for 2020-02-14\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 177 Tweets from @ndtv.\n",
      "Getting data for 2020-02-15\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 129 Tweets from @ndtv.\n",
      "Getting data for 2020-02-16\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 187 Tweets from @ndtv.\n",
      "Getting data for 2020-02-17\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 171 Tweets from @ndtv.\n",
      "Getting data for 2020-02-18\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 177 Tweets from @ndtv.\n",
      "Getting data for 2020-02-19\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 176 Tweets from @ndtv.\n",
      "Getting data for 2020-02-20\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 178 Tweets from @ndtv.\n",
      "Getting data for 2020-02-21\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 172 Tweets from @ndtv.\n",
      "Getting data for 2020-02-22\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 132 Tweets from @ndtv.\n",
      "Getting data for 2020-02-23\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 147 Tweets from @ndtv.\n",
      "Getting data for 2020-02-24\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 334 Tweets from @ndtv.\n",
      "Getting data for 2020-02-25\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 379 Tweets from @ndtv.\n",
      "Getting data for 2020-02-26\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 246 Tweets from @ndtv.\n",
      "Getting data for 2020-02-27\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 206 Tweets from @ndtv.\n",
      "Getting data for 2020-02-28\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 211 Tweets from @ndtv.\n",
      "Getting data for 2020-02-29\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 145 Tweets from @ndtv.\n",
      "Getting data for 2020-03-01\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 133 Tweets from @ndtv.\n",
      "Getting data for 2020-03-02\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 212 Tweets from @ndtv.\n",
      "Getting data for 2020-03-03\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 244 Tweets from @ndtv.\n",
      "Getting data for 2020-03-04\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 230 Tweets from @ndtv.\n",
      "Getting data for 2020-03-05\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 243 Tweets from @ndtv.\n",
      "Getting data for 2020-03-06\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 214 Tweets from @ndtv.\n",
      "Getting data for 2020-03-07\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 159 Tweets from @ndtv.\n",
      "Getting data for 2020-03-08\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 146 Tweets from @ndtv.\n",
      "Getting data for 2020-03-09\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 209 Tweets from @ndtv.\n",
      "Getting data for 2020-03-10\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 189 Tweets from @ndtv.\n",
      "Getting data for 2020-03-11\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 263 Tweets from @ndtv.\n",
      "Getting data for 2020-03-12\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 304 Tweets from @ndtv.\n",
      "Getting data for 2020-03-13\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 264 Tweets from @ndtv.\n",
      "Getting data for 2020-03-14\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 138 Tweets from @ndtv.\n",
      "Getting data for 2020-03-15\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 126 Tweets from @ndtv.\n",
      "Getting data for 2020-03-16\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 239 Tweets from @ndtv.\n",
      "Getting data for 2020-03-17\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 248 Tweets from @ndtv.\n",
      "Getting data for 2020-03-18\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 204 Tweets from @ndtv.\n",
      "Getting data for 2020-03-19\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 229 Tweets from @ndtv.\n",
      "Getting data for 2020-03-20\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 229 Tweets from @ndtv.\n",
      "Getting data for 2020-03-21\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 144 Tweets from @ndtv.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting data for 2020-03-22\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 227 Tweets from @ndtv.\n",
      "Getting data for 2020-03-23\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 247 Tweets from @ndtv.\n",
      "Getting data for 2020-03-24\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 299 Tweets from @ndtv.\n",
      "Getting data for 2020-03-25\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 256 Tweets from @ndtv.\n",
      "Getting data for 2020-03-26\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 201 Tweets from @ndtv.\n",
      "Getting data for 2020-03-27\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 233 Tweets from @ndtv.\n",
      "Getting data for 2020-03-28\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 144 Tweets from @ndtv.\n",
      "Getting data for 2020-03-29\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 145 Tweets from @ndtv.\n",
      "Getting data for 2020-03-30\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 200 Tweets from @ndtv.\n",
      "Getting data for 2020-03-31\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 205 Tweets from @ndtv.\n",
      "Getting data for 2020-04-01\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 220 Tweets from @ndtv.\n",
      "Getting data for 2020-04-02\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 232 Tweets from @ndtv.\n",
      "Getting data for 2020-04-03\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 226 Tweets from @ndtv.\n",
      "Getting data for 2020-04-04\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 153 Tweets from @ndtv.\n",
      "Getting data for 2020-04-05\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 205 Tweets from @ndtv.\n",
      "Getting data for 2020-04-06\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 215 Tweets from @ndtv.\n",
      "Getting data for 2020-04-07\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 184 Tweets from @ndtv.\n",
      "Getting data for 2020-04-08\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 214 Tweets from @ndtv.\n",
      "Getting data for 2020-04-09\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 231 Tweets from @ndtv.\n",
      "Getting data for 2020-04-10\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 258 Tweets from @ndtv.\n",
      "Getting data for 2020-04-11\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 188 Tweets from @ndtv.\n",
      "Getting data for 2020-04-12\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 255 Tweets from @ndtv.\n",
      "Getting data for 2020-04-13\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 239 Tweets from @ndtv.\n",
      "Getting data for 2020-04-14\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 281 Tweets from @ndtv.\n",
      "Getting data for 2020-04-15\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 252 Tweets from @ndtv.\n",
      "Getting data for 2020-04-16\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 266 Tweets from @ndtv.\n",
      "Getting data for 2020-04-17\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 377 Tweets from @ndtv.\n",
      "Getting data for 2020-04-18\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 184 Tweets from @ndtv.\n",
      "Getting data for 2020-04-19\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 192 Tweets from @ndtv.\n",
      "Getting data for 2020-04-20\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 228 Tweets from @ndtv.\n",
      "Getting data for 2020-04-21\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 238 Tweets from @ndtv.\n",
      "Getting data for 2020-04-22\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 245 Tweets from @ndtv.\n",
      "Getting data for 2020-04-23\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 236 Tweets from @ndtv.\n",
      "Getting data for 2020-04-24\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 275 Tweets from @ndtv.\n",
      "Getting data for 2020-04-25\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 168 Tweets from @ndtv.\n",
      "Getting data for 2020-04-26\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 247 Tweets from @ndtv.\n",
      "Getting data for 2020-04-27\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 255 Tweets from @ndtv.\n",
      "Getting data for 2020-04-28\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 289 Tweets from @ndtv.\n",
      "Getting data for 2020-04-29\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 249 Tweets from @ndtv.\n",
      "Getting data for 2020-04-30\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 230 Tweets from @ndtv.\n",
      "Getting data for 2020-05-01\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 235 Tweets from @ndtv.\n",
      "Getting data for 2020-05-02\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 199 Tweets from @ndtv.\n",
      "Getting data for 2020-05-03\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 174 Tweets from @ndtv.\n",
      "Getting data for 2020-05-04\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 265 Tweets from @ndtv.\n",
      "Getting data for 2020-05-05\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 240 Tweets from @ndtv.\n",
      "Getting data for 2020-05-06\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 245 Tweets from @ndtv.\n",
      "Getting data for 2020-05-07\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 296 Tweets from @ndtv.\n",
      "Getting data for 2020-05-08\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 342 Tweets from @ndtv.\n",
      "Getting data for 2020-05-09\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 149 Tweets from @ndtv.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting data for 2020-05-10\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 245 Tweets from @ndtv.\n",
      "Getting data for 2020-05-11\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 240 Tweets from @ndtv.\n",
      "Getting data for 2020-05-12\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 294 Tweets from @ndtv.\n",
      "Getting data for 2020-05-13\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 300 Tweets from @ndtv.\n",
      "Getting data for 2020-05-14\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 305 Tweets from @ndtv.\n",
      "Getting data for 2020-05-15\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 259 Tweets from @ndtv.\n",
      "Getting data for 2020-05-16\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 199 Tweets from @ndtv.\n",
      "Getting data for 2020-05-17\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 300 Tweets from @ndtv.\n",
      "Getting data for 2020-05-18\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 290 Tweets from @ndtv.\n",
      "Getting data for 2020-05-19\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 236 Tweets from @ndtv.\n",
      "Getting data for 2020-05-20\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 242 Tweets from @ndtv.\n",
      "Getting data for 2020-05-21\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 228 Tweets from @ndtv.\n",
      "Getting data for 2020-05-22\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 291 Tweets from @ndtv.\n",
      "Getting data for 2020-05-23\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 183 Tweets from @ndtv.\n",
      "Getting data for 2020-05-24\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 243 Tweets from @ndtv.\n",
      "Getting data for 2020-05-25\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 207 Tweets from @ndtv.\n",
      "Getting data for 2020-05-26\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 205 Tweets from @ndtv.\n",
      "Getting data for 2020-05-27\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 244 Tweets from @ndtv.\n",
      "Getting data for 2020-05-28\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 176 Tweets from @ndtv.\n",
      "Getting data for 2020-05-29\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 224 Tweets from @ndtv.\n",
      "Getting data for 2020-05-30\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 161 Tweets from @ndtv.\n",
      "time taken: 24.4 mins\n",
      "Directory C:\\Users\\rahul\\News channels data\\newsx created\n",
      "Getting data for 2020-01-22\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 9 Tweets from @newsx.\n",
      "Getting data for 2020-01-23\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 81 Tweets from @newsx.\n",
      "Getting data for 2020-01-24\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 4 Tweets from @newsx.\n",
      "Getting data for 2020-01-25\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 4 Tweets from @newsx.\n",
      "Getting data for 2020-01-26\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @newsx.\n",
      "Getting data for 2020-01-27\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 5 Tweets from @newsx.\n",
      "Getting data for 2020-01-28\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 11 Tweets from @newsx.\n",
      "Getting data for 2020-01-29\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 12 Tweets from @newsx.\n",
      "Getting data for 2020-01-30\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 17 Tweets from @newsx.\n",
      "Getting data for 2020-01-31\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 12 Tweets from @newsx.\n",
      "Getting data for 2020-02-01\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 32 Tweets from @newsx.\n",
      "Getting data for 2020-02-02\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 6 Tweets from @newsx.\n",
      "Getting data for 2020-02-03\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 10 Tweets from @newsx.\n",
      "Getting data for 2020-02-04\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 9 Tweets from @newsx.\n",
      "Getting data for 2020-02-05\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 5 Tweets from @newsx.\n",
      "Getting data for 2020-02-06\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 13 Tweets from @newsx.\n",
      "Getting data for 2020-02-07\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 15 Tweets from @newsx.\n",
      "Getting data for 2020-02-08\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 13 Tweets from @newsx.\n",
      "Getting data for 2020-02-09\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 8 Tweets from @newsx.\n",
      "Getting data for 2020-02-10\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 13 Tweets from @newsx.\n",
      "Getting data for 2020-02-11\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 56 Tweets from @newsx.\n",
      "Getting data for 2020-02-12\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 13 Tweets from @newsx.\n",
      "Getting data for 2020-02-13\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 20 Tweets from @newsx.\n",
      "Getting data for 2020-02-14\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 17 Tweets from @newsx.\n",
      "Getting data for 2020-02-15\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 30 Tweets from @newsx.\n",
      "Getting data for 2020-02-16\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 6 Tweets from @newsx.\n",
      "Getting data for 2020-02-17\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 18 Tweets from @newsx.\n",
      "Getting data for 2020-02-18\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 21 Tweets from @newsx.\n",
      "Getting data for 2020-02-19\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 12 Tweets from @newsx.\n",
      "Getting data for 2020-02-20\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 16 Tweets from @newsx.\n",
      "Getting data for 2020-02-21\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 22 Tweets from @newsx.\n",
      "Getting data for 2020-02-22\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 15 Tweets from @newsx.\n",
      "Getting data for 2020-02-23\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 7 Tweets from @newsx.\n",
      "Getting data for 2020-02-24\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 20 Tweets from @newsx.\n",
      "Getting data for 2020-02-25\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 26 Tweets from @newsx.\n",
      "Getting data for 2020-02-26\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 21 Tweets from @newsx.\n",
      "Getting data for 2020-02-27\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 12 Tweets from @newsx.\n",
      "Getting data for 2020-02-28\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 16 Tweets from @newsx.\n",
      "Getting data for 2020-02-29\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 22 Tweets from @newsx.\n",
      "Getting data for 2020-03-01\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 23 Tweets from @newsx.\n",
      "Getting data for 2020-03-02\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 32 Tweets from @newsx.\n",
      "Getting data for 2020-03-03\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 26 Tweets from @newsx.\n",
      "Getting data for 2020-03-04\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 28 Tweets from @newsx.\n",
      "Getting data for 2020-03-05\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 21 Tweets from @newsx.\n",
      "Getting data for 2020-03-06\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 18 Tweets from @newsx.\n",
      "Getting data for 2020-03-07\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 18 Tweets from @newsx.\n",
      "Getting data for 2020-03-08\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 12 Tweets from @newsx.\n",
      "Getting data for 2020-03-09\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 17 Tweets from @newsx.\n",
      "Getting data for 2020-03-10\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 6 Tweets from @newsx.\n",
      "Getting data for 2020-03-11\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 17 Tweets from @newsx.\n",
      "Getting data for 2020-03-12\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 15 Tweets from @newsx.\n",
      "Getting data for 2020-03-13\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 22 Tweets from @newsx.\n",
      "Getting data for 2020-03-14\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 7 Tweets from @newsx.\n",
      "Getting data for 2020-03-15\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 10 Tweets from @newsx.\n",
      "Getting data for 2020-03-16\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 16 Tweets from @newsx.\n",
      "Getting data for 2020-03-17\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 12 Tweets from @newsx.\n",
      "Getting data for 2020-03-18\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 18 Tweets from @newsx.\n",
      "Getting data for 2020-03-19\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 21 Tweets from @newsx.\n",
      "Getting data for 2020-03-20\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 19 Tweets from @newsx.\n",
      "Getting data for 2020-03-21\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 12 Tweets from @newsx.\n",
      "Getting data for 2020-03-22\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 13 Tweets from @newsx.\n",
      "Getting data for 2020-03-23\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 32 Tweets from @newsx.\n",
      "Getting data for 2020-03-24\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 21 Tweets from @newsx.\n",
      "Getting data for 2020-03-25\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 15 Tweets from @newsx.\n",
      "Getting data for 2020-03-26\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 42 Tweets from @newsx.\n",
      "Getting data for 2020-03-27\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 29 Tweets from @newsx.\n",
      "Getting data for 2020-03-28\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 26 Tweets from @newsx.\n",
      "Getting data for 2020-03-29\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 27 Tweets from @newsx.\n",
      "Getting data for 2020-03-30\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 27 Tweets from @newsx.\n",
      "Getting data for 2020-03-31\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 15 Tweets from @newsx.\n",
      "Getting data for 2020-04-01\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 30 Tweets from @newsx.\n",
      "Getting data for 2020-04-02\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 19 Tweets from @newsx.\n",
      "Getting data for 2020-04-03\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 26 Tweets from @newsx.\n",
      "Getting data for 2020-04-04\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 21 Tweets from @newsx.\n",
      "Getting data for 2020-04-05\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 48 Tweets from @newsx.\n",
      "Getting data for 2020-04-06\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 31 Tweets from @newsx.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting data for 2020-04-07\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 26 Tweets from @newsx.\n",
      "Getting data for 2020-04-08\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 23 Tweets from @newsx.\n",
      "Getting data for 2020-04-09\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 23 Tweets from @newsx.\n",
      "Getting data for 2020-04-10\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 28 Tweets from @newsx.\n",
      "Getting data for 2020-04-11\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 16 Tweets from @newsx.\n",
      "Getting data for 2020-04-12\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 18 Tweets from @newsx.\n",
      "Getting data for 2020-04-13\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 26 Tweets from @newsx.\n",
      "Getting data for 2020-04-14\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 25 Tweets from @newsx.\n",
      "Getting data for 2020-04-15\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 15 Tweets from @newsx.\n",
      "Getting data for 2020-04-16\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 22 Tweets from @newsx.\n",
      "Getting data for 2020-04-17\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 19 Tweets from @newsx.\n",
      "Getting data for 2020-04-18\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 14 Tweets from @newsx.\n",
      "Getting data for 2020-04-19\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 19 Tweets from @newsx.\n",
      "Getting data for 2020-04-20\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 22 Tweets from @newsx.\n",
      "Getting data for 2020-04-21\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 29 Tweets from @newsx.\n",
      "Getting data for 2020-04-22\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 13 Tweets from @newsx.\n",
      "Getting data for 2020-04-23\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 30 Tweets from @newsx.\n",
      "Getting data for 2020-04-24\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 85 Tweets from @newsx.\n",
      "Getting data for 2020-04-25\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 63 Tweets from @newsx.\n",
      "Getting data for 2020-04-26\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 34 Tweets from @newsx.\n",
      "Getting data for 2020-04-27\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 110 Tweets from @newsx.\n",
      "Getting data for 2020-04-28\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 118 Tweets from @newsx.\n",
      "Getting data for 2020-04-29\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 94 Tweets from @newsx.\n",
      "Getting data for 2020-04-30\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 78 Tweets from @newsx.\n",
      "Getting data for 2020-05-01\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 85 Tweets from @newsx.\n",
      "Getting data for 2020-05-02\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 56 Tweets from @newsx.\n",
      "Getting data for 2020-05-03\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 33 Tweets from @newsx.\n",
      "Getting data for 2020-05-04\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 81 Tweets from @newsx.\n",
      "Getting data for 2020-05-05\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 110 Tweets from @newsx.\n",
      "Getting data for 2020-05-06\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 98 Tweets from @newsx.\n",
      "Getting data for 2020-05-07\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 93 Tweets from @newsx.\n",
      "Getting data for 2020-05-08\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 109 Tweets from @newsx.\n",
      "Getting data for 2020-05-09\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 74 Tweets from @newsx.\n",
      "Getting data for 2020-05-10\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 79 Tweets from @newsx.\n",
      "Getting data for 2020-05-11\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 71 Tweets from @newsx.\n",
      "Getting data for 2020-05-12\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 100 Tweets from @newsx.\n",
      "Getting data for 2020-05-13\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 102 Tweets from @newsx.\n",
      "Getting data for 2020-05-14\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 99 Tweets from @newsx.\n",
      "Getting data for 2020-05-15\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 92 Tweets from @newsx.\n",
      "Getting data for 2020-05-16\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 91 Tweets from @newsx.\n",
      "Getting data for 2020-05-17\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 70 Tweets from @newsx.\n",
      "Getting data for 2020-05-18\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 63 Tweets from @newsx.\n",
      "Getting data for 2020-05-19\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 60 Tweets from @newsx.\n",
      "Getting data for 2020-05-20\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 59 Tweets from @newsx.\n",
      "Getting data for 2020-05-21\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 51 Tweets from @newsx.\n",
      "Getting data for 2020-05-22\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 78 Tweets from @newsx.\n",
      "Getting data for 2020-05-23\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 85 Tweets from @newsx.\n",
      "Getting data for 2020-05-24\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 61 Tweets from @newsx.\n",
      "Getting data for 2020-05-25\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 66 Tweets from @newsx.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting data for 2020-05-26\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 61 Tweets from @newsx.\n",
      "Getting data for 2020-05-27\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 52 Tweets from @newsx.\n",
      "Getting data for 2020-05-28\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 53 Tweets from @newsx.\n",
      "Getting data for 2020-05-29\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 99 Tweets from @newsx.\n",
      "Getting data for 2020-05-30\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 88 Tweets from @newsx.\n",
      "time taken: 14.86 mins\n",
      "Directory C:\\Users\\rahul\\News channels data\\TIMESNOW created\n",
      "Getting data for 2020-01-22\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 445 Tweets from @TIMESNOW.\n",
      "Getting data for 2020-01-23\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 388 Tweets from @TIMESNOW.\n",
      "Getting data for 2020-01-24\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 418 Tweets from @TIMESNOW.\n",
      "Getting data for 2020-01-25\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 325 Tweets from @TIMESNOW.\n",
      "Getting data for 2020-01-26\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 301 Tweets from @TIMESNOW.\n",
      "Getting data for 2020-01-27\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 367 Tweets from @TIMESNOW.\n",
      "Getting data for 2020-01-28\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 370 Tweets from @TIMESNOW.\n",
      "Getting data for 2020-01-29\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 379 Tweets from @TIMESNOW.\n",
      "Getting data for 2020-01-30\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 393 Tweets from @TIMESNOW.\n",
      "Getting data for 2020-01-31\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 382 Tweets from @TIMESNOW.\n",
      "Getting data for 2020-02-01\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 817 Tweets from @TIMESNOW.\n",
      "Getting data for 2020-02-02\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 285 Tweets from @TIMESNOW.\n",
      "Getting data for 2020-02-03\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 380 Tweets from @TIMESNOW.\n",
      "Getting data for 2020-02-04\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 378 Tweets from @TIMESNOW.\n",
      "Getting data for 2020-02-05\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 360 Tweets from @TIMESNOW.\n",
      "Getting data for 2020-02-06\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 476 Tweets from @TIMESNOW.\n",
      "Getting data for 2020-02-07\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 447 Tweets from @TIMESNOW.\n",
      "Getting data for 2020-02-08\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 441 Tweets from @TIMESNOW.\n",
      "Getting data for 2020-02-09\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 248 Tweets from @TIMESNOW.\n",
      "Getting data for 2020-02-10\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 485 Tweets from @TIMESNOW.\n",
      "Getting data for 2020-02-11\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 655 Tweets from @TIMESNOW.\n",
      "Getting data for 2020-02-12\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 561 Tweets from @TIMESNOW.\n",
      "Getting data for 2020-02-13\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 617 Tweets from @TIMESNOW.\n",
      "Getting data for 2020-02-14\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 308 Tweets from @TIMESNOW.\n",
      "Getting data for 2020-02-15\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 146 Tweets from @TIMESNOW.\n",
      "Getting data for 2020-02-16\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 136 Tweets from @TIMESNOW.\n",
      "Getting data for 2020-02-17\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 389 Tweets from @TIMESNOW.\n",
      "Getting data for 2020-02-18\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 427 Tweets from @TIMESNOW.\n",
      "Getting data for 2020-02-19\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 445 Tweets from @TIMESNOW.\n",
      "Getting data for 2020-02-20\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 415 Tweets from @TIMESNOW.\n",
      "Getting data for 2020-02-21\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 418 Tweets from @TIMESNOW.\n",
      "Getting data for 2020-02-22\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 206 Tweets from @TIMESNOW.\n",
      "Getting data for 2020-02-23\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 210 Tweets from @TIMESNOW.\n",
      "Getting data for 2020-02-24\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 480 Tweets from @TIMESNOW.\n",
      "Getting data for 2020-02-25\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 571 Tweets from @TIMESNOW.\n",
      "Getting data for 2020-02-26\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 438 Tweets from @TIMESNOW.\n",
      "Getting data for 2020-02-27\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 401 Tweets from @TIMESNOW.\n",
      "Getting data for 2020-02-28\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 415 Tweets from @TIMESNOW.\n",
      "Getting data for 2020-02-29\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 223 Tweets from @TIMESNOW.\n",
      "Getting data for 2020-03-01\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 223 Tweets from @TIMESNOW.\n",
      "Getting data for 2020-03-02\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 431 Tweets from @TIMESNOW.\n",
      "Getting data for 2020-03-03\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 448 Tweets from @TIMESNOW.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting data for 2020-03-04\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 450 Tweets from @TIMESNOW.\n",
      "Getting data for 2020-03-05\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 417 Tweets from @TIMESNOW.\n",
      "Getting data for 2020-03-06\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 441 Tweets from @TIMESNOW.\n",
      "Getting data for 2020-03-07\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 229 Tweets from @TIMESNOW.\n",
      "Getting data for 2020-03-08\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 229 Tweets from @TIMESNOW.\n",
      "Getting data for 2020-03-09\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 436 Tweets from @TIMESNOW.\n",
      "Getting data for 2020-03-10\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 375 Tweets from @TIMESNOW.\n",
      "Getting data for 2020-03-11\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 440 Tweets from @TIMESNOW.\n",
      "Getting data for 2020-03-12\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 478 Tweets from @TIMESNOW.\n",
      "Getting data for 2020-03-13\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 433 Tweets from @TIMESNOW.\n",
      "Getting data for 2020-03-14\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 187 Tweets from @TIMESNOW.\n",
      "Getting data for 2020-03-15\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 194 Tweets from @TIMESNOW.\n",
      "Getting data for 2020-03-16\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 457 Tweets from @TIMESNOW.\n",
      "Getting data for 2020-03-17\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 438 Tweets from @TIMESNOW.\n",
      "Getting data for 2020-03-18\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 504 Tweets from @TIMESNOW.\n",
      "Getting data for 2020-03-19\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 425 Tweets from @TIMESNOW.\n",
      "Getting data for 2020-03-20\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 521 Tweets from @TIMESNOW.\n",
      "Getting data for 2020-03-21\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 247 Tweets from @TIMESNOW.\n",
      "Getting data for 2020-03-22\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 327 Tweets from @TIMESNOW.\n",
      "Getting data for 2020-03-23\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 420 Tweets from @TIMESNOW.\n",
      "Getting data for 2020-03-24\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 516 Tweets from @TIMESNOW.\n",
      "Getting data for 2020-03-25\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 493 Tweets from @TIMESNOW.\n",
      "Getting data for 2020-03-26\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 534 Tweets from @TIMESNOW.\n",
      "Getting data for 2020-03-27\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 555 Tweets from @TIMESNOW.\n",
      "Getting data for 2020-03-28\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 242 Tweets from @TIMESNOW.\n",
      "Getting data for 2020-03-29\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 286 Tweets from @TIMESNOW.\n",
      "Getting data for 2020-03-30\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 498 Tweets from @TIMESNOW.\n",
      "Getting data for 2020-03-31\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 487 Tweets from @TIMESNOW.\n",
      "Getting data for 2020-04-01\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 526 Tweets from @TIMESNOW.\n",
      "Getting data for 2020-04-02\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 487 Tweets from @TIMESNOW.\n",
      "Getting data for 2020-04-03\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 494 Tweets from @TIMESNOW.\n",
      "Getting data for 2020-04-04\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 248 Tweets from @TIMESNOW.\n",
      "Getting data for 2020-04-05\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 518 Tweets from @TIMESNOW.\n",
      "Getting data for 2020-04-06\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 455 Tweets from @TIMESNOW.\n",
      "Getting data for 2020-04-07\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 452 Tweets from @TIMESNOW.\n",
      "Getting data for 2020-04-08\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 476 Tweets from @TIMESNOW.\n",
      "Getting data for 2020-04-09\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 478 Tweets from @TIMESNOW.\n",
      "Getting data for 2020-04-10\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 474 Tweets from @TIMESNOW.\n",
      "Getting data for 2020-04-11\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 320 Tweets from @TIMESNOW.\n",
      "Getting data for 2020-04-12\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 215 Tweets from @TIMESNOW.\n",
      "Getting data for 2020-04-13\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 445 Tweets from @TIMESNOW.\n",
      "Getting data for 2020-04-14\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 485 Tweets from @TIMESNOW.\n",
      "Getting data for 2020-04-15\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 424 Tweets from @TIMESNOW.\n",
      "Getting data for 2020-04-16\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 468 Tweets from @TIMESNOW.\n",
      "Getting data for 2020-04-17\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 497 Tweets from @TIMESNOW.\n",
      "Getting data for 2020-04-18\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 274 Tweets from @TIMESNOW.\n",
      "Getting data for 2020-04-19\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 248 Tweets from @TIMESNOW.\n",
      "Getting data for 2020-04-20\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 447 Tweets from @TIMESNOW.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting data for 2020-04-21\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 474 Tweets from @TIMESNOW.\n",
      "Getting data for 2020-04-22\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 448 Tweets from @TIMESNOW.\n",
      "Getting data for 2020-04-23\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 467 Tweets from @TIMESNOW.\n",
      "Getting data for 2020-04-24\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 459 Tweets from @TIMESNOW.\n",
      "Getting data for 2020-04-25\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 375 Tweets from @TIMESNOW.\n",
      "Getting data for 2020-04-26\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 289 Tweets from @TIMESNOW.\n",
      "Getting data for 2020-04-27\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 474 Tweets from @TIMESNOW.\n",
      "Getting data for 2020-04-28\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 473 Tweets from @TIMESNOW.\n",
      "Getting data for 2020-04-29\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 454 Tweets from @TIMESNOW.\n",
      "Getting data for 2020-04-30\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 382 Tweets from @TIMESNOW.\n",
      "Getting data for 2020-05-01\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 440 Tweets from @TIMESNOW.\n",
      "Getting data for 2020-05-02\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 389 Tweets from @TIMESNOW.\n",
      "Getting data for 2020-05-03\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 294 Tweets from @TIMESNOW.\n",
      "Getting data for 2020-05-04\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 460 Tweets from @TIMESNOW.\n",
      "Getting data for 2020-05-05\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 488 Tweets from @TIMESNOW.\n",
      "Getting data for 2020-05-06\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 454 Tweets from @TIMESNOW.\n",
      "Getting data for 2020-05-07\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 538 Tweets from @TIMESNOW.\n",
      "Getting data for 2020-05-08\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 511 Tweets from @TIMESNOW.\n",
      "Getting data for 2020-05-09\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 340 Tweets from @TIMESNOW.\n",
      "Getting data for 2020-05-10\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 308 Tweets from @TIMESNOW.\n",
      "Getting data for 2020-05-11\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 482 Tweets from @TIMESNOW.\n",
      "Getting data for 2020-05-12\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 514 Tweets from @TIMESNOW.\n",
      "Getting data for 2020-05-13\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 446 Tweets from @TIMESNOW.\n",
      "Getting data for 2020-05-14\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 538 Tweets from @TIMESNOW.\n",
      "Getting data for 2020-05-15\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 490 Tweets from @TIMESNOW.\n",
      "Getting data for 2020-05-16\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 384 Tweets from @TIMESNOW.\n",
      "Getting data for 2020-05-17\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 323 Tweets from @TIMESNOW.\n",
      "Getting data for 2020-05-18\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 474 Tweets from @TIMESNOW.\n",
      "Getting data for 2020-05-19\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 403 Tweets from @TIMESNOW.\n",
      "Getting data for 2020-05-20\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 459 Tweets from @TIMESNOW.\n",
      "Getting data for 2020-05-21\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 405 Tweets from @TIMESNOW.\n",
      "Getting data for 2020-05-22\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 368 Tweets from @TIMESNOW.\n",
      "Getting data for 2020-05-23\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 295 Tweets from @TIMESNOW.\n",
      "Getting data for 2020-05-24\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 298 Tweets from @TIMESNOW.\n",
      "Getting data for 2020-05-25\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 412 Tweets from @TIMESNOW.\n",
      "Getting data for 2020-05-26\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 508 Tweets from @TIMESNOW.\n",
      "Getting data for 2020-05-27\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 422 Tweets from @TIMESNOW.\n",
      "Getting data for 2020-05-28\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 414 Tweets from @TIMESNOW.\n",
      "Getting data for 2020-05-29\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 426 Tweets from @TIMESNOW.\n",
      "Getting data for 2020-05-30\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 327 Tweets from @TIMESNOW.\n",
      "time taken: 34.94 mins\n",
      "Directory C:\\Users\\rahul\\News channels data\\republic created\n",
      "Getting data for 2020-01-22\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 531 Tweets from @republic.\n",
      "Getting data for 2020-01-23\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 407 Tweets from @republic.\n",
      "Getting data for 2020-01-24\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 408 Tweets from @republic.\n",
      "Getting data for 2020-01-25\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 300 Tweets from @republic.\n",
      "Getting data for 2020-01-26\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 352 Tweets from @republic.\n",
      "Getting data for 2020-01-27\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 403 Tweets from @republic.\n",
      "Getting data for 2020-01-28\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 407 Tweets from @republic.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting data for 2020-01-29\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 430 Tweets from @republic.\n",
      "Getting data for 2020-01-30\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 467 Tweets from @republic.\n",
      "Getting data for 2020-01-31\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 444 Tweets from @republic.\n",
      "Getting data for 2020-02-01\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 506 Tweets from @republic.\n",
      "Getting data for 2020-02-02\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 253 Tweets from @republic.\n",
      "Getting data for 2020-02-03\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 391 Tweets from @republic.\n",
      "Getting data for 2020-02-04\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 396 Tweets from @republic.\n",
      "Getting data for 2020-02-05\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 453 Tweets from @republic.\n",
      "Getting data for 2020-02-06\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 426 Tweets from @republic.\n",
      "Getting data for 2020-02-07\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 408 Tweets from @republic.\n",
      "Getting data for 2020-02-08\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 292 Tweets from @republic.\n",
      "Getting data for 2020-02-09\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 242 Tweets from @republic.\n",
      "Getting data for 2020-02-10\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 400 Tweets from @republic.\n",
      "Getting data for 2020-02-11\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 442 Tweets from @republic.\n",
      "Getting data for 2020-02-12\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 380 Tweets from @republic.\n",
      "Getting data for 2020-02-13\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 417 Tweets from @republic.\n",
      "Getting data for 2020-02-14\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 372 Tweets from @republic.\n",
      "Getting data for 2020-02-15\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 219 Tweets from @republic.\n",
      "Getting data for 2020-02-16\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 213 Tweets from @republic.\n",
      "Getting data for 2020-02-17\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 409 Tweets from @republic.\n",
      "Getting data for 2020-02-18\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 395 Tweets from @republic.\n",
      "Getting data for 2020-02-19\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 342 Tweets from @republic.\n",
      "Getting data for 2020-02-20\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 392 Tweets from @republic.\n",
      "Getting data for 2020-02-21\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 367 Tweets from @republic.\n",
      "Getting data for 2020-02-22\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 211 Tweets from @republic.\n",
      "Getting data for 2020-02-23\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 216 Tweets from @republic.\n",
      "Getting data for 2020-02-24\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 410 Tweets from @republic.\n",
      "Getting data for 2020-02-25\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 391 Tweets from @republic.\n",
      "Getting data for 2020-02-26\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 321 Tweets from @republic.\n",
      "Getting data for 2020-02-27\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 305 Tweets from @republic.\n",
      "Getting data for 2020-02-28\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 289 Tweets from @republic.\n",
      "Getting data for 2020-02-29\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 174 Tweets from @republic.\n",
      "Getting data for 2020-03-01\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 204 Tweets from @republic.\n",
      "Getting data for 2020-03-02\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 350 Tweets from @republic.\n",
      "Getting data for 2020-03-03\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 406 Tweets from @republic.\n",
      "Getting data for 2020-03-04\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 385 Tweets from @republic.\n",
      "Getting data for 2020-03-05\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 341 Tweets from @republic.\n",
      "Getting data for 2020-03-06\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 294 Tweets from @republic.\n",
      "Getting data for 2020-03-07\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 206 Tweets from @republic.\n",
      "Getting data for 2020-03-08\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 303 Tweets from @republic.\n",
      "Getting data for 2020-03-09\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 309 Tweets from @republic.\n",
      "Getting data for 2020-03-10\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 250 Tweets from @republic.\n",
      "Getting data for 2020-03-11\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 339 Tweets from @republic.\n",
      "Getting data for 2020-03-12\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 351 Tweets from @republic.\n",
      "Getting data for 2020-03-13\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 323 Tweets from @republic.\n",
      "Getting data for 2020-03-14\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 215 Tweets from @republic.\n",
      "Getting data for 2020-03-15\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 245 Tweets from @republic.\n",
      "Getting data for 2020-03-16\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 332 Tweets from @republic.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting data for 2020-03-17\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 367 Tweets from @republic.\n",
      "Getting data for 2020-03-18\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 389 Tweets from @republic.\n",
      "Getting data for 2020-03-19\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 442 Tweets from @republic.\n",
      "Getting data for 2020-03-20\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 436 Tweets from @republic.\n",
      "Getting data for 2020-03-21\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 225 Tweets from @republic.\n",
      "Getting data for 2020-03-22\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 292 Tweets from @republic.\n",
      "Getting data for 2020-03-23\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 390 Tweets from @republic.\n",
      "Getting data for 2020-03-24\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 450 Tweets from @republic.\n",
      "Getting data for 2020-03-25\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 337 Tweets from @republic.\n",
      "Getting data for 2020-03-26\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 484 Tweets from @republic.\n",
      "Getting data for 2020-03-27\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 400 Tweets from @republic.\n",
      "Getting data for 2020-03-28\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 283 Tweets from @republic.\n",
      "Getting data for 2020-03-29\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 302 Tweets from @republic.\n",
      "Getting data for 2020-03-30\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 403 Tweets from @republic.\n",
      "Getting data for 2020-03-31\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 359 Tweets from @republic.\n",
      "Getting data for 2020-04-01\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 387 Tweets from @republic.\n",
      "Getting data for 2020-04-02\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 367 Tweets from @republic.\n",
      "Getting data for 2020-04-03\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 378 Tweets from @republic.\n",
      "Getting data for 2020-04-04\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 207 Tweets from @republic.\n",
      "Getting data for 2020-04-05\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 217 Tweets from @republic.\n",
      "Getting data for 2020-04-06\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 357 Tweets from @republic.\n",
      "Getting data for 2020-04-07\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 394 Tweets from @republic.\n",
      "Getting data for 2020-04-08\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 334 Tweets from @republic.\n",
      "Getting data for 2020-04-09\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 366 Tweets from @republic.\n",
      "Getting data for 2020-04-10\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 260 Tweets from @republic.\n",
      "Getting data for 2020-04-11\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 258 Tweets from @republic.\n",
      "Getting data for 2020-04-12\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 208 Tweets from @republic.\n",
      "Getting data for 2020-04-13\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 363 Tweets from @republic.\n",
      "Getting data for 2020-04-14\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 417 Tweets from @republic.\n",
      "Getting data for 2020-04-15\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 397 Tweets from @republic.\n",
      "Getting data for 2020-04-16\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 390 Tweets from @republic.\n",
      "Getting data for 2020-04-17\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 393 Tweets from @republic.\n",
      "Getting data for 2020-04-18\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 283 Tweets from @republic.\n",
      "Getting data for 2020-04-19\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 308 Tweets from @republic.\n",
      "Getting data for 2020-04-20\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 341 Tweets from @republic.\n",
      "Getting data for 2020-04-21\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 394 Tweets from @republic.\n",
      "Getting data for 2020-04-22\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 409 Tweets from @republic.\n",
      "Getting data for 2020-04-23\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 330 Tweets from @republic.\n",
      "Getting data for 2020-04-24\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 349 Tweets from @republic.\n",
      "Getting data for 2020-04-25\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 264 Tweets from @republic.\n",
      "Getting data for 2020-04-26\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 290 Tweets from @republic.\n",
      "Getting data for 2020-04-27\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 366 Tweets from @republic.\n",
      "Getting data for 2020-04-28\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 382 Tweets from @republic.\n",
      "Getting data for 2020-04-29\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 387 Tweets from @republic.\n",
      "Getting data for 2020-04-30\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 471 Tweets from @republic.\n",
      "Getting data for 2020-05-01\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 260 Tweets from @republic.\n",
      "Getting data for 2020-05-02\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 254 Tweets from @republic.\n",
      "Getting data for 2020-05-03\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 272 Tweets from @republic.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting data for 2020-05-04\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 338 Tweets from @republic.\n",
      "Getting data for 2020-05-05\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 405 Tweets from @republic.\n",
      "Getting data for 2020-05-06\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 340 Tweets from @republic.\n",
      "Getting data for 2020-05-07\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 386 Tweets from @republic.\n",
      "Getting data for 2020-05-08\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 369 Tweets from @republic.\n",
      "Getting data for 2020-05-09\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 203 Tweets from @republic.\n",
      "Getting data for 2020-05-10\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 265 Tweets from @republic.\n",
      "Getting data for 2020-05-11\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 353 Tweets from @republic.\n",
      "Getting data for 2020-05-12\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 425 Tweets from @republic.\n",
      "Getting data for 2020-05-13\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 366 Tweets from @republic.\n",
      "Getting data for 2020-05-14\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 422 Tweets from @republic.\n",
      "Getting data for 2020-05-15\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 376 Tweets from @republic.\n",
      "Getting data for 2020-05-16\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 248 Tweets from @republic.\n",
      "Getting data for 2020-05-17\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 248 Tweets from @republic.\n",
      "Getting data for 2020-05-18\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 302 Tweets from @republic.\n",
      "Getting data for 2020-05-19\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 381 Tweets from @republic.\n",
      "Getting data for 2020-05-20\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 380 Tweets from @republic.\n",
      "Getting data for 2020-05-21\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 354 Tweets from @republic.\n",
      "Getting data for 2020-05-22\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 337 Tweets from @republic.\n",
      "Getting data for 2020-05-23\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 257 Tweets from @republic.\n",
      "Getting data for 2020-05-24\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 307 Tweets from @republic.\n",
      "Getting data for 2020-05-25\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 307 Tweets from @republic.\n",
      "Getting data for 2020-05-26\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 371 Tweets from @republic.\n",
      "Getting data for 2020-05-27\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 357 Tweets from @republic.\n",
      "Getting data for 2020-05-28\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 417 Tweets from @republic.\n",
      "Getting data for 2020-05-29\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 379 Tweets from @republic.\n",
      "Getting data for 2020-05-30\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 271 Tweets from @republic.\n",
      "time taken: 28.87 mins\n",
      "Directory C:\\Users\\rahul\\News channels data\\CNBCTV18news created\n",
      "Getting data for 2020-01-22\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 136 Tweets from @CNBCTV18news.\n",
      "Getting data for 2020-01-23\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 125 Tweets from @CNBCTV18news.\n",
      "Getting data for 2020-01-24\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 108 Tweets from @CNBCTV18news.\n",
      "Getting data for 2020-01-25\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 55 Tweets from @CNBCTV18news.\n",
      "Getting data for 2020-01-26\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 53 Tweets from @CNBCTV18news.\n",
      "Getting data for 2020-01-27\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 113 Tweets from @CNBCTV18news.\n",
      "Getting data for 2020-01-28\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 121 Tweets from @CNBCTV18news.\n",
      "Getting data for 2020-01-29\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 130 Tweets from @CNBCTV18news.\n",
      "Getting data for 2020-01-30\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 141 Tweets from @CNBCTV18news.\n",
      "Getting data for 2020-01-31\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 162 Tweets from @CNBCTV18news.\n",
      "Getting data for 2020-02-01\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 386 Tweets from @CNBCTV18news.\n",
      "Getting data for 2020-02-02\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 87 Tweets from @CNBCTV18news.\n",
      "Getting data for 2020-02-03\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 142 Tweets from @CNBCTV18news.\n",
      "Getting data for 2020-02-04\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 106 Tweets from @CNBCTV18news.\n",
      "Getting data for 2020-02-05\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 174 Tweets from @CNBCTV18news.\n",
      "Getting data for 2020-02-06\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 187 Tweets from @CNBCTV18news.\n",
      "Getting data for 2020-02-07\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 136 Tweets from @CNBCTV18news.\n",
      "Getting data for 2020-02-08\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 85 Tweets from @CNBCTV18news.\n",
      "Getting data for 2020-02-09\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 47 Tweets from @CNBCTV18news.\n",
      "Getting data for 2020-02-10\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 132 Tweets from @CNBCTV18news.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting data for 2020-02-11\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 138 Tweets from @CNBCTV18news.\n",
      "Getting data for 2020-02-12\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 140 Tweets from @CNBCTV18news.\n",
      "Getting data for 2020-02-13\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 127 Tweets from @CNBCTV18news.\n",
      "Getting data for 2020-02-14\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 98 Tweets from @CNBCTV18news.\n",
      "Getting data for 2020-02-15\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 50 Tweets from @CNBCTV18news.\n",
      "Getting data for 2020-02-16\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 37 Tweets from @CNBCTV18news.\n",
      "Getting data for 2020-02-17\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 101 Tweets from @CNBCTV18news.\n",
      "Getting data for 2020-02-18\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 115 Tweets from @CNBCTV18news.\n",
      "Getting data for 2020-02-19\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 116 Tweets from @CNBCTV18news.\n",
      "Getting data for 2020-02-20\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 133 Tweets from @CNBCTV18news.\n",
      "Getting data for 2020-02-21\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 60 Tweets from @CNBCTV18news.\n",
      "Getting data for 2020-02-22\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 40 Tweets from @CNBCTV18news.\n",
      "Getting data for 2020-02-23\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 31 Tweets from @CNBCTV18news.\n",
      "Getting data for 2020-02-24\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 109 Tweets from @CNBCTV18news.\n",
      "Getting data for 2020-02-25\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 118 Tweets from @CNBCTV18news.\n",
      "Getting data for 2020-02-26\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 126 Tweets from @CNBCTV18news.\n",
      "Getting data for 2020-02-27\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 117 Tweets from @CNBCTV18news.\n",
      "Getting data for 2020-02-28\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 161 Tweets from @CNBCTV18news.\n",
      "Getting data for 2020-02-29\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 40 Tweets from @CNBCTV18news.\n",
      "Getting data for 2020-03-01\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 43 Tweets from @CNBCTV18news.\n",
      "Getting data for 2020-03-02\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 101 Tweets from @CNBCTV18news.\n",
      "Getting data for 2020-03-03\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 111 Tweets from @CNBCTV18news.\n",
      "Getting data for 2020-03-04\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 124 Tweets from @CNBCTV18news.\n",
      "Getting data for 2020-03-05\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 121 Tweets from @CNBCTV18news.\n",
      "Getting data for 2020-03-06\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 113 Tweets from @CNBCTV18news.\n",
      "Getting data for 2020-03-07\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 43 Tweets from @CNBCTV18news.\n",
      "Getting data for 2020-03-08\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 43 Tweets from @CNBCTV18news.\n",
      "Getting data for 2020-03-09\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 76 Tweets from @CNBCTV18news.\n",
      "Getting data for 2020-03-10\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 28 Tweets from @CNBCTV18news.\n",
      "Getting data for 2020-03-11\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 106 Tweets from @CNBCTV18news.\n",
      "Getting data for 2020-03-12\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 130 Tweets from @CNBCTV18news.\n",
      "Getting data for 2020-03-13\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 116 Tweets from @CNBCTV18news.\n",
      "Getting data for 2020-03-14\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 39 Tweets from @CNBCTV18news.\n",
      "Getting data for 2020-03-15\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 41 Tweets from @CNBCTV18news.\n",
      "Getting data for 2020-03-16\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 108 Tweets from @CNBCTV18news.\n",
      "Getting data for 2020-03-17\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 126 Tweets from @CNBCTV18news.\n",
      "Getting data for 2020-03-18\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 132 Tweets from @CNBCTV18news.\n",
      "Getting data for 2020-03-19\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 135 Tweets from @CNBCTV18news.\n",
      "Getting data for 2020-03-20\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 126 Tweets from @CNBCTV18news.\n",
      "Getting data for 2020-03-21\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 42 Tweets from @CNBCTV18news.\n",
      "Getting data for 2020-03-22\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 45 Tweets from @CNBCTV18news.\n",
      "Getting data for 2020-03-23\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 125 Tweets from @CNBCTV18news.\n",
      "Getting data for 2020-03-24\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 119 Tweets from @CNBCTV18news.\n",
      "Getting data for 2020-03-25\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 143 Tweets from @CNBCTV18news.\n",
      "Getting data for 2020-03-26\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 145 Tweets from @CNBCTV18news.\n",
      "Getting data for 2020-03-27\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 108 Tweets from @CNBCTV18news.\n",
      "Getting data for 2020-03-28\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 63 Tweets from @CNBCTV18news.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting data for 2020-03-29\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 38 Tweets from @CNBCTV18news.\n",
      "Getting data for 2020-03-30\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 106 Tweets from @CNBCTV18news.\n",
      "Getting data for 2020-03-31\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 111 Tweets from @CNBCTV18news.\n",
      "Getting data for 2020-04-01\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 113 Tweets from @CNBCTV18news.\n",
      "Getting data for 2020-04-02\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 92 Tweets from @CNBCTV18news.\n",
      "Getting data for 2020-04-03\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 119 Tweets from @CNBCTV18news.\n",
      "Getting data for 2020-04-04\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 73 Tweets from @CNBCTV18news.\n",
      "Getting data for 2020-04-05\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 112 Tweets from @CNBCTV18news.\n",
      "Getting data for 2020-04-06\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 73 Tweets from @CNBCTV18news.\n",
      "Getting data for 2020-04-07\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 118 Tweets from @CNBCTV18news.\n",
      "Getting data for 2020-04-08\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 122 Tweets from @CNBCTV18news.\n",
      "Getting data for 2020-04-09\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 120 Tweets from @CNBCTV18news.\n",
      "Getting data for 2020-04-10\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 50 Tweets from @CNBCTV18news.\n",
      "Getting data for 2020-04-11\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 44 Tweets from @CNBCTV18news.\n",
      "Getting data for 2020-04-12\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 31 Tweets from @CNBCTV18news.\n",
      "Getting data for 2020-04-13\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 132 Tweets from @CNBCTV18news.\n",
      "Getting data for 2020-04-14\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 95 Tweets from @CNBCTV18news.\n",
      "Getting data for 2020-04-15\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 144 Tweets from @CNBCTV18news.\n",
      "Getting data for 2020-04-16\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 130 Tweets from @CNBCTV18news.\n",
      "Getting data for 2020-04-17\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 126 Tweets from @CNBCTV18news.\n",
      "Getting data for 2020-04-18\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 45 Tweets from @CNBCTV18news.\n",
      "Getting data for 2020-04-19\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 38 Tweets from @CNBCTV18news.\n",
      "Getting data for 2020-04-20\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 130 Tweets from @CNBCTV18news.\n",
      "Getting data for 2020-04-21\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 133 Tweets from @CNBCTV18news.\n",
      "Getting data for 2020-04-22\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 119 Tweets from @CNBCTV18news.\n",
      "Getting data for 2020-04-23\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 110 Tweets from @CNBCTV18news.\n",
      "Getting data for 2020-04-24\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 102 Tweets from @CNBCTV18news.\n",
      "Getting data for 2020-04-25\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 46 Tweets from @CNBCTV18news.\n",
      "Getting data for 2020-04-26\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 40 Tweets from @CNBCTV18news.\n",
      "Getting data for 2020-04-27\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 98 Tweets from @CNBCTV18news.\n",
      "Getting data for 2020-04-28\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 124 Tweets from @CNBCTV18news.\n",
      "Getting data for 2020-04-29\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 99 Tweets from @CNBCTV18news.\n",
      "Getting data for 2020-04-30\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 112 Tweets from @CNBCTV18news.\n",
      "Getting data for 2020-05-01\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 74 Tweets from @CNBCTV18news.\n",
      "Getting data for 2020-05-02\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 60 Tweets from @CNBCTV18news.\n",
      "Getting data for 2020-05-03\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 58 Tweets from @CNBCTV18news.\n",
      "Getting data for 2020-05-04\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 118 Tweets from @CNBCTV18news.\n",
      "Getting data for 2020-05-05\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 103 Tweets from @CNBCTV18news.\n",
      "Getting data for 2020-05-06\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 98 Tweets from @CNBCTV18news.\n",
      "Getting data for 2020-05-07\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 122 Tweets from @CNBCTV18news.\n",
      "Getting data for 2020-05-08\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 94 Tweets from @CNBCTV18news.\n",
      "Getting data for 2020-05-09\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 59 Tweets from @CNBCTV18news.\n",
      "Getting data for 2020-05-10\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 34 Tweets from @CNBCTV18news.\n",
      "Getting data for 2020-05-11\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 108 Tweets from @CNBCTV18news.\n",
      "Getting data for 2020-05-12\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 107 Tweets from @CNBCTV18news.\n",
      "Getting data for 2020-05-13\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 117 Tweets from @CNBCTV18news.\n",
      "Getting data for 2020-05-14\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 108 Tweets from @CNBCTV18news.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting data for 2020-05-15\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 92 Tweets from @CNBCTV18news.\n",
      "Getting data for 2020-05-16\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 63 Tweets from @CNBCTV18news.\n",
      "Getting data for 2020-05-17\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 55 Tweets from @CNBCTV18news.\n",
      "Getting data for 2020-05-18\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 108 Tweets from @CNBCTV18news.\n",
      "Getting data for 2020-05-19\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 106 Tweets from @CNBCTV18news.\n",
      "Getting data for 2020-05-20\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 139 Tweets from @CNBCTV18news.\n",
      "Getting data for 2020-05-21\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 107 Tweets from @CNBCTV18news.\n",
      "Getting data for 2020-05-22\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 108 Tweets from @CNBCTV18news.\n",
      "Getting data for 2020-05-23\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 48 Tweets from @CNBCTV18news.\n",
      "Getting data for 2020-05-24\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 52 Tweets from @CNBCTV18news.\n",
      "Getting data for 2020-05-25\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 83 Tweets from @CNBCTV18news.\n",
      "Getting data for 2020-05-26\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 83 Tweets from @CNBCTV18news.\n",
      "Getting data for 2020-05-27\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 115 Tweets from @CNBCTV18news.\n",
      "Getting data for 2020-05-28\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 123 Tweets from @CNBCTV18news.\n",
      "Getting data for 2020-05-29\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 106 Tweets from @CNBCTV18news.\n",
      "Getting data for 2020-05-30\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 55 Tweets from @CNBCTV18news.\n",
      "time taken: 18.01 mins\n",
      "Directory C:\\Users\\rahul\\News channels data\\CNNnews18 created\n",
      "Getting data for 2020-01-22\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 232 Tweets from @CNNnews18.\n",
      "Getting data for 2020-01-23\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 261 Tweets from @CNNnews18.\n",
      "Getting data for 2020-01-24\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 277 Tweets from @CNNnews18.\n",
      "Getting data for 2020-01-25\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 175 Tweets from @CNNnews18.\n",
      "Getting data for 2020-01-26\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 123 Tweets from @CNNnews18.\n",
      "Getting data for 2020-01-27\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 257 Tweets from @CNNnews18.\n",
      "Getting data for 2020-01-28\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 298 Tweets from @CNNnews18.\n",
      "Getting data for 2020-01-29\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 255 Tweets from @CNNnews18.\n",
      "Getting data for 2020-01-30\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 236 Tweets from @CNNnews18.\n",
      "Getting data for 2020-01-31\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 259 Tweets from @CNNnews18.\n",
      "Getting data for 2020-02-01\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 310 Tweets from @CNNnews18.\n",
      "Getting data for 2020-02-02\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 158 Tweets from @CNNnews18.\n",
      "Getting data for 2020-02-03\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 300 Tweets from @CNNnews18.\n",
      "Getting data for 2020-02-04\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 262 Tweets from @CNNnews18.\n",
      "Getting data for 2020-02-05\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 265 Tweets from @CNNnews18.\n",
      "Getting data for 2020-02-06\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 241 Tweets from @CNNnews18.\n",
      "Getting data for 2020-02-07\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 234 Tweets from @CNNnews18.\n",
      "Getting data for 2020-02-08\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 226 Tweets from @CNNnews18.\n",
      "Getting data for 2020-02-09\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 122 Tweets from @CNNnews18.\n",
      "Getting data for 2020-02-10\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 234 Tweets from @CNNnews18.\n",
      "Getting data for 2020-02-11\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 321 Tweets from @CNNnews18.\n",
      "Getting data for 2020-02-12\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 280 Tweets from @CNNnews18.\n",
      "Getting data for 2020-02-13\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 254 Tweets from @CNNnews18.\n",
      "Getting data for 2020-02-14\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 239 Tweets from @CNNnews18.\n",
      "Getting data for 2020-02-15\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 126 Tweets from @CNNnews18.\n",
      "Getting data for 2020-02-16\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 110 Tweets from @CNNnews18.\n",
      "Getting data for 2020-02-17\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 222 Tweets from @CNNnews18.\n",
      "Getting data for 2020-02-18\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 223 Tweets from @CNNnews18.\n",
      "Getting data for 2020-02-19\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 176 Tweets from @CNNnews18.\n",
      "Getting data for 2020-02-20\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 224 Tweets from @CNNnews18.\n",
      "Getting data for 2020-02-21\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 229 Tweets from @CNNnews18.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting data for 2020-02-22\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 113 Tweets from @CNNnews18.\n",
      "Getting data for 2020-02-23\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 134 Tweets from @CNNnews18.\n",
      "Getting data for 2020-02-24\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 211 Tweets from @CNNnews18.\n",
      "Getting data for 2020-02-25\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 191 Tweets from @CNNnews18.\n",
      "Getting data for 2020-02-26\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 267 Tweets from @CNNnews18.\n",
      "Getting data for 2020-02-27\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 187 Tweets from @CNNnews18.\n",
      "Getting data for 2020-02-28\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 259 Tweets from @CNNnews18.\n",
      "Getting data for 2020-02-29\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 105 Tweets from @CNNnews18.\n",
      "Getting data for 2020-03-01\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 93 Tweets from @CNNnews18.\n",
      "Getting data for 2020-03-02\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 262 Tweets from @CNNnews18.\n",
      "Getting data for 2020-03-03\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 251 Tweets from @CNNnews18.\n",
      "Getting data for 2020-03-04\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 285 Tweets from @CNNnews18.\n",
      "Getting data for 2020-03-05\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 236 Tweets from @CNNnews18.\n",
      "Getting data for 2020-03-06\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 277 Tweets from @CNNnews18.\n",
      "Getting data for 2020-03-07\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 116 Tweets from @CNNnews18.\n",
      "Getting data for 2020-03-08\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 103 Tweets from @CNNnews18.\n",
      "Getting data for 2020-03-09\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 175 Tweets from @CNNnews18.\n",
      "Getting data for 2020-03-10\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 92 Tweets from @CNNnews18.\n",
      "Getting data for 2020-03-11\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 215 Tweets from @CNNnews18.\n",
      "Getting data for 2020-03-12\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 227 Tweets from @CNNnews18.\n",
      "Getting data for 2020-03-13\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 239 Tweets from @CNNnews18.\n",
      "Getting data for 2020-03-14\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 152 Tweets from @CNNnews18.\n",
      "Getting data for 2020-03-15\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 122 Tweets from @CNNnews18.\n",
      "Getting data for 2020-03-16\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 226 Tweets from @CNNnews18.\n",
      "Getting data for 2020-03-17\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 165 Tweets from @CNNnews18.\n",
      "Getting data for 2020-03-18\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 273 Tweets from @CNNnews18.\n",
      "Getting data for 2020-03-19\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 235 Tweets from @CNNnews18.\n",
      "Getting data for 2020-03-20\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 211 Tweets from @CNNnews18.\n",
      "Getting data for 2020-03-21\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 98 Tweets from @CNNnews18.\n",
      "Getting data for 2020-03-22\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 114 Tweets from @CNNnews18.\n",
      "Getting data for 2020-03-23\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 171 Tweets from @CNNnews18.\n",
      "Getting data for 2020-03-24\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 235 Tweets from @CNNnews18.\n",
      "Getting data for 2020-03-25\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 232 Tweets from @CNNnews18.\n",
      "Getting data for 2020-03-26\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 271 Tweets from @CNNnews18.\n",
      "Getting data for 2020-03-27\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 272 Tweets from @CNNnews18.\n",
      "Getting data for 2020-03-28\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 144 Tweets from @CNNnews18.\n",
      "Getting data for 2020-03-29\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 126 Tweets from @CNNnews18.\n",
      "Getting data for 2020-03-30\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 238 Tweets from @CNNnews18.\n",
      "Getting data for 2020-03-31\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 178 Tweets from @CNNnews18.\n",
      "Getting data for 2020-04-01\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 213 Tweets from @CNNnews18.\n",
      "Getting data for 2020-04-02\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 239 Tweets from @CNNnews18.\n",
      "Getting data for 2020-04-03\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 214 Tweets from @CNNnews18.\n",
      "Getting data for 2020-04-04\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 150 Tweets from @CNNnews18.\n",
      "Getting data for 2020-04-05\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 156 Tweets from @CNNnews18.\n",
      "Getting data for 2020-04-06\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 252 Tweets from @CNNnews18.\n",
      "Getting data for 2020-04-07\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 224 Tweets from @CNNnews18.\n",
      "Getting data for 2020-04-08\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 225 Tweets from @CNNnews18.\n",
      "Getting data for 2020-04-09\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 223 Tweets from @CNNnews18.\n",
      "Getting data for 2020-04-10\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 228 Tweets from @CNNnews18.\n",
      "Getting data for 2020-04-11\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 156 Tweets from @CNNnews18.\n",
      "Getting data for 2020-04-12\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 120 Tweets from @CNNnews18.\n",
      "Getting data for 2020-04-13\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 241 Tweets from @CNNnews18.\n",
      "Getting data for 2020-04-14\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 272 Tweets from @CNNnews18.\n",
      "Getting data for 2020-04-15\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 256 Tweets from @CNNnews18.\n",
      "Getting data for 2020-04-16\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 277 Tweets from @CNNnews18.\n",
      "Getting data for 2020-04-17\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 255 Tweets from @CNNnews18.\n",
      "Getting data for 2020-04-18\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 169 Tweets from @CNNnews18.\n",
      "Getting data for 2020-04-19\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 148 Tweets from @CNNnews18.\n",
      "Getting data for 2020-04-20\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 237 Tweets from @CNNnews18.\n",
      "Getting data for 2020-04-21\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 328 Tweets from @CNNnews18.\n",
      "Getting data for 2020-04-22\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 254 Tweets from @CNNnews18.\n",
      "Getting data for 2020-04-23\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 291 Tweets from @CNNnews18.\n",
      "Getting data for 2020-04-24\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 276 Tweets from @CNNnews18.\n",
      "Getting data for 2020-04-25\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 137 Tweets from @CNNnews18.\n",
      "Getting data for 2020-04-26\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 210 Tweets from @CNNnews18.\n",
      "Getting data for 2020-04-27\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 267 Tweets from @CNNnews18.\n",
      "Getting data for 2020-04-28\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 318 Tweets from @CNNnews18.\n",
      "Getting data for 2020-04-29\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 317 Tweets from @CNNnews18.\n",
      "Getting data for 2020-04-30\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 343 Tweets from @CNNnews18.\n",
      "Getting data for 2020-05-01\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 330 Tweets from @CNNnews18.\n",
      "Getting data for 2020-05-02\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 179 Tweets from @CNNnews18.\n",
      "Getting data for 2020-05-03\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 167 Tweets from @CNNnews18.\n",
      "Getting data for 2020-05-04\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 347 Tweets from @CNNnews18.\n",
      "Getting data for 2020-05-05\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 335 Tweets from @CNNnews18.\n",
      "Getting data for 2020-05-06\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 283 Tweets from @CNNnews18.\n",
      "Getting data for 2020-05-07\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 296 Tweets from @CNNnews18.\n",
      "Getting data for 2020-05-08\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 295 Tweets from @CNNnews18.\n",
      "Getting data for 2020-05-09\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 189 Tweets from @CNNnews18.\n",
      "Getting data for 2020-05-10\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 141 Tweets from @CNNnews18.\n",
      "Getting data for 2020-05-11\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 316 Tweets from @CNNnews18.\n",
      "Getting data for 2020-05-12\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 273 Tweets from @CNNnews18.\n",
      "Getting data for 2020-05-13\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 248 Tweets from @CNNnews18.\n",
      "Getting data for 2020-05-14\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 357 Tweets from @CNNnews18.\n",
      "Getting data for 2020-05-15\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 272 Tweets from @CNNnews18.\n",
      "Getting data for 2020-05-16\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 202 Tweets from @CNNnews18.\n",
      "Getting data for 2020-05-17\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 248 Tweets from @CNNnews18.\n",
      "Getting data for 2020-05-18\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 319 Tweets from @CNNnews18.\n",
      "Getting data for 2020-05-19\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 282 Tweets from @CNNnews18.\n",
      "Getting data for 2020-05-20\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 294 Tweets from @CNNnews18.\n",
      "Getting data for 2020-05-21\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 291 Tweets from @CNNnews18.\n",
      "Getting data for 2020-05-22\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 276 Tweets from @CNNnews18.\n",
      "Getting data for 2020-05-23\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 153 Tweets from @CNNnews18.\n",
      "Getting data for 2020-05-24\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 193 Tweets from @CNNnews18.\n",
      "Getting data for 2020-05-25\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 251 Tweets from @CNNnews18.\n",
      "Getting data for 2020-05-26\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 196 Tweets from @CNNnews18.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting data for 2020-05-27\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 288 Tweets from @CNNnews18.\n",
      "Getting data for 2020-05-28\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 282 Tweets from @CNNnews18.\n",
      "Getting data for 2020-05-29\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 263 Tweets from @CNNnews18.\n",
      "Getting data for 2020-05-30\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 154 Tweets from @CNNnews18.\n",
      "time taken: 24.51 mins\n",
      "Directory C:\\Users\\rahul\\News channels data\\OpIndia_com created\n",
      "Getting data for 2020-01-22\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 67 Tweets from @OpIndia_com.\n",
      "Getting data for 2020-01-23\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 73 Tweets from @OpIndia_com.\n",
      "Getting data for 2020-01-24\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 66 Tweets from @OpIndia_com.\n",
      "Getting data for 2020-01-25\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 62 Tweets from @OpIndia_com.\n",
      "Getting data for 2020-01-26\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 55 Tweets from @OpIndia_com.\n",
      "Getting data for 2020-01-27\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 62 Tweets from @OpIndia_com.\n",
      "Getting data for 2020-01-28\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 72 Tweets from @OpIndia_com.\n",
      "Getting data for 2020-01-29\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 81 Tweets from @OpIndia_com.\n",
      "Getting data for 2020-01-30\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 73 Tweets from @OpIndia_com.\n",
      "Getting data for 2020-01-31\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 60 Tweets from @OpIndia_com.\n",
      "Getting data for 2020-02-01\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 80 Tweets from @OpIndia_com.\n",
      "Getting data for 2020-02-02\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 51 Tweets from @OpIndia_com.\n",
      "Getting data for 2020-02-03\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 51 Tweets from @OpIndia_com.\n",
      "Getting data for 2020-02-04\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 65 Tweets from @OpIndia_com.\n",
      "Getting data for 2020-02-05\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 67 Tweets from @OpIndia_com.\n",
      "Getting data for 2020-02-06\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 70 Tweets from @OpIndia_com.\n",
      "Getting data for 2020-02-07\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 71 Tweets from @OpIndia_com.\n",
      "Getting data for 2020-02-08\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 62 Tweets from @OpIndia_com.\n",
      "Getting data for 2020-02-09\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 49 Tweets from @OpIndia_com.\n",
      "Getting data for 2020-02-10\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 63 Tweets from @OpIndia_com.\n",
      "Getting data for 2020-02-11\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 67 Tweets from @OpIndia_com.\n",
      "Getting data for 2020-02-12\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 53 Tweets from @OpIndia_com.\n",
      "Getting data for 2020-02-13\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 62 Tweets from @OpIndia_com.\n",
      "Getting data for 2020-02-14\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 70 Tweets from @OpIndia_com.\n",
      "Getting data for 2020-02-15\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 56 Tweets from @OpIndia_com.\n",
      "Getting data for 2020-02-16\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 56 Tweets from @OpIndia_com.\n",
      "Getting data for 2020-02-17\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 56 Tweets from @OpIndia_com.\n",
      "Getting data for 2020-02-18\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 59 Tweets from @OpIndia_com.\n",
      "Getting data for 2020-02-19\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 61 Tweets from @OpIndia_com.\n",
      "Getting data for 2020-02-20\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 60 Tweets from @OpIndia_com.\n",
      "Getting data for 2020-02-21\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 73 Tweets from @OpIndia_com.\n",
      "Getting data for 2020-02-22\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 65 Tweets from @OpIndia_com.\n",
      "Getting data for 2020-02-23\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 44 Tweets from @OpIndia_com.\n",
      "Getting data for 2020-02-24\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 52 Tweets from @OpIndia_com.\n",
      "Getting data for 2020-02-25\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 67 Tweets from @OpIndia_com.\n",
      "Getting data for 2020-02-26\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 70 Tweets from @OpIndia_com.\n",
      "Getting data for 2020-02-27\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 73 Tweets from @OpIndia_com.\n",
      "Getting data for 2020-02-28\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 67 Tweets from @OpIndia_com.\n",
      "Getting data for 2020-02-29\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 60 Tweets from @OpIndia_com.\n",
      "Getting data for 2020-03-01\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 59 Tweets from @OpIndia_com.\n",
      "Getting data for 2020-03-02\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 60 Tweets from @OpIndia_com.\n",
      "Getting data for 2020-03-03\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 65 Tweets from @OpIndia_com.\n",
      "Getting data for 2020-03-04\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 65 Tweets from @OpIndia_com.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting data for 2020-03-05\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 66 Tweets from @OpIndia_com.\n",
      "Getting data for 2020-03-06\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 67 Tweets from @OpIndia_com.\n",
      "Getting data for 2020-03-07\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 65 Tweets from @OpIndia_com.\n",
      "Getting data for 2020-03-08\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 61 Tweets from @OpIndia_com.\n",
      "Getting data for 2020-03-09\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 55 Tweets from @OpIndia_com.\n",
      "Getting data for 2020-03-10\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 50 Tweets from @OpIndia_com.\n",
      "Getting data for 2020-03-11\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 62 Tweets from @OpIndia_com.\n",
      "Getting data for 2020-03-12\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 71 Tweets from @OpIndia_com.\n",
      "Getting data for 2020-03-13\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 66 Tweets from @OpIndia_com.\n",
      "Getting data for 2020-03-14\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 62 Tweets from @OpIndia_com.\n",
      "Getting data for 2020-03-15\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 55 Tweets from @OpIndia_com.\n",
      "Getting data for 2020-03-16\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 54 Tweets from @OpIndia_com.\n",
      "Getting data for 2020-03-17\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 54 Tweets from @OpIndia_com.\n",
      "Getting data for 2020-03-18\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 57 Tweets from @OpIndia_com.\n",
      "Getting data for 2020-03-19\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 61 Tweets from @OpIndia_com.\n",
      "Getting data for 2020-03-20\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 61 Tweets from @OpIndia_com.\n",
      "Getting data for 2020-03-21\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 62 Tweets from @OpIndia_com.\n",
      "Getting data for 2020-03-22\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 59 Tweets from @OpIndia_com.\n",
      "Getting data for 2020-03-23\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 58 Tweets from @OpIndia_com.\n",
      "Getting data for 2020-03-24\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 67 Tweets from @OpIndia_com.\n",
      "Getting data for 2020-03-25\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 69 Tweets from @OpIndia_com.\n",
      "Getting data for 2020-03-26\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 73 Tweets from @OpIndia_com.\n",
      "Getting data for 2020-03-27\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 77 Tweets from @OpIndia_com.\n",
      "Getting data for 2020-03-28\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 65 Tweets from @OpIndia_com.\n",
      "Getting data for 2020-03-29\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 60 Tweets from @OpIndia_com.\n",
      "Getting data for 2020-03-30\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 59 Tweets from @OpIndia_com.\n",
      "Getting data for 2020-03-31\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 61 Tweets from @OpIndia_com.\n",
      "Getting data for 2020-04-01\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 69 Tweets from @OpIndia_com.\n",
      "Getting data for 2020-04-02\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 67 Tweets from @OpIndia_com.\n",
      "Getting data for 2020-04-03\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 68 Tweets from @OpIndia_com.\n",
      "Getting data for 2020-04-04\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 57 Tweets from @OpIndia_com.\n",
      "Getting data for 2020-04-05\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 47 Tweets from @OpIndia_com.\n",
      "Getting data for 2020-04-06\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 56 Tweets from @OpIndia_com.\n",
      "Getting data for 2020-04-07\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 67 Tweets from @OpIndia_com.\n",
      "Getting data for 2020-04-08\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 59 Tweets from @OpIndia_com.\n",
      "Getting data for 2020-04-09\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 73 Tweets from @OpIndia_com.\n",
      "Getting data for 2020-04-10\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 64 Tweets from @OpIndia_com.\n",
      "Getting data for 2020-04-11\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 54 Tweets from @OpIndia_com.\n",
      "Getting data for 2020-04-12\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 60 Tweets from @OpIndia_com.\n",
      "Getting data for 2020-04-13\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 60 Tweets from @OpIndia_com.\n",
      "Getting data for 2020-04-14\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 84 Tweets from @OpIndia_com.\n",
      "Getting data for 2020-04-15\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 54 Tweets from @OpIndia_com.\n",
      "Getting data for 2020-04-16\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 63 Tweets from @OpIndia_com.\n",
      "Getting data for 2020-04-17\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 66 Tweets from @OpIndia_com.\n",
      "Getting data for 2020-04-18\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 54 Tweets from @OpIndia_com.\n",
      "Getting data for 2020-04-19\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 56 Tweets from @OpIndia_com.\n",
      "Getting data for 2020-04-20\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 62 Tweets from @OpIndia_com.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting data for 2020-04-21\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 64 Tweets from @OpIndia_com.\n",
      "Getting data for 2020-04-22\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 57 Tweets from @OpIndia_com.\n",
      "Getting data for 2020-04-23\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 67 Tweets from @OpIndia_com.\n",
      "Getting data for 2020-04-24\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 63 Tweets from @OpIndia_com.\n",
      "Getting data for 2020-04-25\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 62 Tweets from @OpIndia_com.\n",
      "Getting data for 2020-04-26\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 61 Tweets from @OpIndia_com.\n",
      "Getting data for 2020-04-27\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 60 Tweets from @OpIndia_com.\n",
      "Getting data for 2020-04-28\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 62 Tweets from @OpIndia_com.\n",
      "Getting data for 2020-04-29\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 62 Tweets from @OpIndia_com.\n",
      "Getting data for 2020-04-30\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 67 Tweets from @OpIndia_com.\n",
      "Getting data for 2020-05-01\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 69 Tweets from @OpIndia_com.\n",
      "Getting data for 2020-05-02\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 69 Tweets from @OpIndia_com.\n",
      "Getting data for 2020-05-03\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 56 Tweets from @OpIndia_com.\n",
      "Getting data for 2020-05-04\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 51 Tweets from @OpIndia_com.\n",
      "Getting data for 2020-05-05\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 57 Tweets from @OpIndia_com.\n",
      "Getting data for 2020-05-06\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 73 Tweets from @OpIndia_com.\n",
      "Getting data for 2020-05-07\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 67 Tweets from @OpIndia_com.\n",
      "Getting data for 2020-05-08\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 69 Tweets from @OpIndia_com.\n",
      "Getting data for 2020-05-09\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 66 Tweets from @OpIndia_com.\n",
      "Getting data for 2020-05-10\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 50 Tweets from @OpIndia_com.\n",
      "Getting data for 2020-05-11\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 53 Tweets from @OpIndia_com.\n",
      "Getting data for 2020-05-12\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 64 Tweets from @OpIndia_com.\n",
      "Getting data for 2020-05-13\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 94 Tweets from @OpIndia_com.\n",
      "Getting data for 2020-05-14\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 84 Tweets from @OpIndia_com.\n",
      "Getting data for 2020-05-15\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 79 Tweets from @OpIndia_com.\n",
      "Getting data for 2020-05-16\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 71 Tweets from @OpIndia_com.\n",
      "Getting data for 2020-05-17\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 64 Tweets from @OpIndia_com.\n",
      "Getting data for 2020-05-18\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 63 Tweets from @OpIndia_com.\n",
      "Getting data for 2020-05-19\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 65 Tweets from @OpIndia_com.\n",
      "Getting data for 2020-05-20\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 68 Tweets from @OpIndia_com.\n",
      "Getting data for 2020-05-21\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 60 Tweets from @OpIndia_com.\n",
      "Getting data for 2020-05-22\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 61 Tweets from @OpIndia_com.\n",
      "Getting data for 2020-05-23\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 71 Tweets from @OpIndia_com.\n",
      "Getting data for 2020-05-24\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 55 Tweets from @OpIndia_com.\n",
      "Getting data for 2020-05-25\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 61 Tweets from @OpIndia_com.\n",
      "Getting data for 2020-05-26\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 70 Tweets from @OpIndia_com.\n",
      "Getting data for 2020-05-27\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 76 Tweets from @OpIndia_com.\n",
      "Getting data for 2020-05-28\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 67 Tweets from @OpIndia_com.\n",
      "Getting data for 2020-05-29\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 65 Tweets from @OpIndia_com.\n",
      "Getting data for 2020-05-30\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 66 Tweets from @OpIndia_com.\n",
      "time taken: 15.62 mins\n",
      "Directory C:\\Users\\rahul\\News channels data\\toi created\n",
      "Getting data for 2020-01-22\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @toi.\n",
      "Getting data for 2020-01-23\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @toi.\n",
      "Getting data for 2020-01-24\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @toi.\n",
      "Getting data for 2020-01-25\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @toi.\n",
      "Getting data for 2020-01-26\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @toi.\n",
      "Getting data for 2020-01-27\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @toi.\n",
      "Getting data for 2020-01-28\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @toi.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting data for 2020-01-29\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @toi.\n",
      "Getting data for 2020-01-30\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @toi.\n",
      "Getting data for 2020-01-31\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @toi.\n",
      "Getting data for 2020-02-01\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @toi.\n",
      "Getting data for 2020-02-02\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @toi.\n",
      "Getting data for 2020-02-03\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @toi.\n",
      "Getting data for 2020-02-04\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @toi.\n",
      "Getting data for 2020-02-05\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @toi.\n",
      "Getting data for 2020-02-06\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @toi.\n",
      "Getting data for 2020-02-07\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @toi.\n",
      "Getting data for 2020-02-08\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @toi.\n",
      "Getting data for 2020-02-09\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @toi.\n",
      "Getting data for 2020-02-10\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @toi.\n",
      "Getting data for 2020-02-11\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @toi.\n",
      "Getting data for 2020-02-12\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @toi.\n",
      "Getting data for 2020-02-13\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @toi.\n",
      "Getting data for 2020-02-14\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @toi.\n",
      "Getting data for 2020-02-15\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @toi.\n",
      "Getting data for 2020-02-16\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @toi.\n",
      "Getting data for 2020-02-17\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @toi.\n",
      "Getting data for 2020-02-18\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @toi.\n",
      "Getting data for 2020-02-19\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @toi.\n",
      "Getting data for 2020-02-20\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @toi.\n",
      "Getting data for 2020-02-21\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @toi.\n",
      "Getting data for 2020-02-22\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @toi.\n",
      "Getting data for 2020-02-23\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @toi.\n",
      "Getting data for 2020-02-24\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @toi.\n",
      "Getting data for 2020-02-25\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @toi.\n",
      "Getting data for 2020-02-26\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @toi.\n",
      "Getting data for 2020-02-27\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @toi.\n",
      "Getting data for 2020-02-28\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @toi.\n",
      "Getting data for 2020-02-29\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @toi.\n",
      "Getting data for 2020-03-01\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @toi.\n",
      "Getting data for 2020-03-02\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @toi.\n",
      "Getting data for 2020-03-03\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @toi.\n",
      "Getting data for 2020-03-04\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @toi.\n",
      "Getting data for 2020-03-05\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @toi.\n",
      "Getting data for 2020-03-06\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @toi.\n",
      "Getting data for 2020-03-07\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @toi.\n",
      "Getting data for 2020-03-08\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @toi.\n",
      "Getting data for 2020-03-09\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @toi.\n",
      "Getting data for 2020-03-10\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @toi.\n",
      "Getting data for 2020-03-11\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @toi.\n",
      "Getting data for 2020-03-12\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @toi.\n",
      "Getting data for 2020-03-13\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @toi.\n",
      "Getting data for 2020-03-14\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @toi.\n",
      "Getting data for 2020-03-15\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @toi.\n",
      "Getting data for 2020-03-16\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @toi.\n",
      "Getting data for 2020-03-17\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @toi.\n",
      "Getting data for 2020-03-18\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @toi.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting data for 2020-03-19\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @toi.\n",
      "Getting data for 2020-03-20\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @toi.\n",
      "Getting data for 2020-03-21\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @toi.\n",
      "Getting data for 2020-03-22\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @toi.\n",
      "Getting data for 2020-03-23\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @toi.\n",
      "Getting data for 2020-03-24\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @toi.\n",
      "Getting data for 2020-03-25\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @toi.\n",
      "Getting data for 2020-03-26\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @toi.\n",
      "Getting data for 2020-03-27\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @toi.\n",
      "Getting data for 2020-03-28\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @toi.\n",
      "Getting data for 2020-03-29\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @toi.\n",
      "Getting data for 2020-03-30\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @toi.\n",
      "Getting data for 2020-03-31\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @toi.\n",
      "Getting data for 2020-04-01\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @toi.\n",
      "Getting data for 2020-04-02\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @toi.\n",
      "Getting data for 2020-04-03\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @toi.\n",
      "Getting data for 2020-04-04\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @toi.\n",
      "Getting data for 2020-04-05\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @toi.\n",
      "Getting data for 2020-04-06\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @toi.\n",
      "Getting data for 2020-04-07\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @toi.\n",
      "Getting data for 2020-04-08\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @toi.\n",
      "Getting data for 2020-04-09\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @toi.\n",
      "Getting data for 2020-04-10\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @toi.\n",
      "Getting data for 2020-04-11\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @toi.\n",
      "Getting data for 2020-04-12\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @toi.\n",
      "Getting data for 2020-04-13\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @toi.\n",
      "Getting data for 2020-04-14\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @toi.\n",
      "Getting data for 2020-04-15\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @toi.\n",
      "Getting data for 2020-04-16\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @toi.\n",
      "Getting data for 2020-04-17\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @toi.\n",
      "Getting data for 2020-04-18\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @toi.\n",
      "Getting data for 2020-04-19\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @toi.\n",
      "Getting data for 2020-04-20\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @toi.\n",
      "Getting data for 2020-04-21\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @toi.\n",
      "Getting data for 2020-04-22\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @toi.\n",
      "Getting data for 2020-04-23\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @toi.\n",
      "Getting data for 2020-04-24\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @toi.\n",
      "Getting data for 2020-04-25\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @toi.\n",
      "Getting data for 2020-04-26\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @toi.\n",
      "Getting data for 2020-04-27\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @toi.\n",
      "Getting data for 2020-04-28\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @toi.\n",
      "Getting data for 2020-04-29\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @toi.\n",
      "Getting data for 2020-04-30\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @toi.\n",
      "Getting data for 2020-05-01\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @toi.\n",
      "Getting data for 2020-05-02\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @toi.\n",
      "Getting data for 2020-05-03\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @toi.\n",
      "Getting data for 2020-05-04\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @toi.\n",
      "Getting data for 2020-05-05\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @toi.\n",
      "Getting data for 2020-05-06\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @toi.\n",
      "Getting data for 2020-05-07\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @toi.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting data for 2020-05-08\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @toi.\n",
      "Getting data for 2020-05-09\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @toi.\n",
      "Getting data for 2020-05-10\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @toi.\n",
      "Getting data for 2020-05-11\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @toi.\n",
      "Getting data for 2020-05-12\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @toi.\n",
      "Getting data for 2020-05-13\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @toi.\n",
      "Getting data for 2020-05-14\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @toi.\n",
      "Getting data for 2020-05-15\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @toi.\n",
      "Getting data for 2020-05-16\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @toi.\n",
      "Getting data for 2020-05-17\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @toi.\n",
      "Getting data for 2020-05-18\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @toi.\n",
      "Getting data for 2020-05-19\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @toi.\n",
      "Getting data for 2020-05-20\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @toi.\n",
      "Getting data for 2020-05-21\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @toi.\n",
      "Getting data for 2020-05-22\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @toi.\n",
      "Getting data for 2020-05-23\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @toi.\n",
      "Getting data for 2020-05-24\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @toi.\n",
      "Getting data for 2020-05-25\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @toi.\n",
      "Getting data for 2020-05-26\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @toi.\n",
      "Getting data for 2020-05-27\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @toi.\n",
      "Getting data for 2020-05-28\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @toi.\n",
      "Getting data for 2020-05-29\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @toi.\n",
      "Getting data for 2020-05-30\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @toi.\n",
      "time taken: 12.53 mins\n",
      "Directory C:\\Users\\rahul\\News channels data\\AltNews created\n",
      "Getting data for 2020-01-22\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 3 Tweets from @AltNews.\n",
      "Getting data for 2020-01-23\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 7 Tweets from @AltNews.\n",
      "Getting data for 2020-01-24\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 6 Tweets from @AltNews.\n",
      "Getting data for 2020-01-25\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 3 Tweets from @AltNews.\n",
      "Getting data for 2020-01-26\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 1 Tweets from @AltNews.\n",
      "Getting data for 2020-01-27\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 5 Tweets from @AltNews.\n",
      "Getting data for 2020-01-28\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 7 Tweets from @AltNews.\n",
      "Getting data for 2020-01-29\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 9 Tweets from @AltNews.\n",
      "Getting data for 2020-01-30\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 2 Tweets from @AltNews.\n",
      "Getting data for 2020-01-31\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 7 Tweets from @AltNews.\n",
      "Getting data for 2020-02-01\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @AltNews.\n",
      "Getting data for 2020-02-02\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @AltNews.\n",
      "Getting data for 2020-02-03\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 5 Tweets from @AltNews.\n",
      "Getting data for 2020-02-04\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 9 Tweets from @AltNews.\n",
      "Getting data for 2020-02-05\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 5 Tweets from @AltNews.\n",
      "Getting data for 2020-02-06\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 8 Tweets from @AltNews.\n",
      "Getting data for 2020-02-07\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 5 Tweets from @AltNews.\n",
      "Getting data for 2020-02-08\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 4 Tweets from @AltNews.\n",
      "Getting data for 2020-02-09\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 1 Tweets from @AltNews.\n",
      "Getting data for 2020-02-10\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 8 Tweets from @AltNews.\n",
      "Getting data for 2020-02-11\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 6 Tweets from @AltNews.\n",
      "Getting data for 2020-02-12\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 3 Tweets from @AltNews.\n",
      "Getting data for 2020-02-13\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 6 Tweets from @AltNews.\n",
      "Getting data for 2020-02-14\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 5 Tweets from @AltNews.\n",
      "Getting data for 2020-02-15\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 4 Tweets from @AltNews.\n",
      "Getting data for 2020-02-16\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @AltNews.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting data for 2020-02-17\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 4 Tweets from @AltNews.\n",
      "Getting data for 2020-02-18\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 2 Tweets from @AltNews.\n",
      "Getting data for 2020-02-19\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 5 Tweets from @AltNews.\n",
      "Getting data for 2020-02-20\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 4 Tweets from @AltNews.\n",
      "Getting data for 2020-02-21\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 4 Tweets from @AltNews.\n",
      "Getting data for 2020-02-22\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @AltNews.\n",
      "Getting data for 2020-02-23\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 3 Tweets from @AltNews.\n",
      "Getting data for 2020-02-24\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 4 Tweets from @AltNews.\n",
      "Getting data for 2020-02-25\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 5 Tweets from @AltNews.\n",
      "Getting data for 2020-02-26\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 6 Tweets from @AltNews.\n",
      "Getting data for 2020-02-27\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 3 Tweets from @AltNews.\n",
      "Getting data for 2020-02-28\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 4 Tweets from @AltNews.\n",
      "Getting data for 2020-02-29\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 4 Tweets from @AltNews.\n",
      "Getting data for 2020-03-01\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @AltNews.\n",
      "Getting data for 2020-03-02\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 5 Tweets from @AltNews.\n",
      "Getting data for 2020-03-03\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 5 Tweets from @AltNews.\n",
      "Getting data for 2020-03-04\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 5 Tweets from @AltNews.\n",
      "Getting data for 2020-03-05\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 5 Tweets from @AltNews.\n",
      "Getting data for 2020-03-06\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 2 Tweets from @AltNews.\n",
      "Getting data for 2020-03-07\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 2 Tweets from @AltNews.\n",
      "Getting data for 2020-03-08\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @AltNews.\n",
      "Getting data for 2020-03-09\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 4 Tweets from @AltNews.\n",
      "Getting data for 2020-03-10\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @AltNews.\n",
      "Getting data for 2020-03-11\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 5 Tweets from @AltNews.\n",
      "Getting data for 2020-03-12\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 5 Tweets from @AltNews.\n",
      "Getting data for 2020-03-13\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 5 Tweets from @AltNews.\n",
      "Getting data for 2020-03-14\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 6 Tweets from @AltNews.\n",
      "Getting data for 2020-03-15\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @AltNews.\n",
      "Getting data for 2020-03-16\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 5 Tweets from @AltNews.\n",
      "Getting data for 2020-03-17\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 4 Tweets from @AltNews.\n",
      "Getting data for 2020-03-18\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 3 Tweets from @AltNews.\n",
      "Getting data for 2020-03-19\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 8 Tweets from @AltNews.\n",
      "Getting data for 2020-03-20\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 8 Tweets from @AltNews.\n",
      "Getting data for 2020-03-21\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 9 Tweets from @AltNews.\n",
      "Getting data for 2020-03-22\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 3 Tweets from @AltNews.\n",
      "Getting data for 2020-03-23\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 8 Tweets from @AltNews.\n",
      "Getting data for 2020-03-24\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 5 Tweets from @AltNews.\n",
      "Getting data for 2020-03-25\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 4 Tweets from @AltNews.\n",
      "Getting data for 2020-03-26\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 6 Tweets from @AltNews.\n",
      "Getting data for 2020-03-27\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 4 Tweets from @AltNews.\n",
      "Getting data for 2020-03-28\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 5 Tweets from @AltNews.\n",
      "Getting data for 2020-03-29\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 3 Tweets from @AltNews.\n",
      "Getting data for 2020-03-30\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 5 Tweets from @AltNews.\n",
      "Getting data for 2020-03-31\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 7 Tweets from @AltNews.\n",
      "Getting data for 2020-04-01\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 4 Tweets from @AltNews.\n",
      "Getting data for 2020-04-02\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 6 Tweets from @AltNews.\n",
      "Getting data for 2020-04-03\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 4 Tweets from @AltNews.\n",
      "Getting data for 2020-04-04\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 8 Tweets from @AltNews.\n",
      "Getting data for 2020-04-05\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 1 Tweets from @AltNews.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting data for 2020-04-06\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 10 Tweets from @AltNews.\n",
      "Getting data for 2020-04-07\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 9 Tweets from @AltNews.\n",
      "Getting data for 2020-04-08\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 7 Tweets from @AltNews.\n",
      "Getting data for 2020-04-09\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 5 Tweets from @AltNews.\n",
      "Getting data for 2020-04-10\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 4 Tweets from @AltNews.\n",
      "Getting data for 2020-04-11\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 6 Tweets from @AltNews.\n",
      "Getting data for 2020-04-12\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 2 Tweets from @AltNews.\n",
      "Getting data for 2020-04-13\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 1 Tweets from @AltNews.\n",
      "Getting data for 2020-04-14\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 4 Tweets from @AltNews.\n",
      "Getting data for 2020-04-15\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 5 Tweets from @AltNews.\n",
      "Getting data for 2020-04-16\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 4 Tweets from @AltNews.\n",
      "Getting data for 2020-04-17\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 7 Tweets from @AltNews.\n",
      "Getting data for 2020-04-18\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 4 Tweets from @AltNews.\n",
      "Getting data for 2020-04-19\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 1 Tweets from @AltNews.\n",
      "Getting data for 2020-04-20\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 5 Tweets from @AltNews.\n",
      "Getting data for 2020-04-21\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 4 Tweets from @AltNews.\n",
      "Getting data for 2020-04-22\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 2 Tweets from @AltNews.\n",
      "Getting data for 2020-04-23\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 2 Tweets from @AltNews.\n",
      "Getting data for 2020-04-24\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 6 Tweets from @AltNews.\n",
      "Getting data for 2020-04-25\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 4 Tweets from @AltNews.\n",
      "Getting data for 2020-04-26\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @AltNews.\n",
      "Getting data for 2020-04-27\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 6 Tweets from @AltNews.\n",
      "Getting data for 2020-04-28\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 2 Tweets from @AltNews.\n",
      "Getting data for 2020-04-29\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 6 Tweets from @AltNews.\n",
      "Getting data for 2020-04-30\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 7 Tweets from @AltNews.\n",
      "Getting data for 2020-05-01\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 3 Tweets from @AltNews.\n",
      "Getting data for 2020-05-02\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 1 Tweets from @AltNews.\n",
      "Getting data for 2020-05-03\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 1 Tweets from @AltNews.\n",
      "Getting data for 2020-05-04\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 4 Tweets from @AltNews.\n",
      "Getting data for 2020-05-05\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 3 Tweets from @AltNews.\n",
      "Getting data for 2020-05-06\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 1 Tweets from @AltNews.\n",
      "Getting data for 2020-05-07\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 3 Tweets from @AltNews.\n",
      "Getting data for 2020-05-08\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 8 Tweets from @AltNews.\n",
      "Getting data for 2020-05-09\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 4 Tweets from @AltNews.\n",
      "Getting data for 2020-05-10\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @AltNews.\n",
      "Getting data for 2020-05-11\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 7 Tweets from @AltNews.\n",
      "Getting data for 2020-05-12\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 3 Tweets from @AltNews.\n",
      "Getting data for 2020-05-13\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 7 Tweets from @AltNews.\n",
      "Getting data for 2020-05-14\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 8 Tweets from @AltNews.\n",
      "Getting data for 2020-05-15\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 3 Tweets from @AltNews.\n",
      "Getting data for 2020-05-16\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 7 Tweets from @AltNews.\n",
      "Getting data for 2020-05-17\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 1 Tweets from @AltNews.\n",
      "Getting data for 2020-05-18\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 2 Tweets from @AltNews.\n",
      "Getting data for 2020-05-19\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 4 Tweets from @AltNews.\n",
      "Getting data for 2020-05-20\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 4 Tweets from @AltNews.\n",
      "Getting data for 2020-05-21\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 10 Tweets from @AltNews.\n",
      "Getting data for 2020-05-22\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 4 Tweets from @AltNews.\n",
      "Getting data for 2020-05-23\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 4 Tweets from @AltNews.\n",
      "Getting data for 2020-05-24\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @AltNews.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting data for 2020-05-25\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 4 Tweets from @AltNews.\n",
      "Getting data for 2020-05-26\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 4 Tweets from @AltNews.\n",
      "Getting data for 2020-05-27\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 2 Tweets from @AltNews.\n",
      "Getting data for 2020-05-28\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 3 Tweets from @AltNews.\n",
      "Getting data for 2020-05-29\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 4 Tweets from @AltNews.\n",
      "Getting data for 2020-05-30\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 3 Tweets from @AltNews.\n",
      "time taken: 13.17 mins\n",
      "Directory C:\\Users\\rahul\\News channels data\\TheNewIndian_in created\n",
      "Getting data for 2020-01-22\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @TheNewIndian_in.\n",
      "Getting data for 2020-01-23\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @TheNewIndian_in.\n",
      "Getting data for 2020-01-24\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @TheNewIndian_in.\n",
      "Getting data for 2020-01-25\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @TheNewIndian_in.\n",
      "Getting data for 2020-01-26\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @TheNewIndian_in.\n",
      "Getting data for 2020-01-27\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @TheNewIndian_in.\n",
      "Getting data for 2020-01-28\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @TheNewIndian_in.\n",
      "Getting data for 2020-01-29\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @TheNewIndian_in.\n",
      "Getting data for 2020-01-30\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @TheNewIndian_in.\n",
      "Getting data for 2020-01-31\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @TheNewIndian_in.\n",
      "Getting data for 2020-02-01\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @TheNewIndian_in.\n",
      "Getting data for 2020-02-02\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @TheNewIndian_in.\n",
      "Getting data for 2020-02-03\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @TheNewIndian_in.\n",
      "Getting data for 2020-02-04\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @TheNewIndian_in.\n",
      "Getting data for 2020-02-05\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @TheNewIndian_in.\n",
      "Getting data for 2020-02-06\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @TheNewIndian_in.\n",
      "Getting data for 2020-02-07\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @TheNewIndian_in.\n",
      "Getting data for 2020-02-08\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @TheNewIndian_in.\n",
      "Getting data for 2020-02-09\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @TheNewIndian_in.\n",
      "Getting data for 2020-02-10\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @TheNewIndian_in.\n",
      "Getting data for 2020-02-11\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @TheNewIndian_in.\n",
      "Getting data for 2020-02-12\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @TheNewIndian_in.\n",
      "Getting data for 2020-02-13\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @TheNewIndian_in.\n",
      "Getting data for 2020-02-14\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @TheNewIndian_in.\n",
      "Getting data for 2020-02-15\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @TheNewIndian_in.\n",
      "Getting data for 2020-02-16\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @TheNewIndian_in.\n",
      "Getting data for 2020-02-17\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @TheNewIndian_in.\n",
      "Getting data for 2020-02-18\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @TheNewIndian_in.\n",
      "Getting data for 2020-02-19\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @TheNewIndian_in.\n",
      "Getting data for 2020-02-20\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @TheNewIndian_in.\n",
      "Getting data for 2020-02-21\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @TheNewIndian_in.\n",
      "Getting data for 2020-02-22\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @TheNewIndian_in.\n",
      "Getting data for 2020-02-23\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @TheNewIndian_in.\n",
      "Getting data for 2020-02-24\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @TheNewIndian_in.\n",
      "Getting data for 2020-02-25\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @TheNewIndian_in.\n",
      "Getting data for 2020-02-26\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @TheNewIndian_in.\n",
      "Getting data for 2020-02-27\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @TheNewIndian_in.\n",
      "Getting data for 2020-02-28\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @TheNewIndian_in.\n",
      "Getting data for 2020-02-29\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @TheNewIndian_in.\n",
      "Getting data for 2020-03-01\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @TheNewIndian_in.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting data for 2020-03-02\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @TheNewIndian_in.\n",
      "Getting data for 2020-03-03\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @TheNewIndian_in.\n",
      "Getting data for 2020-03-04\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @TheNewIndian_in.\n",
      "Getting data for 2020-03-05\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @TheNewIndian_in.\n",
      "Getting data for 2020-03-06\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @TheNewIndian_in.\n",
      "Getting data for 2020-03-07\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @TheNewIndian_in.\n",
      "Getting data for 2020-03-08\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @TheNewIndian_in.\n",
      "Getting data for 2020-03-09\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @TheNewIndian_in.\n",
      "Getting data for 2020-03-10\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @TheNewIndian_in.\n",
      "Getting data for 2020-03-11\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @TheNewIndian_in.\n",
      "Getting data for 2020-03-12\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @TheNewIndian_in.\n",
      "Getting data for 2020-03-13\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @TheNewIndian_in.\n",
      "Getting data for 2020-03-14\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @TheNewIndian_in.\n",
      "Getting data for 2020-03-15\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @TheNewIndian_in.\n",
      "Getting data for 2020-03-16\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @TheNewIndian_in.\n",
      "Getting data for 2020-03-17\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @TheNewIndian_in.\n",
      "Getting data for 2020-03-18\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @TheNewIndian_in.\n",
      "Getting data for 2020-03-19\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @TheNewIndian_in.\n",
      "Getting data for 2020-03-20\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @TheNewIndian_in.\n",
      "Getting data for 2020-03-21\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @TheNewIndian_in.\n",
      "Getting data for 2020-03-22\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @TheNewIndian_in.\n",
      "Getting data for 2020-03-23\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @TheNewIndian_in.\n",
      "Getting data for 2020-03-24\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @TheNewIndian_in.\n",
      "Getting data for 2020-03-25\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @TheNewIndian_in.\n",
      "Getting data for 2020-03-26\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @TheNewIndian_in.\n",
      "Getting data for 2020-03-27\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @TheNewIndian_in.\n",
      "Getting data for 2020-03-28\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @TheNewIndian_in.\n",
      "Getting data for 2020-03-29\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @TheNewIndian_in.\n",
      "Getting data for 2020-03-30\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @TheNewIndian_in.\n",
      "Getting data for 2020-03-31\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @TheNewIndian_in.\n",
      "Getting data for 2020-04-01\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @TheNewIndian_in.\n",
      "Getting data for 2020-04-02\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @TheNewIndian_in.\n",
      "Getting data for 2020-04-03\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @TheNewIndian_in.\n",
      "Getting data for 2020-04-04\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @TheNewIndian_in.\n",
      "Getting data for 2020-04-05\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @TheNewIndian_in.\n",
      "Getting data for 2020-04-06\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @TheNewIndian_in.\n",
      "Getting data for 2020-04-07\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @TheNewIndian_in.\n",
      "Getting data for 2020-04-08\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @TheNewIndian_in.\n",
      "Getting data for 2020-04-09\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @TheNewIndian_in.\n",
      "Getting data for 2020-04-10\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @TheNewIndian_in.\n",
      "Getting data for 2020-04-11\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @TheNewIndian_in.\n",
      "Getting data for 2020-04-12\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @TheNewIndian_in.\n",
      "Getting data for 2020-04-13\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @TheNewIndian_in.\n",
      "Getting data for 2020-04-14\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @TheNewIndian_in.\n",
      "Getting data for 2020-04-15\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @TheNewIndian_in.\n",
      "Getting data for 2020-04-16\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @TheNewIndian_in.\n",
      "Getting data for 2020-04-17\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @TheNewIndian_in.\n",
      "Getting data for 2020-04-18\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @TheNewIndian_in.\n",
      "Getting data for 2020-04-19\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @TheNewIndian_in.\n",
      "Getting data for 2020-04-20\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @TheNewIndian_in.\n",
      "Getting data for 2020-04-21\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @TheNewIndian_in.\n",
      "Getting data for 2020-04-22\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @TheNewIndian_in.\n",
      "Getting data for 2020-04-23\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @TheNewIndian_in.\n",
      "Getting data for 2020-04-24\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @TheNewIndian_in.\n",
      "Getting data for 2020-04-25\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @TheNewIndian_in.\n",
      "Getting data for 2020-04-26\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @TheNewIndian_in.\n",
      "Getting data for 2020-04-27\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @TheNewIndian_in.\n",
      "Getting data for 2020-04-28\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @TheNewIndian_in.\n",
      "Getting data for 2020-04-29\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @TheNewIndian_in.\n",
      "Getting data for 2020-04-30\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @TheNewIndian_in.\n",
      "Getting data for 2020-05-01\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @TheNewIndian_in.\n",
      "Getting data for 2020-05-02\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @TheNewIndian_in.\n",
      "Getting data for 2020-05-03\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @TheNewIndian_in.\n",
      "Getting data for 2020-05-04\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @TheNewIndian_in.\n",
      "Getting data for 2020-05-05\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @TheNewIndian_in.\n",
      "Getting data for 2020-05-06\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @TheNewIndian_in.\n",
      "Getting data for 2020-05-07\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @TheNewIndian_in.\n",
      "Getting data for 2020-05-08\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @TheNewIndian_in.\n",
      "Getting data for 2020-05-09\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @TheNewIndian_in.\n",
      "Getting data for 2020-05-10\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @TheNewIndian_in.\n",
      "Getting data for 2020-05-11\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @TheNewIndian_in.\n",
      "Getting data for 2020-05-12\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @TheNewIndian_in.\n",
      "Getting data for 2020-05-13\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @TheNewIndian_in.\n",
      "Getting data for 2020-05-14\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @TheNewIndian_in.\n",
      "Getting data for 2020-05-15\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @TheNewIndian_in.\n",
      "Getting data for 2020-05-16\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @TheNewIndian_in.\n",
      "Getting data for 2020-05-17\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @TheNewIndian_in.\n",
      "Getting data for 2020-05-18\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @TheNewIndian_in.\n",
      "Getting data for 2020-05-19\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @TheNewIndian_in.\n",
      "Getting data for 2020-05-20\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @TheNewIndian_in.\n",
      "Getting data for 2020-05-21\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @TheNewIndian_in.\n",
      "Getting data for 2020-05-22\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @TheNewIndian_in.\n",
      "Getting data for 2020-05-23\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @TheNewIndian_in.\n",
      "Getting data for 2020-05-24\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @TheNewIndian_in.\n",
      "Getting data for 2020-05-25\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @TheNewIndian_in.\n",
      "Getting data for 2020-05-26\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @TheNewIndian_in.\n",
      "Getting data for 2020-05-27\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @TheNewIndian_in.\n",
      "Getting data for 2020-05-28\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @TheNewIndian_in.\n",
      "Getting data for 2020-05-29\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @TheNewIndian_in.\n",
      "Getting data for 2020-05-30\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @TheNewIndian_in.\n",
      "time taken: 12.54 mins\n",
      "Directory C:\\Users\\rahul\\News channels data\\firstpost created\n",
      "Getting data for 2020-01-22\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 88 Tweets from @firstpost.\n",
      "Getting data for 2020-01-23\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 98 Tweets from @firstpost.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting data for 2020-01-24\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 80 Tweets from @firstpost.\n",
      "Getting data for 2020-01-25\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 55 Tweets from @firstpost.\n",
      "Getting data for 2020-01-26\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 58 Tweets from @firstpost.\n",
      "Getting data for 2020-01-27\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 93 Tweets from @firstpost.\n",
      "Getting data for 2020-01-28\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 88 Tweets from @firstpost.\n",
      "Getting data for 2020-01-29\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 93 Tweets from @firstpost.\n",
      "Getting data for 2020-01-30\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 100 Tweets from @firstpost.\n",
      "Getting data for 2020-01-31\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 99 Tweets from @firstpost.\n",
      "Getting data for 2020-02-01\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 135 Tweets from @firstpost.\n",
      "Getting data for 2020-02-02\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 65 Tweets from @firstpost.\n",
      "Getting data for 2020-02-03\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 98 Tweets from @firstpost.\n",
      "Getting data for 2020-02-04\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 97 Tweets from @firstpost.\n",
      "Getting data for 2020-02-05\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 99 Tweets from @firstpost.\n",
      "Getting data for 2020-02-06\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 110 Tweets from @firstpost.\n",
      "Getting data for 2020-02-07\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 95 Tweets from @firstpost.\n",
      "Getting data for 2020-02-08\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 108 Tweets from @firstpost.\n",
      "Getting data for 2020-02-09\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 50 Tweets from @firstpost.\n",
      "Getting data for 2020-02-10\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 100 Tweets from @firstpost.\n",
      "Getting data for 2020-02-11\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 134 Tweets from @firstpost.\n",
      "Getting data for 2020-02-12\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 98 Tweets from @firstpost.\n",
      "Getting data for 2020-02-13\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 87 Tweets from @firstpost.\n",
      "Getting data for 2020-02-14\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 100 Tweets from @firstpost.\n",
      "Getting data for 2020-02-15\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 65 Tweets from @firstpost.\n",
      "Getting data for 2020-02-16\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 62 Tweets from @firstpost.\n",
      "Getting data for 2020-02-17\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 81 Tweets from @firstpost.\n",
      "Getting data for 2020-02-18\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 98 Tweets from @firstpost.\n",
      "Getting data for 2020-02-19\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 88 Tweets from @firstpost.\n",
      "Getting data for 2020-02-20\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 102 Tweets from @firstpost.\n",
      "Getting data for 2020-02-21\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 67 Tweets from @firstpost.\n",
      "Getting data for 2020-02-22\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 60 Tweets from @firstpost.\n",
      "Getting data for 2020-02-23\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 49 Tweets from @firstpost.\n",
      "Getting data for 2020-02-24\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 103 Tweets from @firstpost.\n",
      "Getting data for 2020-02-25\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 110 Tweets from @firstpost.\n",
      "Getting data for 2020-02-26\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 122 Tweets from @firstpost.\n",
      "Getting data for 2020-02-27\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 106 Tweets from @firstpost.\n",
      "Getting data for 2020-02-28\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 118 Tweets from @firstpost.\n",
      "Getting data for 2020-02-29\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 67 Tweets from @firstpost.\n",
      "Getting data for 2020-03-01\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 52 Tweets from @firstpost.\n",
      "Getting data for 2020-03-02\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 106 Tweets from @firstpost.\n",
      "Getting data for 2020-03-03\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 100 Tweets from @firstpost.\n",
      "Getting data for 2020-03-04\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 114 Tweets from @firstpost.\n",
      "Getting data for 2020-03-05\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 101 Tweets from @firstpost.\n",
      "Getting data for 2020-03-06\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 90 Tweets from @firstpost.\n",
      "Getting data for 2020-03-07\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 54 Tweets from @firstpost.\n",
      "Getting data for 2020-03-08\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 50 Tweets from @firstpost.\n",
      "Getting data for 2020-03-09\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 102 Tweets from @firstpost.\n",
      "Getting data for 2020-03-10\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 54 Tweets from @firstpost.\n",
      "Getting data for 2020-03-11\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 134 Tweets from @firstpost.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting data for 2020-03-12\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 116 Tweets from @firstpost.\n",
      "Getting data for 2020-03-13\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 118 Tweets from @firstpost.\n",
      "Getting data for 2020-03-14\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 65 Tweets from @firstpost.\n",
      "Getting data for 2020-03-15\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 53 Tweets from @firstpost.\n",
      "Getting data for 2020-03-16\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 110 Tweets from @firstpost.\n",
      "Getting data for 2020-03-17\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 107 Tweets from @firstpost.\n",
      "Getting data for 2020-03-18\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 125 Tweets from @firstpost.\n",
      "Getting data for 2020-03-19\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 117 Tweets from @firstpost.\n",
      "Getting data for 2020-03-20\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 104 Tweets from @firstpost.\n",
      "Getting data for 2020-03-21\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 84 Tweets from @firstpost.\n",
      "Getting data for 2020-03-22\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 69 Tweets from @firstpost.\n",
      "Getting data for 2020-03-23\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 111 Tweets from @firstpost.\n",
      "Getting data for 2020-03-24\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 123 Tweets from @firstpost.\n",
      "Getting data for 2020-03-25\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 111 Tweets from @firstpost.\n",
      "Getting data for 2020-03-26\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 132 Tweets from @firstpost.\n",
      "Getting data for 2020-03-27\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 125 Tweets from @firstpost.\n",
      "Getting data for 2020-03-28\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 69 Tweets from @firstpost.\n",
      "Getting data for 2020-03-29\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 68 Tweets from @firstpost.\n",
      "Getting data for 2020-03-30\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 106 Tweets from @firstpost.\n",
      "Getting data for 2020-03-31\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 115 Tweets from @firstpost.\n",
      "Getting data for 2020-04-01\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 121 Tweets from @firstpost.\n",
      "Getting data for 2020-04-02\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 106 Tweets from @firstpost.\n",
      "Getting data for 2020-04-03\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 117 Tweets from @firstpost.\n",
      "Getting data for 2020-04-04\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 75 Tweets from @firstpost.\n",
      "Getting data for 2020-04-05\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 62 Tweets from @firstpost.\n",
      "Getting data for 2020-04-06\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 95 Tweets from @firstpost.\n",
      "Getting data for 2020-04-07\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 107 Tweets from @firstpost.\n",
      "Getting data for 2020-04-08\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 111 Tweets from @firstpost.\n",
      "Getting data for 2020-04-09\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 105 Tweets from @firstpost.\n",
      "Getting data for 2020-04-10\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 98 Tweets from @firstpost.\n",
      "Getting data for 2020-04-11\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 69 Tweets from @firstpost.\n",
      "Getting data for 2020-04-12\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 66 Tweets from @firstpost.\n",
      "Getting data for 2020-04-13\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 103 Tweets from @firstpost.\n",
      "Getting data for 2020-04-14\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 127 Tweets from @firstpost.\n",
      "Getting data for 2020-04-15\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 120 Tweets from @firstpost.\n",
      "Getting data for 2020-04-16\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 130 Tweets from @firstpost.\n",
      "Getting data for 2020-04-17\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 106 Tweets from @firstpost.\n",
      "Getting data for 2020-04-18\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 76 Tweets from @firstpost.\n",
      "Getting data for 2020-04-19\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 59 Tweets from @firstpost.\n",
      "Getting data for 2020-04-20\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 124 Tweets from @firstpost.\n",
      "Getting data for 2020-04-21\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 131 Tweets from @firstpost.\n",
      "Getting data for 2020-04-22\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 121 Tweets from @firstpost.\n",
      "Getting data for 2020-04-23\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 137 Tweets from @firstpost.\n",
      "Getting data for 2020-04-24\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 113 Tweets from @firstpost.\n",
      "Getting data for 2020-04-25\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 60 Tweets from @firstpost.\n",
      "Getting data for 2020-04-26\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 65 Tweets from @firstpost.\n",
      "Getting data for 2020-04-27\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 121 Tweets from @firstpost.\n",
      "Getting data for 2020-04-28\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 136 Tweets from @firstpost.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting data for 2020-04-29\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 124 Tweets from @firstpost.\n",
      "Getting data for 2020-04-30\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 118 Tweets from @firstpost.\n",
      "Getting data for 2020-05-01\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 87 Tweets from @firstpost.\n",
      "Getting data for 2020-05-02\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 74 Tweets from @firstpost.\n",
      "Getting data for 2020-05-03\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 76 Tweets from @firstpost.\n",
      "Getting data for 2020-05-04\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 116 Tweets from @firstpost.\n",
      "Getting data for 2020-05-05\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 144 Tweets from @firstpost.\n",
      "Getting data for 2020-05-06\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 134 Tweets from @firstpost.\n",
      "Getting data for 2020-05-07\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 136 Tweets from @firstpost.\n",
      "Getting data for 2020-05-08\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 108 Tweets from @firstpost.\n",
      "Getting data for 2020-05-09\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 77 Tweets from @firstpost.\n",
      "Getting data for 2020-05-10\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 74 Tweets from @firstpost.\n",
      "Getting data for 2020-05-11\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 110 Tweets from @firstpost.\n",
      "Getting data for 2020-05-12\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 135 Tweets from @firstpost.\n",
      "Getting data for 2020-05-13\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 142 Tweets from @firstpost.\n",
      "Getting data for 2020-05-14\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 134 Tweets from @firstpost.\n",
      "Getting data for 2020-05-15\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 113 Tweets from @firstpost.\n",
      "Getting data for 2020-05-16\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 69 Tweets from @firstpost.\n",
      "Getting data for 2020-05-17\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 77 Tweets from @firstpost.\n",
      "Getting data for 2020-05-18\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 112 Tweets from @firstpost.\n",
      "Getting data for 2020-05-19\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 118 Tweets from @firstpost.\n",
      "Getting data for 2020-05-20\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 127 Tweets from @firstpost.\n",
      "Getting data for 2020-05-21\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 121 Tweets from @firstpost.\n",
      "Getting data for 2020-05-22\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 103 Tweets from @firstpost.\n",
      "Getting data for 2020-05-23\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 55 Tweets from @firstpost.\n",
      "Getting data for 2020-05-24\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 72 Tweets from @firstpost.\n",
      "Getting data for 2020-05-25\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 78 Tweets from @firstpost.\n",
      "Getting data for 2020-05-26\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 107 Tweets from @firstpost.\n",
      "Getting data for 2020-05-27\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 106 Tweets from @firstpost.\n",
      "Getting data for 2020-05-28\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 105 Tweets from @firstpost.\n",
      "Getting data for 2020-05-29\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 103 Tweets from @firstpost.\n",
      "Getting data for 2020-05-30\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 71 Tweets from @firstpost.\n",
      "time taken: 17.68 mins\n",
      "Directory C:\\Users\\rahul\\News channels data\\fpjindia created\n",
      "Getting data for 2020-01-22\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 122 Tweets from @fpjindia.\n",
      "Getting data for 2020-01-23\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 119 Tweets from @fpjindia.\n",
      "Getting data for 2020-01-24\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 175 Tweets from @fpjindia.\n",
      "Getting data for 2020-01-25\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 69 Tweets from @fpjindia.\n",
      "Getting data for 2020-01-26\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 54 Tweets from @fpjindia.\n",
      "Getting data for 2020-01-27\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 73 Tweets from @fpjindia.\n",
      "Getting data for 2020-01-28\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 95 Tweets from @fpjindia.\n",
      "Getting data for 2020-01-29\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 124 Tweets from @fpjindia.\n",
      "Getting data for 2020-01-30\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 88 Tweets from @fpjindia.\n",
      "Getting data for 2020-01-31\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 123 Tweets from @fpjindia.\n",
      "Getting data for 2020-02-01\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 134 Tweets from @fpjindia.\n",
      "Getting data for 2020-02-02\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 92 Tweets from @fpjindia.\n",
      "Getting data for 2020-02-03\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 50 Tweets from @fpjindia.\n",
      "Getting data for 2020-02-04\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 115 Tweets from @fpjindia.\n",
      "Getting data for 2020-02-05\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 134 Tweets from @fpjindia.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting data for 2020-02-06\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 123 Tweets from @fpjindia.\n",
      "Getting data for 2020-02-07\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 148 Tweets from @fpjindia.\n",
      "Getting data for 2020-02-08\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 203 Tweets from @fpjindia.\n",
      "Getting data for 2020-02-09\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 149 Tweets from @fpjindia.\n",
      "Getting data for 2020-02-10\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 99 Tweets from @fpjindia.\n",
      "Getting data for 2020-02-11\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 184 Tweets from @fpjindia.\n",
      "Getting data for 2020-02-12\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 141 Tweets from @fpjindia.\n",
      "Getting data for 2020-02-13\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 138 Tweets from @fpjindia.\n",
      "Getting data for 2020-02-14\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 128 Tweets from @fpjindia.\n",
      "Getting data for 2020-02-15\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 89 Tweets from @fpjindia.\n",
      "Getting data for 2020-02-16\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 140 Tweets from @fpjindia.\n",
      "Getting data for 2020-02-17\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 124 Tweets from @fpjindia.\n",
      "Getting data for 2020-02-18\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 134 Tweets from @fpjindia.\n",
      "Getting data for 2020-02-19\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 148 Tweets from @fpjindia.\n",
      "Getting data for 2020-02-20\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 114 Tweets from @fpjindia.\n",
      "Getting data for 2020-02-21\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 143 Tweets from @fpjindia.\n",
      "Getting data for 2020-02-22\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 85 Tweets from @fpjindia.\n",
      "Getting data for 2020-02-23\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 119 Tweets from @fpjindia.\n",
      "Getting data for 2020-02-24\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 142 Tweets from @fpjindia.\n",
      "Getting data for 2020-02-25\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 141 Tweets from @fpjindia.\n",
      "Getting data for 2020-02-26\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 145 Tweets from @fpjindia.\n",
      "Getting data for 2020-02-27\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 130 Tweets from @fpjindia.\n",
      "Getting data for 2020-02-28\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 142 Tweets from @fpjindia.\n",
      "Getting data for 2020-02-29\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 111 Tweets from @fpjindia.\n",
      "Getting data for 2020-03-01\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 58 Tweets from @fpjindia.\n",
      "Getting data for 2020-03-02\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 90 Tweets from @fpjindia.\n",
      "Getting data for 2020-03-03\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 106 Tweets from @fpjindia.\n",
      "Getting data for 2020-03-04\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 114 Tweets from @fpjindia.\n",
      "Getting data for 2020-03-05\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 87 Tweets from @fpjindia.\n",
      "Getting data for 2020-03-06\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 88 Tweets from @fpjindia.\n",
      "Getting data for 2020-03-07\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 93 Tweets from @fpjindia.\n",
      "Getting data for 2020-03-08\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 109 Tweets from @fpjindia.\n",
      "Getting data for 2020-03-09\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 88 Tweets from @fpjindia.\n",
      "Getting data for 2020-03-10\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 93 Tweets from @fpjindia.\n",
      "Getting data for 2020-03-11\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 139 Tweets from @fpjindia.\n",
      "Getting data for 2020-03-12\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 78 Tweets from @fpjindia.\n",
      "Getting data for 2020-03-13\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 114 Tweets from @fpjindia.\n",
      "Getting data for 2020-03-14\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 107 Tweets from @fpjindia.\n",
      "Getting data for 2020-03-15\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 76 Tweets from @fpjindia.\n",
      "Getting data for 2020-03-16\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 88 Tweets from @fpjindia.\n",
      "Getting data for 2020-03-17\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 133 Tweets from @fpjindia.\n",
      "Getting data for 2020-03-18\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 118 Tweets from @fpjindia.\n",
      "Getting data for 2020-03-19\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 164 Tweets from @fpjindia.\n",
      "Getting data for 2020-03-20\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 96 Tweets from @fpjindia.\n",
      "Getting data for 2020-03-21\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 67 Tweets from @fpjindia.\n",
      "Getting data for 2020-03-22\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 101 Tweets from @fpjindia.\n",
      "Getting data for 2020-03-23\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 131 Tweets from @fpjindia.\n",
      "Getting data for 2020-03-24\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 120 Tweets from @fpjindia.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting data for 2020-03-25\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 67 Tweets from @fpjindia.\n",
      "Getting data for 2020-03-26\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 84 Tweets from @fpjindia.\n",
      "Getting data for 2020-03-27\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 91 Tweets from @fpjindia.\n",
      "Getting data for 2020-03-28\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 57 Tweets from @fpjindia.\n",
      "Getting data for 2020-03-29\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 48 Tweets from @fpjindia.\n",
      "Getting data for 2020-03-30\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 93 Tweets from @fpjindia.\n",
      "Getting data for 2020-03-31\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 90 Tweets from @fpjindia.\n",
      "Getting data for 2020-04-01\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 108 Tweets from @fpjindia.\n",
      "Getting data for 2020-04-02\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 136 Tweets from @fpjindia.\n",
      "Getting data for 2020-04-03\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 118 Tweets from @fpjindia.\n",
      "Getting data for 2020-04-04\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 66 Tweets from @fpjindia.\n",
      "Getting data for 2020-04-05\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 119 Tweets from @fpjindia.\n",
      "Getting data for 2020-04-06\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 93 Tweets from @fpjindia.\n",
      "Getting data for 2020-04-07\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 91 Tweets from @fpjindia.\n",
      "Getting data for 2020-04-08\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 101 Tweets from @fpjindia.\n",
      "Getting data for 2020-04-09\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 68 Tweets from @fpjindia.\n",
      "Getting data for 2020-04-10\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 75 Tweets from @fpjindia.\n",
      "Getting data for 2020-04-11\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 77 Tweets from @fpjindia.\n",
      "Getting data for 2020-04-12\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 72 Tweets from @fpjindia.\n",
      "Getting data for 2020-04-13\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 96 Tweets from @fpjindia.\n",
      "Getting data for 2020-04-14\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 129 Tweets from @fpjindia.\n",
      "Getting data for 2020-04-15\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 95 Tweets from @fpjindia.\n",
      "Getting data for 2020-04-16\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 108 Tweets from @fpjindia.\n",
      "Getting data for 2020-04-17\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 94 Tweets from @fpjindia.\n",
      "Getting data for 2020-04-18\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 91 Tweets from @fpjindia.\n",
      "Getting data for 2020-04-19\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 102 Tweets from @fpjindia.\n",
      "Getting data for 2020-04-20\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 104 Tweets from @fpjindia.\n",
      "Getting data for 2020-04-21\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 106 Tweets from @fpjindia.\n",
      "Getting data for 2020-04-22\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 112 Tweets from @fpjindia.\n",
      "Getting data for 2020-04-23\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 85 Tweets from @fpjindia.\n",
      "Getting data for 2020-04-24\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 96 Tweets from @fpjindia.\n",
      "Getting data for 2020-04-25\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 94 Tweets from @fpjindia.\n",
      "Getting data for 2020-04-26\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 70 Tweets from @fpjindia.\n",
      "Getting data for 2020-04-27\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 90 Tweets from @fpjindia.\n",
      "Getting data for 2020-04-28\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 117 Tweets from @fpjindia.\n",
      "Getting data for 2020-04-29\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 107 Tweets from @fpjindia.\n",
      "Getting data for 2020-04-30\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 123 Tweets from @fpjindia.\n",
      "Getting data for 2020-05-01\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 97 Tweets from @fpjindia.\n",
      "Getting data for 2020-05-02\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 102 Tweets from @fpjindia.\n",
      "Getting data for 2020-05-03\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 83 Tweets from @fpjindia.\n",
      "Getting data for 2020-05-04\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 59 Tweets from @fpjindia.\n",
      "Getting data for 2020-05-05\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 89 Tweets from @fpjindia.\n",
      "Getting data for 2020-05-06\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 91 Tweets from @fpjindia.\n",
      "Getting data for 2020-05-07\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 113 Tweets from @fpjindia.\n",
      "Getting data for 2020-05-08\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 81 Tweets from @fpjindia.\n",
      "Getting data for 2020-05-09\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 90 Tweets from @fpjindia.\n",
      "Getting data for 2020-05-10\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 94 Tweets from @fpjindia.\n",
      "Getting data for 2020-05-11\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 66 Tweets from @fpjindia.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting data for 2020-05-12\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 157 Tweets from @fpjindia.\n",
      "Getting data for 2020-05-13\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 162 Tweets from @fpjindia.\n",
      "Getting data for 2020-05-14\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 138 Tweets from @fpjindia.\n",
      "Getting data for 2020-05-15\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 89 Tweets from @fpjindia.\n",
      "Getting data for 2020-05-16\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 88 Tweets from @fpjindia.\n",
      "Getting data for 2020-05-17\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 128 Tweets from @fpjindia.\n",
      "Getting data for 2020-05-18\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 91 Tweets from @fpjindia.\n",
      "Getting data for 2020-05-19\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 94 Tweets from @fpjindia.\n",
      "Getting data for 2020-05-20\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 95 Tweets from @fpjindia.\n",
      "Getting data for 2020-05-21\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 107 Tweets from @fpjindia.\n",
      "Getting data for 2020-05-22\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 74 Tweets from @fpjindia.\n",
      "Getting data for 2020-05-23\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 90 Tweets from @fpjindia.\n",
      "Getting data for 2020-05-24\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 78 Tweets from @fpjindia.\n",
      "Getting data for 2020-05-25\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 82 Tweets from @fpjindia.\n",
      "Getting data for 2020-05-26\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 100 Tweets from @fpjindia.\n",
      "Getting data for 2020-05-27\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 73 Tweets from @fpjindia.\n",
      "Getting data for 2020-05-28\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 95 Tweets from @fpjindia.\n",
      "Getting data for 2020-05-29\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 86 Tweets from @fpjindia.\n",
      "Getting data for 2020-05-30\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 82 Tweets from @fpjindia.\n",
      "time taken: 17.56 mins\n",
      "Directory C:\\Users\\rahul\\News channels data\\newslaundry created\n",
      "Getting data for 2020-01-22\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 11 Tweets from @newslaundry.\n",
      "Getting data for 2020-01-23\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 25 Tweets from @newslaundry.\n",
      "Getting data for 2020-01-24\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 22 Tweets from @newslaundry.\n",
      "Getting data for 2020-01-25\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 22 Tweets from @newslaundry.\n",
      "Getting data for 2020-01-26\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 16 Tweets from @newslaundry.\n",
      "Getting data for 2020-01-27\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 16 Tweets from @newslaundry.\n",
      "Getting data for 2020-01-28\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 22 Tweets from @newslaundry.\n",
      "Getting data for 2020-01-29\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 23 Tweets from @newslaundry.\n",
      "Getting data for 2020-01-30\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 21 Tweets from @newslaundry.\n",
      "Getting data for 2020-01-31\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 23 Tweets from @newslaundry.\n",
      "Getting data for 2020-02-01\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 19 Tweets from @newslaundry.\n",
      "Getting data for 2020-02-02\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 17 Tweets from @newslaundry.\n",
      "Getting data for 2020-02-03\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 22 Tweets from @newslaundry.\n",
      "Getting data for 2020-02-04\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 16 Tweets from @newslaundry.\n",
      "Getting data for 2020-02-05\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 19 Tweets from @newslaundry.\n",
      "Getting data for 2020-02-06\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 23 Tweets from @newslaundry.\n",
      "Getting data for 2020-02-07\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 29 Tweets from @newslaundry.\n",
      "Getting data for 2020-02-08\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 27 Tweets from @newslaundry.\n",
      "Getting data for 2020-02-09\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 22 Tweets from @newslaundry.\n",
      "Getting data for 2020-02-10\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 24 Tweets from @newslaundry.\n",
      "Getting data for 2020-02-11\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 79 Tweets from @newslaundry.\n",
      "Getting data for 2020-02-12\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 17 Tweets from @newslaundry.\n",
      "Getting data for 2020-02-13\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 17 Tweets from @newslaundry.\n",
      "Getting data for 2020-02-14\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 17 Tweets from @newslaundry.\n",
      "Getting data for 2020-02-15\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 14 Tweets from @newslaundry.\n",
      "Getting data for 2020-02-16\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 20 Tweets from @newslaundry.\n",
      "Getting data for 2020-02-17\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 19 Tweets from @newslaundry.\n",
      "Getting data for 2020-02-18\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 20 Tweets from @newslaundry.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting data for 2020-02-19\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 18 Tweets from @newslaundry.\n",
      "Getting data for 2020-02-20\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 21 Tweets from @newslaundry.\n",
      "Getting data for 2020-02-21\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 21 Tweets from @newslaundry.\n",
      "Getting data for 2020-02-22\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 19 Tweets from @newslaundry.\n",
      "Getting data for 2020-02-23\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 20 Tweets from @newslaundry.\n",
      "Getting data for 2020-02-24\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 16 Tweets from @newslaundry.\n",
      "Getting data for 2020-02-25\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 25 Tweets from @newslaundry.\n",
      "Getting data for 2020-02-26\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 32 Tweets from @newslaundry.\n",
      "Getting data for 2020-02-27\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 25 Tweets from @newslaundry.\n",
      "Getting data for 2020-02-28\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 23 Tweets from @newslaundry.\n",
      "Getting data for 2020-02-29\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 23 Tweets from @newslaundry.\n",
      "Getting data for 2020-03-01\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 17 Tweets from @newslaundry.\n",
      "Getting data for 2020-03-02\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 21 Tweets from @newslaundry.\n",
      "Getting data for 2020-03-03\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 18 Tweets from @newslaundry.\n",
      "Getting data for 2020-03-04\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 20 Tweets from @newslaundry.\n",
      "Getting data for 2020-03-05\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 30 Tweets from @newslaundry.\n",
      "Getting data for 2020-03-06\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 24 Tweets from @newslaundry.\n",
      "Getting data for 2020-03-07\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 20 Tweets from @newslaundry.\n",
      "Getting data for 2020-03-08\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 22 Tweets from @newslaundry.\n",
      "Getting data for 2020-03-09\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 23 Tweets from @newslaundry.\n",
      "Getting data for 2020-03-10\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 12 Tweets from @newslaundry.\n",
      "Getting data for 2020-03-11\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 8 Tweets from @newslaundry.\n",
      "Getting data for 2020-03-12\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 15 Tweets from @newslaundry.\n",
      "Getting data for 2020-03-13\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 22 Tweets from @newslaundry.\n",
      "Getting data for 2020-03-14\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 14 Tweets from @newslaundry.\n",
      "Getting data for 2020-03-15\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 14 Tweets from @newslaundry.\n",
      "Getting data for 2020-03-16\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 22 Tweets from @newslaundry.\n",
      "Getting data for 2020-03-17\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 25 Tweets from @newslaundry.\n",
      "Getting data for 2020-03-18\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 20 Tweets from @newslaundry.\n",
      "Getting data for 2020-03-19\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 19 Tweets from @newslaundry.\n",
      "Getting data for 2020-03-20\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 22 Tweets from @newslaundry.\n",
      "Getting data for 2020-03-21\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 18 Tweets from @newslaundry.\n",
      "Getting data for 2020-03-22\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 24 Tweets from @newslaundry.\n",
      "Getting data for 2020-03-23\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 25 Tweets from @newslaundry.\n",
      "Getting data for 2020-03-24\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 25 Tweets from @newslaundry.\n",
      "Getting data for 2020-03-25\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 18 Tweets from @newslaundry.\n",
      "Getting data for 2020-03-26\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 22 Tweets from @newslaundry.\n",
      "Getting data for 2020-03-27\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 21 Tweets from @newslaundry.\n",
      "Getting data for 2020-03-28\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 22 Tweets from @newslaundry.\n",
      "Getting data for 2020-03-29\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 15 Tweets from @newslaundry.\n",
      "Getting data for 2020-03-30\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 27 Tweets from @newslaundry.\n",
      "Getting data for 2020-03-31\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 20 Tweets from @newslaundry.\n",
      "Getting data for 2020-04-01\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 21 Tweets from @newslaundry.\n",
      "Getting data for 2020-04-02\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 19 Tweets from @newslaundry.\n",
      "Getting data for 2020-04-03\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 18 Tweets from @newslaundry.\n",
      "Getting data for 2020-04-04\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 29 Tweets from @newslaundry.\n",
      "Getting data for 2020-04-05\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 18 Tweets from @newslaundry.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting data for 2020-04-06\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 19 Tweets from @newslaundry.\n",
      "Getting data for 2020-04-07\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 20 Tweets from @newslaundry.\n",
      "Getting data for 2020-04-08\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 19 Tweets from @newslaundry.\n",
      "Getting data for 2020-04-09\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 28 Tweets from @newslaundry.\n",
      "Getting data for 2020-04-10\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 26 Tweets from @newslaundry.\n",
      "Getting data for 2020-04-11\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 20 Tweets from @newslaundry.\n",
      "Getting data for 2020-04-12\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 15 Tweets from @newslaundry.\n",
      "Getting data for 2020-04-13\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 18 Tweets from @newslaundry.\n",
      "Getting data for 2020-04-14\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 20 Tweets from @newslaundry.\n",
      "Getting data for 2020-04-15\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 17 Tweets from @newslaundry.\n",
      "Getting data for 2020-04-16\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 24 Tweets from @newslaundry.\n",
      "Getting data for 2020-04-17\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 21 Tweets from @newslaundry.\n",
      "Getting data for 2020-04-18\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 17 Tweets from @newslaundry.\n",
      "Getting data for 2020-04-19\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 19 Tweets from @newslaundry.\n",
      "Getting data for 2020-04-20\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 18 Tweets from @newslaundry.\n",
      "Getting data for 2020-04-21\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 24 Tweets from @newslaundry.\n",
      "Getting data for 2020-04-22\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 21 Tweets from @newslaundry.\n",
      "Getting data for 2020-04-23\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 33 Tweets from @newslaundry.\n",
      "Getting data for 2020-04-24\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 21 Tweets from @newslaundry.\n",
      "Getting data for 2020-04-25\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 20 Tweets from @newslaundry.\n",
      "Getting data for 2020-04-26\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 21 Tweets from @newslaundry.\n",
      "Getting data for 2020-04-27\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 19 Tweets from @newslaundry.\n",
      "Getting data for 2020-04-28\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 21 Tweets from @newslaundry.\n",
      "Getting data for 2020-04-29\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 16 Tweets from @newslaundry.\n",
      "Getting data for 2020-04-30\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 25 Tweets from @newslaundry.\n",
      "Getting data for 2020-05-01\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 33 Tweets from @newslaundry.\n",
      "Getting data for 2020-05-02\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 23 Tweets from @newslaundry.\n",
      "Getting data for 2020-05-03\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 33 Tweets from @newslaundry.\n",
      "Getting data for 2020-05-04\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 18 Tweets from @newslaundry.\n",
      "Getting data for 2020-05-05\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 20 Tweets from @newslaundry.\n",
      "Getting data for 2020-05-06\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 15 Tweets from @newslaundry.\n",
      "Getting data for 2020-05-07\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 24 Tweets from @newslaundry.\n",
      "Getting data for 2020-05-08\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 23 Tweets from @newslaundry.\n",
      "Getting data for 2020-05-09\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 24 Tweets from @newslaundry.\n",
      "Getting data for 2020-05-10\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 15 Tweets from @newslaundry.\n",
      "Getting data for 2020-05-11\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 15 Tweets from @newslaundry.\n",
      "Getting data for 2020-05-12\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 23 Tweets from @newslaundry.\n",
      "Getting data for 2020-05-13\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 23 Tweets from @newslaundry.\n",
      "Getting data for 2020-05-14\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 17 Tweets from @newslaundry.\n",
      "Getting data for 2020-05-15\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 21 Tweets from @newslaundry.\n",
      "Getting data for 2020-05-16\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 28 Tweets from @newslaundry.\n",
      "Getting data for 2020-05-17\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 22 Tweets from @newslaundry.\n",
      "Getting data for 2020-05-18\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 14 Tweets from @newslaundry.\n",
      "Getting data for 2020-05-19\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 25 Tweets from @newslaundry.\n",
      "Getting data for 2020-05-20\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 24 Tweets from @newslaundry.\n",
      "Getting data for 2020-05-21\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 25 Tweets from @newslaundry.\n",
      "Getting data for 2020-05-22\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 27 Tweets from @newslaundry.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting data for 2020-05-23\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 38 Tweets from @newslaundry.\n",
      "Getting data for 2020-05-24\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 34 Tweets from @newslaundry.\n",
      "Getting data for 2020-05-25\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 33 Tweets from @newslaundry.\n",
      "Getting data for 2020-05-26\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 29 Tweets from @newslaundry.\n",
      "Getting data for 2020-05-27\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 22 Tweets from @newslaundry.\n",
      "Getting data for 2020-05-28\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 35 Tweets from @newslaundry.\n",
      "Getting data for 2020-05-29\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 26 Tweets from @newslaundry.\n",
      "Getting data for 2020-05-30\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 23 Tweets from @newslaundry.\n",
      "time taken: 13.81 mins\n",
      "Directory C:\\Users\\rahul\\News channels data\\TheQuint created\n",
      "Getting data for 2020-01-22\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 193 Tweets from @TheQuint.\n",
      "Getting data for 2020-01-23\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 220 Tweets from @TheQuint.\n",
      "Getting data for 2020-01-24\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 189 Tweets from @TheQuint.\n",
      "Getting data for 2020-01-25\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 163 Tweets from @TheQuint.\n",
      "Getting data for 2020-01-26\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 159 Tweets from @TheQuint.\n",
      "Getting data for 2020-01-27\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 196 Tweets from @TheQuint.\n",
      "Getting data for 2020-01-28\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 174 Tweets from @TheQuint.\n",
      "Getting data for 2020-01-29\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 223 Tweets from @TheQuint.\n",
      "Getting data for 2020-01-30\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 223 Tweets from @TheQuint.\n",
      "Getting data for 2020-01-31\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 251 Tweets from @TheQuint.\n",
      "Getting data for 2020-02-01\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 243 Tweets from @TheQuint.\n",
      "Getting data for 2020-02-02\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 107 Tweets from @TheQuint.\n",
      "Getting data for 2020-02-03\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 199 Tweets from @TheQuint.\n",
      "Getting data for 2020-02-04\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 203 Tweets from @TheQuint.\n",
      "Getting data for 2020-02-05\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 223 Tweets from @TheQuint.\n",
      "Getting data for 2020-02-06\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 231 Tweets from @TheQuint.\n",
      "Getting data for 2020-02-07\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 199 Tweets from @TheQuint.\n",
      "Getting data for 2020-02-08\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 179 Tweets from @TheQuint.\n",
      "Getting data for 2020-02-09\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 133 Tweets from @TheQuint.\n",
      "Getting data for 2020-02-10\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 207 Tweets from @TheQuint.\n",
      "Getting data for 2020-02-11\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 330 Tweets from @TheQuint.\n",
      "Getting data for 2020-02-12\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 225 Tweets from @TheQuint.\n",
      "Getting data for 2020-02-13\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 193 Tweets from @TheQuint.\n",
      "Getting data for 2020-02-14\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 204 Tweets from @TheQuint.\n",
      "Getting data for 2020-02-15\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 127 Tweets from @TheQuint.\n",
      "Getting data for 2020-02-16\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 105 Tweets from @TheQuint.\n",
      "Getting data for 2020-02-17\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 181 Tweets from @TheQuint.\n",
      "Getting data for 2020-02-18\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 172 Tweets from @TheQuint.\n",
      "Getting data for 2020-02-19\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 177 Tweets from @TheQuint.\n",
      "Getting data for 2020-02-20\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 194 Tweets from @TheQuint.\n",
      "Getting data for 2020-02-21\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 190 Tweets from @TheQuint.\n",
      "Getting data for 2020-02-22\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 140 Tweets from @TheQuint.\n",
      "Getting data for 2020-02-23\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 105 Tweets from @TheQuint.\n",
      "Getting data for 2020-02-24\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 250 Tweets from @TheQuint.\n",
      "Getting data for 2020-02-25\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 244 Tweets from @TheQuint.\n",
      "Getting data for 2020-02-26\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 219 Tweets from @TheQuint.\n",
      "Getting data for 2020-02-27\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 200 Tweets from @TheQuint.\n",
      "Getting data for 2020-02-28\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 175 Tweets from @TheQuint.\n",
      "Getting data for 2020-02-29\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 136 Tweets from @TheQuint.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting data for 2020-03-01\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 91 Tweets from @TheQuint.\n",
      "Getting data for 2020-03-02\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 189 Tweets from @TheQuint.\n",
      "Getting data for 2020-03-03\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 206 Tweets from @TheQuint.\n",
      "Getting data for 2020-03-04\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 193 Tweets from @TheQuint.\n",
      "Getting data for 2020-03-05\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 222 Tweets from @TheQuint.\n",
      "Getting data for 2020-03-06\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 191 Tweets from @TheQuint.\n",
      "Getting data for 2020-03-07\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 147 Tweets from @TheQuint.\n",
      "Getting data for 2020-03-08\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 169 Tweets from @TheQuint.\n",
      "Getting data for 2020-03-09\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 199 Tweets from @TheQuint.\n",
      "Getting data for 2020-03-10\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 143 Tweets from @TheQuint.\n",
      "Getting data for 2020-03-11\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 268 Tweets from @TheQuint.\n",
      "Getting data for 2020-03-12\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 277 Tweets from @TheQuint.\n",
      "Getting data for 2020-03-13\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 250 Tweets from @TheQuint.\n",
      "Getting data for 2020-03-14\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 131 Tweets from @TheQuint.\n",
      "Getting data for 2020-03-15\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 131 Tweets from @TheQuint.\n",
      "Getting data for 2020-03-16\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 261 Tweets from @TheQuint.\n",
      "Getting data for 2020-03-17\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 288 Tweets from @TheQuint.\n",
      "Getting data for 2020-03-18\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 305 Tweets from @TheQuint.\n",
      "Getting data for 2020-03-19\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 277 Tweets from @TheQuint.\n",
      "Getting data for 2020-03-20\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 307 Tweets from @TheQuint.\n",
      "Getting data for 2020-03-21\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 200 Tweets from @TheQuint.\n",
      "Getting data for 2020-03-22\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 151 Tweets from @TheQuint.\n",
      "Getting data for 2020-03-23\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 218 Tweets from @TheQuint.\n",
      "Getting data for 2020-03-24\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 256 Tweets from @TheQuint.\n",
      "Getting data for 2020-03-25\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 254 Tweets from @TheQuint.\n",
      "Getting data for 2020-03-26\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 220 Tweets from @TheQuint.\n",
      "Getting data for 2020-03-27\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 252 Tweets from @TheQuint.\n",
      "Getting data for 2020-03-28\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 161 Tweets from @TheQuint.\n",
      "Getting data for 2020-03-29\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 126 Tweets from @TheQuint.\n",
      "Getting data for 2020-03-30\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 235 Tweets from @TheQuint.\n",
      "Getting data for 2020-03-31\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 271 Tweets from @TheQuint.\n",
      "Getting data for 2020-04-01\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 215 Tweets from @TheQuint.\n",
      "Getting data for 2020-04-02\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 216 Tweets from @TheQuint.\n",
      "Getting data for 2020-04-03\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 201 Tweets from @TheQuint.\n",
      "Getting data for 2020-04-04\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 185 Tweets from @TheQuint.\n",
      "Getting data for 2020-04-05\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 122 Tweets from @TheQuint.\n",
      "Getting data for 2020-04-06\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 222 Tweets from @TheQuint.\n",
      "Getting data for 2020-04-07\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 223 Tweets from @TheQuint.\n",
      "Getting data for 2020-04-08\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 204 Tweets from @TheQuint.\n",
      "Getting data for 2020-04-09\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 208 Tweets from @TheQuint.\n",
      "Getting data for 2020-04-10\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 140 Tweets from @TheQuint.\n",
      "Getting data for 2020-04-11\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 152 Tweets from @TheQuint.\n",
      "Getting data for 2020-04-12\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 107 Tweets from @TheQuint.\n",
      "Getting data for 2020-04-13\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 168 Tweets from @TheQuint.\n",
      "Getting data for 2020-04-14\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 164 Tweets from @TheQuint.\n",
      "Getting data for 2020-04-15\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 182 Tweets from @TheQuint.\n",
      "Getting data for 2020-04-16\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 178 Tweets from @TheQuint.\n",
      "Getting data for 2020-04-17\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 158 Tweets from @TheQuint.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting data for 2020-04-18\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 142 Tweets from @TheQuint.\n",
      "Getting data for 2020-04-19\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 101 Tweets from @TheQuint.\n",
      "Getting data for 2020-04-20\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 145 Tweets from @TheQuint.\n",
      "Getting data for 2020-04-21\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 149 Tweets from @TheQuint.\n",
      "Getting data for 2020-04-22\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 163 Tweets from @TheQuint.\n",
      "Getting data for 2020-04-23\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 150 Tweets from @TheQuint.\n",
      "Getting data for 2020-04-24\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 156 Tweets from @TheQuint.\n",
      "Getting data for 2020-04-25\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 120 Tweets from @TheQuint.\n",
      "Getting data for 2020-04-26\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 116 Tweets from @TheQuint.\n",
      "Getting data for 2020-04-27\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 139 Tweets from @TheQuint.\n",
      "Getting data for 2020-04-28\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 153 Tweets from @TheQuint.\n",
      "Getting data for 2020-04-29\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 164 Tweets from @TheQuint.\n",
      "Getting data for 2020-04-30\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 169 Tweets from @TheQuint.\n",
      "Getting data for 2020-05-01\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 127 Tweets from @TheQuint.\n",
      "Getting data for 2020-05-02\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 118 Tweets from @TheQuint.\n",
      "Getting data for 2020-05-03\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 114 Tweets from @TheQuint.\n",
      "Getting data for 2020-05-04\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 132 Tweets from @TheQuint.\n",
      "Getting data for 2020-05-05\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 141 Tweets from @TheQuint.\n",
      "Getting data for 2020-05-06\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 172 Tweets from @TheQuint.\n",
      "Getting data for 2020-05-07\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 143 Tweets from @TheQuint.\n",
      "Getting data for 2020-05-08\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 129 Tweets from @TheQuint.\n",
      "Getting data for 2020-05-09\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 131 Tweets from @TheQuint.\n",
      "Getting data for 2020-05-10\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 84 Tweets from @TheQuint.\n",
      "Getting data for 2020-05-11\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 128 Tweets from @TheQuint.\n",
      "Getting data for 2020-05-12\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 143 Tweets from @TheQuint.\n",
      "Getting data for 2020-05-13\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 147 Tweets from @TheQuint.\n",
      "Getting data for 2020-05-14\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 168 Tweets from @TheQuint.\n",
      "Getting data for 2020-05-15\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 148 Tweets from @TheQuint.\n",
      "Getting data for 2020-05-16\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 138 Tweets from @TheQuint.\n",
      "Getting data for 2020-05-17\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 97 Tweets from @TheQuint.\n",
      "Getting data for 2020-05-18\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 138 Tweets from @TheQuint.\n",
      "Getting data for 2020-05-19\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 143 Tweets from @TheQuint.\n",
      "Getting data for 2020-05-20\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 144 Tweets from @TheQuint.\n",
      "Getting data for 2020-05-21\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 149 Tweets from @TheQuint.\n",
      "Getting data for 2020-05-22\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 156 Tweets from @TheQuint.\n",
      "Getting data for 2020-05-23\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 108 Tweets from @TheQuint.\n",
      "Getting data for 2020-05-24\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 101 Tweets from @TheQuint.\n",
      "Getting data for 2020-05-25\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 133 Tweets from @TheQuint.\n",
      "Getting data for 2020-05-26\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 129 Tweets from @TheQuint.\n",
      "Getting data for 2020-05-27\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 136 Tweets from @TheQuint.\n",
      "Getting data for 2020-05-28\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 150 Tweets from @TheQuint.\n",
      "Getting data for 2020-05-29\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 146 Tweets from @TheQuint.\n",
      "Getting data for 2020-05-30\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 102 Tweets from @TheQuint.\n",
      "time taken: 21.11 mins\n",
      "Directory C:\\Users\\rahul\\News channels data\\ScoopWhoop created\n",
      "Getting data for 2020-01-22\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 1 Tweets from @ScoopWhoop.\n",
      "Getting data for 2020-01-23\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @ScoopWhoop.\n",
      "Getting data for 2020-01-24\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 1 Tweets from @ScoopWhoop.\n",
      "Getting data for 2020-01-25\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 2 Tweets from @ScoopWhoop.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting data for 2020-01-26\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 2 Tweets from @ScoopWhoop.\n",
      "Getting data for 2020-01-27\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @ScoopWhoop.\n",
      "Getting data for 2020-01-28\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @ScoopWhoop.\n",
      "Getting data for 2020-01-29\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 1 Tweets from @ScoopWhoop.\n",
      "Getting data for 2020-01-30\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 2 Tweets from @ScoopWhoop.\n",
      "Getting data for 2020-01-31\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 1 Tweets from @ScoopWhoop.\n",
      "Getting data for 2020-02-01\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @ScoopWhoop.\n",
      "Getting data for 2020-02-02\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @ScoopWhoop.\n",
      "Getting data for 2020-02-03\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 1 Tweets from @ScoopWhoop.\n",
      "Getting data for 2020-02-04\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 1 Tweets from @ScoopWhoop.\n",
      "Getting data for 2020-02-05\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 1 Tweets from @ScoopWhoop.\n",
      "Getting data for 2020-02-06\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 1 Tweets from @ScoopWhoop.\n",
      "Getting data for 2020-02-07\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 2 Tweets from @ScoopWhoop.\n",
      "Getting data for 2020-02-08\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 1 Tweets from @ScoopWhoop.\n",
      "Getting data for 2020-02-09\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 3 Tweets from @ScoopWhoop.\n",
      "Getting data for 2020-02-10\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 9 Tweets from @ScoopWhoop.\n",
      "Getting data for 2020-02-11\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 3 Tweets from @ScoopWhoop.\n",
      "Getting data for 2020-02-12\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @ScoopWhoop.\n",
      "Getting data for 2020-02-13\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 2 Tweets from @ScoopWhoop.\n",
      "Getting data for 2020-02-14\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 2 Tweets from @ScoopWhoop.\n",
      "Getting data for 2020-02-15\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 1 Tweets from @ScoopWhoop.\n",
      "Getting data for 2020-02-16\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 2 Tweets from @ScoopWhoop.\n",
      "Getting data for 2020-02-17\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 1 Tweets from @ScoopWhoop.\n",
      "Getting data for 2020-02-18\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @ScoopWhoop.\n",
      "Getting data for 2020-02-19\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @ScoopWhoop.\n",
      "Getting data for 2020-02-20\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 2 Tweets from @ScoopWhoop.\n",
      "Getting data for 2020-02-21\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @ScoopWhoop.\n",
      "Getting data for 2020-02-22\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @ScoopWhoop.\n",
      "Getting data for 2020-02-23\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @ScoopWhoop.\n",
      "Getting data for 2020-02-24\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 1 Tweets from @ScoopWhoop.\n",
      "Getting data for 2020-02-25\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @ScoopWhoop.\n",
      "Getting data for 2020-02-26\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 1 Tweets from @ScoopWhoop.\n",
      "Getting data for 2020-02-27\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @ScoopWhoop.\n",
      "Getting data for 2020-02-28\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @ScoopWhoop.\n",
      "Getting data for 2020-02-29\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 1 Tweets from @ScoopWhoop.\n",
      "Getting data for 2020-03-01\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @ScoopWhoop.\n",
      "Getting data for 2020-03-02\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 1 Tweets from @ScoopWhoop.\n",
      "Getting data for 2020-03-03\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @ScoopWhoop.\n",
      "Getting data for 2020-03-04\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 1 Tweets from @ScoopWhoop.\n",
      "Getting data for 2020-03-05\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @ScoopWhoop.\n",
      "Getting data for 2020-03-06\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 3 Tweets from @ScoopWhoop.\n",
      "Getting data for 2020-03-07\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 3 Tweets from @ScoopWhoop.\n",
      "Getting data for 2020-03-08\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 1 Tweets from @ScoopWhoop.\n",
      "Getting data for 2020-03-09\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 1 Tweets from @ScoopWhoop.\n",
      "Getting data for 2020-03-10\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @ScoopWhoop.\n",
      "Getting data for 2020-03-11\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 1 Tweets from @ScoopWhoop.\n",
      "Getting data for 2020-03-12\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @ScoopWhoop.\n",
      "Getting data for 2020-03-13\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 1 Tweets from @ScoopWhoop.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting data for 2020-03-14\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @ScoopWhoop.\n",
      "Getting data for 2020-03-15\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @ScoopWhoop.\n",
      "Getting data for 2020-03-16\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 1 Tweets from @ScoopWhoop.\n",
      "Getting data for 2020-03-17\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @ScoopWhoop.\n",
      "Getting data for 2020-03-18\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 3 Tweets from @ScoopWhoop.\n",
      "Getting data for 2020-03-19\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 1 Tweets from @ScoopWhoop.\n",
      "Getting data for 2020-03-20\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @ScoopWhoop.\n",
      "Getting data for 2020-03-21\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @ScoopWhoop.\n",
      "Getting data for 2020-03-22\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @ScoopWhoop.\n",
      "Getting data for 2020-03-23\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @ScoopWhoop.\n",
      "Getting data for 2020-03-24\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @ScoopWhoop.\n",
      "Getting data for 2020-03-25\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 1 Tweets from @ScoopWhoop.\n",
      "Getting data for 2020-03-26\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @ScoopWhoop.\n",
      "Getting data for 2020-03-27\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 1 Tweets from @ScoopWhoop.\n",
      "Getting data for 2020-03-28\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 1 Tweets from @ScoopWhoop.\n",
      "Getting data for 2020-03-29\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @ScoopWhoop.\n",
      "Getting data for 2020-03-30\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @ScoopWhoop.\n",
      "Getting data for 2020-03-31\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 1 Tweets from @ScoopWhoop.\n",
      "Getting data for 2020-04-01\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @ScoopWhoop.\n",
      "Getting data for 2020-04-02\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @ScoopWhoop.\n",
      "Getting data for 2020-04-03\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 1 Tweets from @ScoopWhoop.\n",
      "Getting data for 2020-04-04\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @ScoopWhoop.\n",
      "Getting data for 2020-04-05\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 2 Tweets from @ScoopWhoop.\n",
      "Getting data for 2020-04-06\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @ScoopWhoop.\n",
      "Getting data for 2020-04-07\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 1 Tweets from @ScoopWhoop.\n",
      "Getting data for 2020-04-08\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 2 Tweets from @ScoopWhoop.\n",
      "Getting data for 2020-04-09\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @ScoopWhoop.\n",
      "Getting data for 2020-04-10\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @ScoopWhoop.\n",
      "Getting data for 2020-04-11\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 1 Tweets from @ScoopWhoop.\n",
      "Getting data for 2020-04-12\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 1 Tweets from @ScoopWhoop.\n",
      "Getting data for 2020-04-13\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 1 Tweets from @ScoopWhoop.\n",
      "Getting data for 2020-04-14\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 1 Tweets from @ScoopWhoop.\n",
      "Getting data for 2020-04-15\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 2 Tweets from @ScoopWhoop.\n",
      "Getting data for 2020-04-16\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 1 Tweets from @ScoopWhoop.\n",
      "Getting data for 2020-04-17\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 1 Tweets from @ScoopWhoop.\n",
      "Getting data for 2020-04-18\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 1 Tweets from @ScoopWhoop.\n",
      "Getting data for 2020-04-19\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @ScoopWhoop.\n",
      "Getting data for 2020-04-20\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 1 Tweets from @ScoopWhoop.\n",
      "Getting data for 2020-04-21\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 3 Tweets from @ScoopWhoop.\n",
      "Getting data for 2020-04-22\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 1 Tweets from @ScoopWhoop.\n",
      "Getting data for 2020-04-23\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @ScoopWhoop.\n",
      "Getting data for 2020-04-24\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @ScoopWhoop.\n",
      "Getting data for 2020-04-25\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 2 Tweets from @ScoopWhoop.\n",
      "Getting data for 2020-04-26\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @ScoopWhoop.\n",
      "Getting data for 2020-04-27\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @ScoopWhoop.\n",
      "Getting data for 2020-04-28\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 1 Tweets from @ScoopWhoop.\n",
      "Getting data for 2020-04-29\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 2 Tweets from @ScoopWhoop.\n",
      "Getting data for 2020-04-30\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @ScoopWhoop.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting data for 2020-05-01\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 2 Tweets from @ScoopWhoop.\n",
      "Getting data for 2020-05-02\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @ScoopWhoop.\n",
      "Getting data for 2020-05-03\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @ScoopWhoop.\n",
      "Getting data for 2020-05-04\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @ScoopWhoop.\n",
      "Getting data for 2020-05-05\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @ScoopWhoop.\n",
      "Getting data for 2020-05-06\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @ScoopWhoop.\n",
      "Getting data for 2020-05-07\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @ScoopWhoop.\n",
      "Getting data for 2020-05-08\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @ScoopWhoop.\n",
      "Getting data for 2020-05-09\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @ScoopWhoop.\n",
      "Getting data for 2020-05-10\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @ScoopWhoop.\n",
      "Getting data for 2020-05-11\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 1 Tweets from @ScoopWhoop.\n",
      "Getting data for 2020-05-12\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @ScoopWhoop.\n",
      "Getting data for 2020-05-13\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @ScoopWhoop.\n",
      "Getting data for 2020-05-14\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @ScoopWhoop.\n",
      "Getting data for 2020-05-15\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 1 Tweets from @ScoopWhoop.\n",
      "Getting data for 2020-05-16\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 4 Tweets from @ScoopWhoop.\n",
      "Getting data for 2020-05-17\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @ScoopWhoop.\n",
      "Getting data for 2020-05-18\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @ScoopWhoop.\n",
      "Getting data for 2020-05-19\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @ScoopWhoop.\n",
      "Getting data for 2020-05-20\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @ScoopWhoop.\n",
      "Getting data for 2020-05-21\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 1 Tweets from @ScoopWhoop.\n",
      "Getting data for 2020-05-22\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @ScoopWhoop.\n",
      "Getting data for 2020-05-23\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 3 Tweets from @ScoopWhoop.\n",
      "Getting data for 2020-05-24\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @ScoopWhoop.\n",
      "Getting data for 2020-05-25\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 2 Tweets from @ScoopWhoop.\n",
      "Getting data for 2020-05-26\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @ScoopWhoop.\n",
      "Getting data for 2020-05-27\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @ScoopWhoop.\n",
      "Getting data for 2020-05-28\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @ScoopWhoop.\n",
      "Getting data for 2020-05-29\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @ScoopWhoop.\n",
      "Getting data for 2020-05-30\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @ScoopWhoop.\n",
      "time taken: 12.84 mins\n",
      "Directory C:\\Users\\rahul\\News channels data\\scroll_in created\n",
      "Getting data for 2020-01-22\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 107 Tweets from @scroll_in.\n",
      "Getting data for 2020-01-23\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 110 Tweets from @scroll_in.\n",
      "Getting data for 2020-01-24\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 98 Tweets from @scroll_in.\n",
      "Getting data for 2020-01-25\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 81 Tweets from @scroll_in.\n",
      "Getting data for 2020-01-26\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 120 Tweets from @scroll_in.\n",
      "Getting data for 2020-01-27\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 100 Tweets from @scroll_in.\n",
      "Getting data for 2020-01-28\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 101 Tweets from @scroll_in.\n",
      "Getting data for 2020-01-29\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 110 Tweets from @scroll_in.\n",
      "Getting data for 2020-01-30\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 146 Tweets from @scroll_in.\n",
      "Getting data for 2020-01-31\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 135 Tweets from @scroll_in.\n",
      "Getting data for 2020-02-01\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 92 Tweets from @scroll_in.\n",
      "Getting data for 2020-02-02\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 96 Tweets from @scroll_in.\n",
      "Getting data for 2020-02-03\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 112 Tweets from @scroll_in.\n",
      "Getting data for 2020-02-04\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 110 Tweets from @scroll_in.\n",
      "Getting data for 2020-02-05\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 110 Tweets from @scroll_in.\n",
      "Getting data for 2020-02-06\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 97 Tweets from @scroll_in.\n",
      "Getting data for 2020-02-07\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 104 Tweets from @scroll_in.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting data for 2020-02-08\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 77 Tweets from @scroll_in.\n",
      "Getting data for 2020-02-09\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 89 Tweets from @scroll_in.\n",
      "Getting data for 2020-02-10\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 115 Tweets from @scroll_in.\n",
      "Getting data for 2020-02-11\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 144 Tweets from @scroll_in.\n",
      "Getting data for 2020-02-12\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 98 Tweets from @scroll_in.\n",
      "Getting data for 2020-02-13\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 100 Tweets from @scroll_in.\n",
      "Getting data for 2020-02-14\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 101 Tweets from @scroll_in.\n",
      "Getting data for 2020-02-15\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 80 Tweets from @scroll_in.\n",
      "Getting data for 2020-02-16\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 87 Tweets from @scroll_in.\n",
      "Getting data for 2020-02-17\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 98 Tweets from @scroll_in.\n",
      "Getting data for 2020-02-18\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 89 Tweets from @scroll_in.\n",
      "Getting data for 2020-02-19\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 91 Tweets from @scroll_in.\n",
      "Getting data for 2020-02-20\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 92 Tweets from @scroll_in.\n",
      "Getting data for 2020-02-21\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 93 Tweets from @scroll_in.\n",
      "Getting data for 2020-02-22\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 62 Tweets from @scroll_in.\n",
      "Getting data for 2020-02-23\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 94 Tweets from @scroll_in.\n",
      "Getting data for 2020-02-24\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 131 Tweets from @scroll_in.\n",
      "Getting data for 2020-02-25\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 141 Tweets from @scroll_in.\n",
      "Getting data for 2020-02-26\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 226 Tweets from @scroll_in.\n",
      "Getting data for 2020-02-27\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 176 Tweets from @scroll_in.\n",
      "Getting data for 2020-02-28\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 107 Tweets from @scroll_in.\n",
      "Getting data for 2020-02-29\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 77 Tweets from @scroll_in.\n",
      "Getting data for 2020-03-01\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 96 Tweets from @scroll_in.\n",
      "Getting data for 2020-03-02\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 127 Tweets from @scroll_in.\n",
      "Getting data for 2020-03-03\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 106 Tweets from @scroll_in.\n",
      "Getting data for 2020-03-04\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 198 Tweets from @scroll_in.\n",
      "Getting data for 2020-03-05\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 150 Tweets from @scroll_in.\n",
      "Getting data for 2020-03-06\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 109 Tweets from @scroll_in.\n",
      "Getting data for 2020-03-07\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 78 Tweets from @scroll_in.\n",
      "Getting data for 2020-03-08\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 84 Tweets from @scroll_in.\n",
      "Getting data for 2020-03-09\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 105 Tweets from @scroll_in.\n",
      "Getting data for 2020-03-10\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 117 Tweets from @scroll_in.\n",
      "Getting data for 2020-03-11\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 175 Tweets from @scroll_in.\n",
      "Getting data for 2020-03-12\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 142 Tweets from @scroll_in.\n",
      "Getting data for 2020-03-13\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 137 Tweets from @scroll_in.\n",
      "Getting data for 2020-03-14\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 104 Tweets from @scroll_in.\n",
      "Getting data for 2020-03-15\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 133 Tweets from @scroll_in.\n",
      "Getting data for 2020-03-16\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 180 Tweets from @scroll_in.\n",
      "Getting data for 2020-03-17\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 179 Tweets from @scroll_in.\n",
      "Getting data for 2020-03-18\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 212 Tweets from @scroll_in.\n",
      "Getting data for 2020-03-19\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 230 Tweets from @scroll_in.\n",
      "Getting data for 2020-03-20\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 155 Tweets from @scroll_in.\n",
      "Getting data for 2020-03-21\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 170 Tweets from @scroll_in.\n",
      "Getting data for 2020-03-22\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 182 Tweets from @scroll_in.\n",
      "Getting data for 2020-03-23\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 156 Tweets from @scroll_in.\n",
      "Getting data for 2020-03-24\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 270 Tweets from @scroll_in.\n",
      "Getting data for 2020-03-25\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 207 Tweets from @scroll_in.\n",
      "Getting data for 2020-03-26\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 217 Tweets from @scroll_in.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting data for 2020-03-27\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 143 Tweets from @scroll_in.\n",
      "Getting data for 2020-03-28\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 128 Tweets from @scroll_in.\n",
      "Getting data for 2020-03-29\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 149 Tweets from @scroll_in.\n",
      "Getting data for 2020-03-30\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 199 Tweets from @scroll_in.\n",
      "Getting data for 2020-03-31\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 183 Tweets from @scroll_in.\n",
      "Getting data for 2020-04-01\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 212 Tweets from @scroll_in.\n",
      "Getting data for 2020-04-02\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 219 Tweets from @scroll_in.\n",
      "Getting data for 2020-04-03\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 186 Tweets from @scroll_in.\n",
      "Getting data for 2020-04-04\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 108 Tweets from @scroll_in.\n",
      "Getting data for 2020-04-05\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 128 Tweets from @scroll_in.\n",
      "Getting data for 2020-04-06\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 176 Tweets from @scroll_in.\n",
      "Getting data for 2020-04-07\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 188 Tweets from @scroll_in.\n",
      "Getting data for 2020-04-08\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 178 Tweets from @scroll_in.\n",
      "Getting data for 2020-04-09\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 197 Tweets from @scroll_in.\n",
      "Getting data for 2020-04-10\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 145 Tweets from @scroll_in.\n",
      "Getting data for 2020-04-11\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 110 Tweets from @scroll_in.\n",
      "Getting data for 2020-04-12\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 152 Tweets from @scroll_in.\n",
      "Getting data for 2020-04-13\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 208 Tweets from @scroll_in.\n",
      "Getting data for 2020-04-14\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 205 Tweets from @scroll_in.\n",
      "Getting data for 2020-04-15\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 186 Tweets from @scroll_in.\n",
      "Getting data for 2020-04-16\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 179 Tweets from @scroll_in.\n",
      "Getting data for 2020-04-17\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 152 Tweets from @scroll_in.\n",
      "Getting data for 2020-04-18\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 113 Tweets from @scroll_in.\n",
      "Getting data for 2020-04-19\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 169 Tweets from @scroll_in.\n",
      "Getting data for 2020-04-20\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 162 Tweets from @scroll_in.\n",
      "Getting data for 2020-04-21\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 176 Tweets from @scroll_in.\n",
      "Getting data for 2020-04-22\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 174 Tweets from @scroll_in.\n",
      "Getting data for 2020-04-23\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 195 Tweets from @scroll_in.\n",
      "Getting data for 2020-04-24\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 147 Tweets from @scroll_in.\n",
      "Getting data for 2020-04-25\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 82 Tweets from @scroll_in.\n",
      "Getting data for 2020-04-26\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 148 Tweets from @scroll_in.\n",
      "Getting data for 2020-04-27\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 185 Tweets from @scroll_in.\n",
      "Getting data for 2020-04-28\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 82 Tweets from @scroll_in.\n",
      "Getting data for 2020-04-29\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 195 Tweets from @scroll_in.\n",
      "Getting data for 2020-04-30\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 185 Tweets from @scroll_in.\n",
      "Getting data for 2020-05-01\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 179 Tweets from @scroll_in.\n",
      "Getting data for 2020-05-02\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 104 Tweets from @scroll_in.\n",
      "Getting data for 2020-05-03\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 134 Tweets from @scroll_in.\n",
      "Getting data for 2020-05-04\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 155 Tweets from @scroll_in.\n",
      "Getting data for 2020-05-05\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 155 Tweets from @scroll_in.\n",
      "Getting data for 2020-05-06\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 148 Tweets from @scroll_in.\n",
      "Getting data for 2020-05-07\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 165 Tweets from @scroll_in.\n",
      "Getting data for 2020-05-08\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 173 Tweets from @scroll_in.\n",
      "Getting data for 2020-05-09\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 106 Tweets from @scroll_in.\n",
      "Getting data for 2020-05-10\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 121 Tweets from @scroll_in.\n",
      "Getting data for 2020-05-11\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 206 Tweets from @scroll_in.\n",
      "Getting data for 2020-05-12\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 209 Tweets from @scroll_in.\n",
      "Getting data for 2020-05-13\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 183 Tweets from @scroll_in.\n",
      "Getting data for 2020-05-14\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 186 Tweets from @scroll_in.\n",
      "Getting data for 2020-05-15\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 153 Tweets from @scroll_in.\n",
      "Getting data for 2020-05-16\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 106 Tweets from @scroll_in.\n",
      "Getting data for 2020-05-17\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 161 Tweets from @scroll_in.\n",
      "Getting data for 2020-05-18\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 189 Tweets from @scroll_in.\n",
      "Getting data for 2020-05-19\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 176 Tweets from @scroll_in.\n",
      "Getting data for 2020-05-20\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 157 Tweets from @scroll_in.\n",
      "Getting data for 2020-05-21\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 184 Tweets from @scroll_in.\n",
      "Getting data for 2020-05-22\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 163 Tweets from @scroll_in.\n",
      "Getting data for 2020-05-23\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 146 Tweets from @scroll_in.\n",
      "Getting data for 2020-05-24\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 124 Tweets from @scroll_in.\n",
      "Getting data for 2020-05-25\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 169 Tweets from @scroll_in.\n",
      "Getting data for 2020-05-26\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 164 Tweets from @scroll_in.\n",
      "Getting data for 2020-05-27\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 171 Tweets from @scroll_in.\n",
      "Getting data for 2020-05-28\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 197 Tweets from @scroll_in.\n",
      "Getting data for 2020-05-29\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 175 Tweets from @scroll_in.\n",
      "Getting data for 2020-05-30\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 135 Tweets from @scroll_in.\n",
      "time taken: 19.23 mins\n",
      "Directory C:\\Users\\rahul\\News channels data\\SwarajyaMag created\n",
      "Getting data for 2020-01-22\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 63 Tweets from @SwarajyaMag.\n",
      "Getting data for 2020-01-23\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 74 Tweets from @SwarajyaMag.\n",
      "Getting data for 2020-01-24\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 73 Tweets from @SwarajyaMag.\n",
      "Getting data for 2020-01-25\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 48 Tweets from @SwarajyaMag.\n",
      "Getting data for 2020-01-26\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 31 Tweets from @SwarajyaMag.\n",
      "Getting data for 2020-01-27\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 57 Tweets from @SwarajyaMag.\n",
      "Getting data for 2020-01-28\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 72 Tweets from @SwarajyaMag.\n",
      "Getting data for 2020-01-29\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 81 Tweets from @SwarajyaMag.\n",
      "Getting data for 2020-01-30\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 64 Tweets from @SwarajyaMag.\n",
      "Getting data for 2020-01-31\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 57 Tweets from @SwarajyaMag.\n",
      "Getting data for 2020-02-01\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 100 Tweets from @SwarajyaMag.\n",
      "Getting data for 2020-02-02\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 32 Tweets from @SwarajyaMag.\n",
      "Getting data for 2020-02-03\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 54 Tweets from @SwarajyaMag.\n",
      "Getting data for 2020-02-04\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 50 Tweets from @SwarajyaMag.\n",
      "Getting data for 2020-02-05\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 68 Tweets from @SwarajyaMag.\n",
      "Getting data for 2020-02-06\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 71 Tweets from @SwarajyaMag.\n",
      "Getting data for 2020-02-07\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 72 Tweets from @SwarajyaMag.\n",
      "Getting data for 2020-02-08\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 53 Tweets from @SwarajyaMag.\n",
      "Getting data for 2020-02-09\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 30 Tweets from @SwarajyaMag.\n",
      "Getting data for 2020-02-10\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 56 Tweets from @SwarajyaMag.\n",
      "Getting data for 2020-02-11\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 81 Tweets from @SwarajyaMag.\n",
      "Getting data for 2020-02-12\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 63 Tweets from @SwarajyaMag.\n",
      "Getting data for 2020-02-13\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 58 Tweets from @SwarajyaMag.\n",
      "Getting data for 2020-02-14\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 69 Tweets from @SwarajyaMag.\n",
      "Getting data for 2020-02-15\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 42 Tweets from @SwarajyaMag.\n",
      "Getting data for 2020-02-16\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 42 Tweets from @SwarajyaMag.\n",
      "Getting data for 2020-02-17\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 56 Tweets from @SwarajyaMag.\n",
      "Getting data for 2020-02-18\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 62 Tweets from @SwarajyaMag.\n",
      "Getting data for 2020-02-19\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 53 Tweets from @SwarajyaMag.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting data for 2020-02-20\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 55 Tweets from @SwarajyaMag.\n",
      "Getting data for 2020-02-21\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 51 Tweets from @SwarajyaMag.\n",
      "Getting data for 2020-02-22\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 45 Tweets from @SwarajyaMag.\n",
      "Getting data for 2020-02-23\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 48 Tweets from @SwarajyaMag.\n",
      "Getting data for 2020-02-24\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 68 Tweets from @SwarajyaMag.\n",
      "Getting data for 2020-02-25\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 67 Tweets from @SwarajyaMag.\n",
      "Getting data for 2020-02-26\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 58 Tweets from @SwarajyaMag.\n",
      "Getting data for 2020-02-27\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 50 Tweets from @SwarajyaMag.\n",
      "Getting data for 2020-02-28\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 52 Tweets from @SwarajyaMag.\n",
      "Getting data for 2020-02-29\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 43 Tweets from @SwarajyaMag.\n",
      "Getting data for 2020-03-01\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 40 Tweets from @SwarajyaMag.\n",
      "Getting data for 2020-03-02\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 55 Tweets from @SwarajyaMag.\n",
      "Getting data for 2020-03-03\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 56 Tweets from @SwarajyaMag.\n",
      "Getting data for 2020-03-04\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 56 Tweets from @SwarajyaMag.\n",
      "Getting data for 2020-03-05\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 60 Tweets from @SwarajyaMag.\n",
      "Getting data for 2020-03-06\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 52 Tweets from @SwarajyaMag.\n",
      "Getting data for 2020-03-07\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 42 Tweets from @SwarajyaMag.\n",
      "Getting data for 2020-03-08\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 51 Tweets from @SwarajyaMag.\n",
      "Getting data for 2020-03-09\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 62 Tweets from @SwarajyaMag.\n",
      "Getting data for 2020-03-10\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 47 Tweets from @SwarajyaMag.\n",
      "Getting data for 2020-03-11\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 59 Tweets from @SwarajyaMag.\n",
      "Getting data for 2020-03-12\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 70 Tweets from @SwarajyaMag.\n",
      "Getting data for 2020-03-13\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 47 Tweets from @SwarajyaMag.\n",
      "Getting data for 2020-03-14\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 54 Tweets from @SwarajyaMag.\n",
      "Getting data for 2020-03-15\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 49 Tweets from @SwarajyaMag.\n",
      "Getting data for 2020-03-16\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 81 Tweets from @SwarajyaMag.\n",
      "Getting data for 2020-03-17\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 59 Tweets from @SwarajyaMag.\n",
      "Getting data for 2020-03-18\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 62 Tweets from @SwarajyaMag.\n",
      "Getting data for 2020-03-19\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 70 Tweets from @SwarajyaMag.\n",
      "Getting data for 2020-03-20\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 77 Tweets from @SwarajyaMag.\n",
      "Getting data for 2020-03-21\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 72 Tweets from @SwarajyaMag.\n",
      "Getting data for 2020-03-22\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 76 Tweets from @SwarajyaMag.\n",
      "Getting data for 2020-03-23\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 68 Tweets from @SwarajyaMag.\n",
      "Getting data for 2020-03-24\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 76 Tweets from @SwarajyaMag.\n",
      "Getting data for 2020-03-25\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 61 Tweets from @SwarajyaMag.\n",
      "Getting data for 2020-03-26\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 97 Tweets from @SwarajyaMag.\n",
      "Getting data for 2020-03-27\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 90 Tweets from @SwarajyaMag.\n",
      "Getting data for 2020-03-28\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 63 Tweets from @SwarajyaMag.\n",
      "Getting data for 2020-03-29\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 61 Tweets from @SwarajyaMag.\n",
      "Getting data for 2020-03-30\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 70 Tweets from @SwarajyaMag.\n",
      "Getting data for 2020-03-31\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 68 Tweets from @SwarajyaMag.\n",
      "Getting data for 2020-04-01\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 66 Tweets from @SwarajyaMag.\n",
      "Getting data for 2020-04-02\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 86 Tweets from @SwarajyaMag.\n",
      "Getting data for 2020-04-03\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 76 Tweets from @SwarajyaMag.\n",
      "Getting data for 2020-04-04\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 50 Tweets from @SwarajyaMag.\n",
      "Getting data for 2020-04-05\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 66 Tweets from @SwarajyaMag.\n",
      "Getting data for 2020-04-06\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 72 Tweets from @SwarajyaMag.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting data for 2020-04-07\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 65 Tweets from @SwarajyaMag.\n",
      "Getting data for 2020-04-08\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 74 Tweets from @SwarajyaMag.\n",
      "Getting data for 2020-04-09\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 81 Tweets from @SwarajyaMag.\n",
      "Getting data for 2020-04-10\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 83 Tweets from @SwarajyaMag.\n",
      "Getting data for 2020-04-11\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 67 Tweets from @SwarajyaMag.\n",
      "Getting data for 2020-04-12\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 47 Tweets from @SwarajyaMag.\n",
      "Getting data for 2020-04-13\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 77 Tweets from @SwarajyaMag.\n",
      "Getting data for 2020-04-14\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 78 Tweets from @SwarajyaMag.\n",
      "Getting data for 2020-04-15\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 75 Tweets from @SwarajyaMag.\n",
      "Getting data for 2020-04-16\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 87 Tweets from @SwarajyaMag.\n",
      "Getting data for 2020-04-17\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 78 Tweets from @SwarajyaMag.\n",
      "Getting data for 2020-04-18\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 66 Tweets from @SwarajyaMag.\n",
      "Getting data for 2020-04-19\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 50 Tweets from @SwarajyaMag.\n",
      "Getting data for 2020-04-20\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 76 Tweets from @SwarajyaMag.\n",
      "Getting data for 2020-04-21\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 77 Tweets from @SwarajyaMag.\n",
      "Getting data for 2020-04-22\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 80 Tweets from @SwarajyaMag.\n",
      "Getting data for 2020-04-23\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 78 Tweets from @SwarajyaMag.\n",
      "Getting data for 2020-04-24\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 75 Tweets from @SwarajyaMag.\n",
      "Getting data for 2020-04-25\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 59 Tweets from @SwarajyaMag.\n",
      "Getting data for 2020-04-26\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 56 Tweets from @SwarajyaMag.\n",
      "Getting data for 2020-04-27\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 71 Tweets from @SwarajyaMag.\n",
      "Getting data for 2020-04-28\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 62 Tweets from @SwarajyaMag.\n",
      "Getting data for 2020-04-29\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 59 Tweets from @SwarajyaMag.\n",
      "Getting data for 2020-04-30\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 67 Tweets from @SwarajyaMag.\n",
      "Getting data for 2020-05-01\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 70 Tweets from @SwarajyaMag.\n",
      "Getting data for 2020-05-02\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 56 Tweets from @SwarajyaMag.\n",
      "Getting data for 2020-05-03\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 56 Tweets from @SwarajyaMag.\n",
      "Getting data for 2020-05-04\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 66 Tweets from @SwarajyaMag.\n",
      "Getting data for 2020-05-05\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 60 Tweets from @SwarajyaMag.\n",
      "Getting data for 2020-05-06\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 70 Tweets from @SwarajyaMag.\n",
      "Getting data for 2020-05-07\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 81 Tweets from @SwarajyaMag.\n",
      "Getting data for 2020-05-08\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 66 Tweets from @SwarajyaMag.\n",
      "Getting data for 2020-05-09\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 62 Tweets from @SwarajyaMag.\n",
      "Getting data for 2020-05-10\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 48 Tweets from @SwarajyaMag.\n",
      "Getting data for 2020-05-11\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 59 Tweets from @SwarajyaMag.\n",
      "Getting data for 2020-05-12\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 61 Tweets from @SwarajyaMag.\n",
      "Getting data for 2020-05-13\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 69 Tweets from @SwarajyaMag.\n",
      "Getting data for 2020-05-14\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 97 Tweets from @SwarajyaMag.\n",
      "Getting data for 2020-05-15\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 66 Tweets from @SwarajyaMag.\n",
      "Getting data for 2020-05-16\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 69 Tweets from @SwarajyaMag.\n",
      "Getting data for 2020-05-17\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 57 Tweets from @SwarajyaMag.\n",
      "Getting data for 2020-05-18\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 48 Tweets from @SwarajyaMag.\n",
      "Getting data for 2020-05-19\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 56 Tweets from @SwarajyaMag.\n",
      "Getting data for 2020-05-20\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 63 Tweets from @SwarajyaMag.\n",
      "Getting data for 2020-05-21\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 65 Tweets from @SwarajyaMag.\n",
      "Getting data for 2020-05-22\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 58 Tweets from @SwarajyaMag.\n",
      "Getting data for 2020-05-23\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 43 Tweets from @SwarajyaMag.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting data for 2020-05-24\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 42 Tweets from @SwarajyaMag.\n",
      "Getting data for 2020-05-25\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 54 Tweets from @SwarajyaMag.\n",
      "Getting data for 2020-05-26\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 62 Tweets from @SwarajyaMag.\n",
      "Getting data for 2020-05-27\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 63 Tweets from @SwarajyaMag.\n",
      "Getting data for 2020-05-28\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 69 Tweets from @SwarajyaMag.\n",
      "Getting data for 2020-05-29\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 62 Tweets from @SwarajyaMag.\n",
      "Getting data for 2020-05-30\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 43 Tweets from @SwarajyaMag.\n",
      "time taken: 15.47 mins\n",
      "Directory C:\\Users\\rahul\\News channels data\\ThePrintIndia created\n",
      "Getting data for 2020-01-22\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 77 Tweets from @ThePrintIndia.\n",
      "Getting data for 2020-01-23\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 85 Tweets from @ThePrintIndia.\n",
      "Getting data for 2020-01-24\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 73 Tweets from @ThePrintIndia.\n",
      "Getting data for 2020-01-25\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 46 Tweets from @ThePrintIndia.\n",
      "Getting data for 2020-01-26\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 51 Tweets from @ThePrintIndia.\n",
      "Getting data for 2020-01-27\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 75 Tweets from @ThePrintIndia.\n",
      "Getting data for 2020-01-28\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 93 Tweets from @ThePrintIndia.\n",
      "Getting data for 2020-01-29\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 91 Tweets from @ThePrintIndia.\n",
      "Getting data for 2020-01-30\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 88 Tweets from @ThePrintIndia.\n",
      "Getting data for 2020-01-31\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 90 Tweets from @ThePrintIndia.\n",
      "Getting data for 2020-02-01\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 148 Tweets from @ThePrintIndia.\n",
      "Getting data for 2020-02-02\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 49 Tweets from @ThePrintIndia.\n",
      "Getting data for 2020-02-03\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 80 Tweets from @ThePrintIndia.\n",
      "Getting data for 2020-02-04\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 80 Tweets from @ThePrintIndia.\n",
      "Getting data for 2020-02-05\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 84 Tweets from @ThePrintIndia.\n",
      "Getting data for 2020-02-06\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 79 Tweets from @ThePrintIndia.\n",
      "Getting data for 2020-02-07\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 79 Tweets from @ThePrintIndia.\n",
      "Getting data for 2020-02-08\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 41 Tweets from @ThePrintIndia.\n",
      "Getting data for 2020-02-09\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 40 Tweets from @ThePrintIndia.\n",
      "Getting data for 2020-02-10\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 84 Tweets from @ThePrintIndia.\n",
      "Getting data for 2020-02-11\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 168 Tweets from @ThePrintIndia.\n",
      "Getting data for 2020-02-12\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 89 Tweets from @ThePrintIndia.\n",
      "Getting data for 2020-02-13\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 83 Tweets from @ThePrintIndia.\n",
      "Getting data for 2020-02-14\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 87 Tweets from @ThePrintIndia.\n",
      "Getting data for 2020-02-15\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 58 Tweets from @ThePrintIndia.\n",
      "Getting data for 2020-02-16\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 56 Tweets from @ThePrintIndia.\n",
      "Getting data for 2020-02-17\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 72 Tweets from @ThePrintIndia.\n",
      "Getting data for 2020-02-18\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 75 Tweets from @ThePrintIndia.\n",
      "Getting data for 2020-02-19\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 82 Tweets from @ThePrintIndia.\n",
      "Getting data for 2020-02-20\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 76 Tweets from @ThePrintIndia.\n",
      "Getting data for 2020-02-21\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 72 Tweets from @ThePrintIndia.\n",
      "Getting data for 2020-02-22\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 41 Tweets from @ThePrintIndia.\n",
      "Getting data for 2020-02-23\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 33 Tweets from @ThePrintIndia.\n",
      "Getting data for 2020-02-24\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 101 Tweets from @ThePrintIndia.\n",
      "Getting data for 2020-02-25\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 105 Tweets from @ThePrintIndia.\n",
      "Getting data for 2020-02-26\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 128 Tweets from @ThePrintIndia.\n",
      "Getting data for 2020-02-27\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 88 Tweets from @ThePrintIndia.\n",
      "Getting data for 2020-02-28\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 82 Tweets from @ThePrintIndia.\n",
      "Getting data for 2020-02-29\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 49 Tweets from @ThePrintIndia.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting data for 2020-03-01\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 54 Tweets from @ThePrintIndia.\n",
      "Getting data for 2020-03-02\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 126 Tweets from @ThePrintIndia.\n",
      "Getting data for 2020-03-03\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 147 Tweets from @ThePrintIndia.\n",
      "Getting data for 2020-03-04\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 94 Tweets from @ThePrintIndia.\n",
      "Getting data for 2020-03-05\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 90 Tweets from @ThePrintIndia.\n",
      "Getting data for 2020-03-06\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 86 Tweets from @ThePrintIndia.\n",
      "Getting data for 2020-03-07\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 52 Tweets from @ThePrintIndia.\n",
      "Getting data for 2020-03-08\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 48 Tweets from @ThePrintIndia.\n",
      "Getting data for 2020-03-09\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 82 Tweets from @ThePrintIndia.\n",
      "Getting data for 2020-03-10\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 73 Tweets from @ThePrintIndia.\n",
      "Getting data for 2020-03-11\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 93 Tweets from @ThePrintIndia.\n",
      "Getting data for 2020-03-12\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 97 Tweets from @ThePrintIndia.\n",
      "Getting data for 2020-03-13\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 97 Tweets from @ThePrintIndia.\n",
      "Getting data for 2020-03-14\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 60 Tweets from @ThePrintIndia.\n",
      "Getting data for 2020-03-15\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 61 Tweets from @ThePrintIndia.\n",
      "Getting data for 2020-03-16\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 82 Tweets from @ThePrintIndia.\n",
      "Getting data for 2020-03-17\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 101 Tweets from @ThePrintIndia.\n",
      "Getting data for 2020-03-18\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 102 Tweets from @ThePrintIndia.\n",
      "Getting data for 2020-03-19\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 127 Tweets from @ThePrintIndia.\n",
      "Getting data for 2020-03-20\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 113 Tweets from @ThePrintIndia.\n",
      "Getting data for 2020-03-21\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 72 Tweets from @ThePrintIndia.\n",
      "Getting data for 2020-03-22\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 77 Tweets from @ThePrintIndia.\n",
      "Getting data for 2020-03-23\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 131 Tweets from @ThePrintIndia.\n",
      "Getting data for 2020-03-24\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 127 Tweets from @ThePrintIndia.\n",
      "Getting data for 2020-03-25\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 147 Tweets from @ThePrintIndia.\n",
      "Getting data for 2020-03-26\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 114 Tweets from @ThePrintIndia.\n",
      "Getting data for 2020-03-27\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 125 Tweets from @ThePrintIndia.\n",
      "Getting data for 2020-03-28\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 71 Tweets from @ThePrintIndia.\n",
      "Getting data for 2020-03-29\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 67 Tweets from @ThePrintIndia.\n",
      "Getting data for 2020-03-30\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 104 Tweets from @ThePrintIndia.\n",
      "Getting data for 2020-03-31\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 97 Tweets from @ThePrintIndia.\n",
      "Getting data for 2020-04-01\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 133 Tweets from @ThePrintIndia.\n",
      "Getting data for 2020-04-02\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 119 Tweets from @ThePrintIndia.\n",
      "Getting data for 2020-04-03\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 119 Tweets from @ThePrintIndia.\n",
      "Getting data for 2020-04-04\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 68 Tweets from @ThePrintIndia.\n",
      "Getting data for 2020-04-05\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 59 Tweets from @ThePrintIndia.\n",
      "Getting data for 2020-04-06\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 124 Tweets from @ThePrintIndia.\n",
      "Getting data for 2020-04-07\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 115 Tweets from @ThePrintIndia.\n",
      "Getting data for 2020-04-08\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 116 Tweets from @ThePrintIndia.\n",
      "Getting data for 2020-04-09\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 102 Tweets from @ThePrintIndia.\n",
      "Getting data for 2020-04-10\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 117 Tweets from @ThePrintIndia.\n",
      "Getting data for 2020-04-11\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 57 Tweets from @ThePrintIndia.\n",
      "Getting data for 2020-04-12\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 59 Tweets from @ThePrintIndia.\n",
      "Getting data for 2020-04-13\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 109 Tweets from @ThePrintIndia.\n",
      "Getting data for 2020-04-14\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 121 Tweets from @ThePrintIndia.\n",
      "Getting data for 2020-04-15\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 110 Tweets from @ThePrintIndia.\n",
      "Getting data for 2020-04-16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 118 Tweets from @ThePrintIndia.\n",
      "Getting data for 2020-04-17\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 104 Tweets from @ThePrintIndia.\n",
      "Getting data for 2020-04-18\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 61 Tweets from @ThePrintIndia.\n",
      "Getting data for 2020-04-19\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 57 Tweets from @ThePrintIndia.\n",
      "Getting data for 2020-04-20\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 101 Tweets from @ThePrintIndia.\n",
      "Getting data for 2020-04-21\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 107 Tweets from @ThePrintIndia.\n",
      "Getting data for 2020-04-22\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 118 Tweets from @ThePrintIndia.\n",
      "Getting data for 2020-04-23\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 114 Tweets from @ThePrintIndia.\n",
      "Getting data for 2020-04-24\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 108 Tweets from @ThePrintIndia.\n",
      "Getting data for 2020-04-25\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 57 Tweets from @ThePrintIndia.\n",
      "Getting data for 2020-04-26\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 55 Tweets from @ThePrintIndia.\n",
      "Getting data for 2020-04-27\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 97 Tweets from @ThePrintIndia.\n",
      "Getting data for 2020-04-28\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 116 Tweets from @ThePrintIndia.\n",
      "Getting data for 2020-04-29\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 98 Tweets from @ThePrintIndia.\n",
      "Getting data for 2020-04-30\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 107 Tweets from @ThePrintIndia.\n",
      "Getting data for 2020-05-01\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 122 Tweets from @ThePrintIndia.\n",
      "Getting data for 2020-05-02\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 55 Tweets from @ThePrintIndia.\n",
      "Getting data for 2020-05-03\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 57 Tweets from @ThePrintIndia.\n",
      "Getting data for 2020-05-04\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 115 Tweets from @ThePrintIndia.\n",
      "Getting data for 2020-05-05\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 117 Tweets from @ThePrintIndia.\n",
      "Getting data for 2020-05-06\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 107 Tweets from @ThePrintIndia.\n",
      "Getting data for 2020-05-07\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 121 Tweets from @ThePrintIndia.\n",
      "Getting data for 2020-05-08\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 129 Tweets from @ThePrintIndia.\n",
      "Getting data for 2020-05-09\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 77 Tweets from @ThePrintIndia.\n",
      "Getting data for 2020-05-10\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 72 Tweets from @ThePrintIndia.\n",
      "Getting data for 2020-05-11\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 116 Tweets from @ThePrintIndia.\n",
      "Getting data for 2020-05-12\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 126 Tweets from @ThePrintIndia.\n",
      "Getting data for 2020-05-13\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 123 Tweets from @ThePrintIndia.\n",
      "Getting data for 2020-05-14\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 109 Tweets from @ThePrintIndia.\n",
      "Getting data for 2020-05-15\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 124 Tweets from @ThePrintIndia.\n",
      "Getting data for 2020-05-16\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 86 Tweets from @ThePrintIndia.\n",
      "Getting data for 2020-05-17\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 84 Tweets from @ThePrintIndia.\n",
      "Getting data for 2020-05-18\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 109 Tweets from @ThePrintIndia.\n",
      "Getting data for 2020-05-19\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 115 Tweets from @ThePrintIndia.\n",
      "Getting data for 2020-05-20\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 118 Tweets from @ThePrintIndia.\n",
      "Getting data for 2020-05-21\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 118 Tweets from @ThePrintIndia.\n",
      "Getting data for 2020-05-22\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 124 Tweets from @ThePrintIndia.\n",
      "Getting data for 2020-05-23\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 82 Tweets from @ThePrintIndia.\n",
      "Getting data for 2020-05-24\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 72 Tweets from @ThePrintIndia.\n",
      "Getting data for 2020-05-25\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 108 Tweets from @ThePrintIndia.\n",
      "Getting data for 2020-05-26\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 115 Tweets from @ThePrintIndia.\n",
      "Getting data for 2020-05-27\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 112 Tweets from @ThePrintIndia.\n",
      "Getting data for 2020-05-28\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 121 Tweets from @ThePrintIndia.\n",
      "Getting data for 2020-05-29\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 117 Tweets from @ThePrintIndia.\n",
      "Getting data for 2020-05-30\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 77 Tweets from @ThePrintIndia.\n",
      "time taken: 16.91 mins\n",
      "Directory C:\\Users\\rahul\\News channels data\\thewire_in created\n",
      "Getting data for 2020-01-22\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 45 Tweets from @thewire_in.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting data for 2020-01-23\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 45 Tweets from @thewire_in.\n",
      "Getting data for 2020-01-24\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 41 Tweets from @thewire_in.\n",
      "Getting data for 2020-01-25\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 42 Tweets from @thewire_in.\n",
      "Getting data for 2020-01-26\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 41 Tweets from @thewire_in.\n",
      "Getting data for 2020-01-27\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 49 Tweets from @thewire_in.\n",
      "Getting data for 2020-01-28\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 47 Tweets from @thewire_in.\n",
      "Getting data for 2020-01-29\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 48 Tweets from @thewire_in.\n",
      "Getting data for 2020-01-30\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 47 Tweets from @thewire_in.\n",
      "Getting data for 2020-01-31\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 50 Tweets from @thewire_in.\n",
      "Getting data for 2020-02-01\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 92 Tweets from @thewire_in.\n",
      "Getting data for 2020-02-02\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 61 Tweets from @thewire_in.\n",
      "Getting data for 2020-02-03\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 50 Tweets from @thewire_in.\n",
      "Getting data for 2020-02-04\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 47 Tweets from @thewire_in.\n",
      "Getting data for 2020-02-05\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 53 Tweets from @thewire_in.\n",
      "Getting data for 2020-02-06\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 59 Tweets from @thewire_in.\n",
      "Getting data for 2020-02-07\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 70 Tweets from @thewire_in.\n",
      "Getting data for 2020-02-08\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 82 Tweets from @thewire_in.\n",
      "Getting data for 2020-02-09\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 34 Tweets from @thewire_in.\n",
      "Getting data for 2020-02-10\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 45 Tweets from @thewire_in.\n",
      "Getting data for 2020-02-11\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 87 Tweets from @thewire_in.\n",
      "Getting data for 2020-02-12\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 52 Tweets from @thewire_in.\n",
      "Getting data for 2020-02-13\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 42 Tweets from @thewire_in.\n",
      "Getting data for 2020-02-14\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 56 Tweets from @thewire_in.\n",
      "Getting data for 2020-02-15\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 43 Tweets from @thewire_in.\n",
      "Getting data for 2020-02-16\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 39 Tweets from @thewire_in.\n",
      "Getting data for 2020-02-17\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 40 Tweets from @thewire_in.\n",
      "Getting data for 2020-02-18\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 49 Tweets from @thewire_in.\n",
      "Getting data for 2020-02-19\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 42 Tweets from @thewire_in.\n",
      "Getting data for 2020-02-20\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 45 Tweets from @thewire_in.\n",
      "Getting data for 2020-02-21\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 55 Tweets from @thewire_in.\n",
      "Getting data for 2020-02-22\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 48 Tweets from @thewire_in.\n",
      "Getting data for 2020-02-23\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 40 Tweets from @thewire_in.\n",
      "Getting data for 2020-02-24\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 51 Tweets from @thewire_in.\n",
      "Getting data for 2020-02-25\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 44 Tweets from @thewire_in.\n",
      "Getting data for 2020-02-26\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 51 Tweets from @thewire_in.\n",
      "Getting data for 2020-02-27\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 49 Tweets from @thewire_in.\n",
      "Getting data for 2020-02-28\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 46 Tweets from @thewire_in.\n",
      "Getting data for 2020-02-29\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 42 Tweets from @thewire_in.\n",
      "Getting data for 2020-03-01\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 41 Tweets from @thewire_in.\n",
      "Getting data for 2020-03-02\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 44 Tweets from @thewire_in.\n",
      "Getting data for 2020-03-03\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 58 Tweets from @thewire_in.\n",
      "Getting data for 2020-03-04\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 47 Tweets from @thewire_in.\n",
      "Getting data for 2020-03-05\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 56 Tweets from @thewire_in.\n",
      "Getting data for 2020-03-06\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 42 Tweets from @thewire_in.\n",
      "Getting data for 2020-03-07\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 43 Tweets from @thewire_in.\n",
      "Getting data for 2020-03-08\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 40 Tweets from @thewire_in.\n",
      "Getting data for 2020-03-09\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 52 Tweets from @thewire_in.\n",
      "Getting data for 2020-03-10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 38 Tweets from @thewire_in.\n",
      "Getting data for 2020-03-11\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 39 Tweets from @thewire_in.\n",
      "Getting data for 2020-03-12\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 52 Tweets from @thewire_in.\n",
      "Getting data for 2020-03-13\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 63 Tweets from @thewire_in.\n",
      "Getting data for 2020-03-14\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 44 Tweets from @thewire_in.\n",
      "Getting data for 2020-03-15\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 52 Tweets from @thewire_in.\n",
      "Getting data for 2020-03-16\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 48 Tweets from @thewire_in.\n",
      "Getting data for 2020-03-17\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 44 Tweets from @thewire_in.\n",
      "Getting data for 2020-03-18\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 47 Tweets from @thewire_in.\n",
      "Getting data for 2020-03-19\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 49 Tweets from @thewire_in.\n",
      "Getting data for 2020-03-20\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 50 Tweets from @thewire_in.\n",
      "Getting data for 2020-03-21\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 33 Tweets from @thewire_in.\n",
      "Getting data for 2020-03-22\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 40 Tweets from @thewire_in.\n",
      "Getting data for 2020-03-23\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 41 Tweets from @thewire_in.\n",
      "Getting data for 2020-03-24\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 50 Tweets from @thewire_in.\n",
      "Getting data for 2020-03-25\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 57 Tweets from @thewire_in.\n",
      "Getting data for 2020-03-26\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 46 Tweets from @thewire_in.\n",
      "Getting data for 2020-03-27\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 60 Tweets from @thewire_in.\n",
      "Getting data for 2020-03-28\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 54 Tweets from @thewire_in.\n",
      "Getting data for 2020-03-29\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 43 Tweets from @thewire_in.\n",
      "Getting data for 2020-03-30\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 46 Tweets from @thewire_in.\n",
      "Getting data for 2020-03-31\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 47 Tweets from @thewire_in.\n",
      "Getting data for 2020-04-01\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 45 Tweets from @thewire_in.\n",
      "Getting data for 2020-04-02\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 45 Tweets from @thewire_in.\n",
      "Getting data for 2020-04-03\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 52 Tweets from @thewire_in.\n",
      "Getting data for 2020-04-04\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 45 Tweets from @thewire_in.\n",
      "Getting data for 2020-04-05\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 39 Tweets from @thewire_in.\n",
      "Getting data for 2020-04-06\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 41 Tweets from @thewire_in.\n",
      "Getting data for 2020-04-07\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 44 Tweets from @thewire_in.\n",
      "Getting data for 2020-04-08\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 46 Tweets from @thewire_in.\n",
      "Getting data for 2020-04-09\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 51 Tweets from @thewire_in.\n",
      "Getting data for 2020-04-10\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 55 Tweets from @thewire_in.\n",
      "Getting data for 2020-04-11\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 50 Tweets from @thewire_in.\n",
      "Getting data for 2020-04-12\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 37 Tweets from @thewire_in.\n",
      "Getting data for 2020-04-13\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 44 Tweets from @thewire_in.\n",
      "Getting data for 2020-04-14\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 53 Tweets from @thewire_in.\n",
      "Getting data for 2020-04-15\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 50 Tweets from @thewire_in.\n",
      "Getting data for 2020-04-16\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 46 Tweets from @thewire_in.\n",
      "Getting data for 2020-04-17\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 51 Tweets from @thewire_in.\n",
      "Getting data for 2020-04-18\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 44 Tweets from @thewire_in.\n",
      "Getting data for 2020-04-19\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 44 Tweets from @thewire_in.\n",
      "Getting data for 2020-04-20\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 44 Tweets from @thewire_in.\n",
      "Getting data for 2020-04-21\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 48 Tweets from @thewire_in.\n",
      "Getting data for 2020-04-22\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 53 Tweets from @thewire_in.\n",
      "Getting data for 2020-04-23\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 45 Tweets from @thewire_in.\n",
      "Getting data for 2020-04-24\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 44 Tweets from @thewire_in.\n",
      "Getting data for 2020-04-25\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 43 Tweets from @thewire_in.\n",
      "Getting data for 2020-04-26\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 33 Tweets from @thewire_in.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting data for 2020-04-27\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 45 Tweets from @thewire_in.\n",
      "Getting data for 2020-04-28\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 43 Tweets from @thewire_in.\n",
      "Getting data for 2020-04-29\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 50 Tweets from @thewire_in.\n",
      "Getting data for 2020-04-30\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 51 Tweets from @thewire_in.\n",
      "Getting data for 2020-05-01\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 47 Tweets from @thewire_in.\n",
      "Getting data for 2020-05-02\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 40 Tweets from @thewire_in.\n",
      "Getting data for 2020-05-03\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 32 Tweets from @thewire_in.\n",
      "Getting data for 2020-05-04\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 50 Tweets from @thewire_in.\n",
      "Getting data for 2020-05-05\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 45 Tweets from @thewire_in.\n",
      "Getting data for 2020-05-06\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 50 Tweets from @thewire_in.\n",
      "Getting data for 2020-05-07\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 56 Tweets from @thewire_in.\n",
      "Getting data for 2020-05-08\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 51 Tweets from @thewire_in.\n",
      "Getting data for 2020-05-09\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 46 Tweets from @thewire_in.\n",
      "Getting data for 2020-05-10\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 45 Tweets from @thewire_in.\n",
      "Getting data for 2020-05-11\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 45 Tweets from @thewire_in.\n",
      "Getting data for 2020-05-12\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 39 Tweets from @thewire_in.\n",
      "Getting data for 2020-05-13\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 47 Tweets from @thewire_in.\n",
      "Getting data for 2020-05-14\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 46 Tweets from @thewire_in.\n",
      "Getting data for 2020-05-15\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 47 Tweets from @thewire_in.\n",
      "Getting data for 2020-05-16\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 46 Tweets from @thewire_in.\n",
      "Getting data for 2020-05-17\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 49 Tweets from @thewire_in.\n",
      "Getting data for 2020-05-18\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 47 Tweets from @thewire_in.\n",
      "Getting data for 2020-05-19\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 45 Tweets from @thewire_in.\n",
      "Getting data for 2020-05-20\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 48 Tweets from @thewire_in.\n",
      "Getting data for 2020-05-21\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 46 Tweets from @thewire_in.\n",
      "Getting data for 2020-05-22\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 52 Tweets from @thewire_in.\n",
      "Getting data for 2020-05-23\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 48 Tweets from @thewire_in.\n",
      "Getting data for 2020-05-24\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 45 Tweets from @thewire_in.\n",
      "Getting data for 2020-05-25\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 45 Tweets from @thewire_in.\n",
      "Getting data for 2020-05-26\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 45 Tweets from @thewire_in.\n",
      "Getting data for 2020-05-27\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 53 Tweets from @thewire_in.\n",
      "Getting data for 2020-05-28\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 40 Tweets from @thewire_in.\n",
      "Getting data for 2020-05-29\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 57 Tweets from @thewire_in.\n",
      "Getting data for 2020-05-30\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 45 Tweets from @thewire_in.\n",
      "time taken: 14.93 mins\n",
      "Directory C:\\Users\\rahul\\News channels data\\MirrorNow created\n",
      "Getting data for 2020-01-22\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 81 Tweets from @MirrorNow.\n",
      "Getting data for 2020-01-23\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 64 Tweets from @MirrorNow.\n",
      "Getting data for 2020-01-24\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 95 Tweets from @MirrorNow.\n",
      "Getting data for 2020-01-25\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 58 Tweets from @MirrorNow.\n",
      "Getting data for 2020-01-26\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 33 Tweets from @MirrorNow.\n",
      "Getting data for 2020-01-27\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 52 Tweets from @MirrorNow.\n",
      "Getting data for 2020-01-28\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 84 Tweets from @MirrorNow.\n",
      "Getting data for 2020-01-29\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 72 Tweets from @MirrorNow.\n",
      "Getting data for 2020-01-30\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 90 Tweets from @MirrorNow.\n",
      "Getting data for 2020-01-31\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 85 Tweets from @MirrorNow.\n",
      "Getting data for 2020-02-01\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 121 Tweets from @MirrorNow.\n",
      "Getting data for 2020-02-02\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 17 Tweets from @MirrorNow.\n",
      "Getting data for 2020-02-03\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 76 Tweets from @MirrorNow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting data for 2020-02-04\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 77 Tweets from @MirrorNow.\n",
      "Getting data for 2020-02-05\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 72 Tweets from @MirrorNow.\n",
      "Getting data for 2020-02-06\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 115 Tweets from @MirrorNow.\n",
      "Getting data for 2020-02-07\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 85 Tweets from @MirrorNow.\n",
      "Getting data for 2020-02-08\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 122 Tweets from @MirrorNow.\n",
      "Getting data for 2020-02-09\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 46 Tweets from @MirrorNow.\n",
      "Getting data for 2020-02-10\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 74 Tweets from @MirrorNow.\n",
      "Getting data for 2020-02-11\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 106 Tweets from @MirrorNow.\n",
      "Getting data for 2020-02-12\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 108 Tweets from @MirrorNow.\n",
      "Getting data for 2020-02-13\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 117 Tweets from @MirrorNow.\n",
      "Getting data for 2020-02-14\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 64 Tweets from @MirrorNow.\n",
      "Getting data for 2020-02-15\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 27 Tweets from @MirrorNow.\n",
      "Getting data for 2020-02-16\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 22 Tweets from @MirrorNow.\n",
      "Getting data for 2020-02-17\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 64 Tweets from @MirrorNow.\n",
      "Getting data for 2020-02-18\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 62 Tweets from @MirrorNow.\n",
      "Getting data for 2020-02-19\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 72 Tweets from @MirrorNow.\n",
      "Getting data for 2020-02-20\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 62 Tweets from @MirrorNow.\n",
      "Getting data for 2020-02-21\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 69 Tweets from @MirrorNow.\n",
      "Getting data for 2020-02-22\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 18 Tweets from @MirrorNow.\n",
      "Getting data for 2020-02-23\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 19 Tweets from @MirrorNow.\n",
      "Getting data for 2020-02-24\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 59 Tweets from @MirrorNow.\n",
      "Getting data for 2020-02-25\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 91 Tweets from @MirrorNow.\n",
      "Getting data for 2020-02-26\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 81 Tweets from @MirrorNow.\n",
      "Getting data for 2020-02-27\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 75 Tweets from @MirrorNow.\n",
      "Getting data for 2020-02-28\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 65 Tweets from @MirrorNow.\n",
      "Getting data for 2020-02-29\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 26 Tweets from @MirrorNow.\n",
      "Getting data for 2020-03-01\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 34 Tweets from @MirrorNow.\n",
      "Getting data for 2020-03-02\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 64 Tweets from @MirrorNow.\n",
      "Getting data for 2020-03-03\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 83 Tweets from @MirrorNow.\n",
      "Getting data for 2020-03-04\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 72 Tweets from @MirrorNow.\n",
      "Getting data for 2020-03-05\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 55 Tweets from @MirrorNow.\n",
      "Getting data for 2020-03-06\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 86 Tweets from @MirrorNow.\n",
      "Getting data for 2020-03-07\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 25 Tweets from @MirrorNow.\n",
      "Getting data for 2020-03-08\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 26 Tweets from @MirrorNow.\n",
      "Getting data for 2020-03-09\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 61 Tweets from @MirrorNow.\n",
      "Getting data for 2020-03-10\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 39 Tweets from @MirrorNow.\n",
      "Getting data for 2020-03-11\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 98 Tweets from @MirrorNow.\n",
      "Getting data for 2020-03-12\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 60 Tweets from @MirrorNow.\n",
      "Getting data for 2020-03-13\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 112 Tweets from @MirrorNow.\n",
      "Getting data for 2020-03-14\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 28 Tweets from @MirrorNow.\n",
      "Getting data for 2020-03-15\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 38 Tweets from @MirrorNow.\n",
      "Getting data for 2020-03-16\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 93 Tweets from @MirrorNow.\n",
      "Getting data for 2020-03-17\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 114 Tweets from @MirrorNow.\n",
      "Getting data for 2020-03-18\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 82 Tweets from @MirrorNow.\n",
      "Getting data for 2020-03-19\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 111 Tweets from @MirrorNow.\n",
      "Getting data for 2020-03-20\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 121 Tweets from @MirrorNow.\n",
      "Getting data for 2020-03-21\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 34 Tweets from @MirrorNow.\n",
      "Getting data for 2020-03-22\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 50 Tweets from @MirrorNow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting data for 2020-03-23\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 109 Tweets from @MirrorNow.\n",
      "Getting data for 2020-03-24\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 106 Tweets from @MirrorNow.\n",
      "Getting data for 2020-03-25\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 93 Tweets from @MirrorNow.\n",
      "Getting data for 2020-03-26\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 99 Tweets from @MirrorNow.\n",
      "Getting data for 2020-03-27\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 92 Tweets from @MirrorNow.\n",
      "Getting data for 2020-03-28\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 49 Tweets from @MirrorNow.\n",
      "Getting data for 2020-03-29\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 28 Tweets from @MirrorNow.\n",
      "Getting data for 2020-03-30\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 106 Tweets from @MirrorNow.\n",
      "Getting data for 2020-03-31\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 98 Tweets from @MirrorNow.\n",
      "Getting data for 2020-04-01\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 75 Tweets from @MirrorNow.\n",
      "Getting data for 2020-04-02\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 77 Tweets from @MirrorNow.\n",
      "Getting data for 2020-04-03\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 83 Tweets from @MirrorNow.\n",
      "Getting data for 2020-04-04\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 27 Tweets from @MirrorNow.\n",
      "Getting data for 2020-04-05\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 43 Tweets from @MirrorNow.\n",
      "Getting data for 2020-04-06\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 89 Tweets from @MirrorNow.\n",
      "Getting data for 2020-04-07\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 70 Tweets from @MirrorNow.\n",
      "Getting data for 2020-04-08\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 82 Tweets from @MirrorNow.\n",
      "Getting data for 2020-04-09\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 53 Tweets from @MirrorNow.\n",
      "Getting data for 2020-04-10\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 55 Tweets from @MirrorNow.\n",
      "Getting data for 2020-04-11\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 37 Tweets from @MirrorNow.\n",
      "Getting data for 2020-04-12\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 54 Tweets from @MirrorNow.\n",
      "Getting data for 2020-04-13\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 44 Tweets from @MirrorNow.\n",
      "Getting data for 2020-04-14\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 78 Tweets from @MirrorNow.\n",
      "Getting data for 2020-04-15\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 73 Tweets from @MirrorNow.\n",
      "Getting data for 2020-04-16\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 62 Tweets from @MirrorNow.\n",
      "Getting data for 2020-04-17\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 69 Tweets from @MirrorNow.\n",
      "Getting data for 2020-04-18\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 44 Tweets from @MirrorNow.\n",
      "Getting data for 2020-04-19\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 69 Tweets from @MirrorNow.\n",
      "Getting data for 2020-04-20\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 66 Tweets from @MirrorNow.\n",
      "Getting data for 2020-04-21\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 84 Tweets from @MirrorNow.\n",
      "Getting data for 2020-04-22\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 85 Tweets from @MirrorNow.\n",
      "Getting data for 2020-04-23\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 83 Tweets from @MirrorNow.\n",
      "Getting data for 2020-04-24\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 83 Tweets from @MirrorNow.\n",
      "Getting data for 2020-04-25\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 31 Tweets from @MirrorNow.\n",
      "Getting data for 2020-04-26\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 68 Tweets from @MirrorNow.\n",
      "Getting data for 2020-04-27\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 79 Tweets from @MirrorNow.\n",
      "Getting data for 2020-04-28\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 75 Tweets from @MirrorNow.\n",
      "Getting data for 2020-04-29\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 74 Tweets from @MirrorNow.\n",
      "Getting data for 2020-04-30\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 108 Tweets from @MirrorNow.\n",
      "Getting data for 2020-05-01\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 123 Tweets from @MirrorNow.\n",
      "Getting data for 2020-05-02\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 42 Tweets from @MirrorNow.\n",
      "Getting data for 2020-05-03\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 66 Tweets from @MirrorNow.\n",
      "Getting data for 2020-05-04\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 80 Tweets from @MirrorNow.\n",
      "Getting data for 2020-05-05\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 72 Tweets from @MirrorNow.\n",
      "Getting data for 2020-05-06\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 61 Tweets from @MirrorNow.\n",
      "Getting data for 2020-05-07\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 88 Tweets from @MirrorNow.\n",
      "Getting data for 2020-05-08\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 93 Tweets from @MirrorNow.\n",
      "Getting data for 2020-05-09\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 57 Tweets from @MirrorNow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting data for 2020-05-10\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 47 Tweets from @MirrorNow.\n",
      "Getting data for 2020-05-11\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 97 Tweets from @MirrorNow.\n",
      "Getting data for 2020-05-12\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 86 Tweets from @MirrorNow.\n",
      "Getting data for 2020-05-13\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 95 Tweets from @MirrorNow.\n",
      "Getting data for 2020-05-14\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 89 Tweets from @MirrorNow.\n",
      "Getting data for 2020-05-15\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 87 Tweets from @MirrorNow.\n",
      "Getting data for 2020-05-16\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 53 Tweets from @MirrorNow.\n",
      "Getting data for 2020-05-17\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 66 Tweets from @MirrorNow.\n",
      "Getting data for 2020-05-18\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 66 Tweets from @MirrorNow.\n",
      "Getting data for 2020-05-19\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 72 Tweets from @MirrorNow.\n",
      "Getting data for 2020-05-20\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 77 Tweets from @MirrorNow.\n",
      "Getting data for 2020-05-21\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 81 Tweets from @MirrorNow.\n",
      "Getting data for 2020-05-22\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 66 Tweets from @MirrorNow.\n",
      "Getting data for 2020-05-23\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 45 Tweets from @MirrorNow.\n",
      "Getting data for 2020-05-24\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 79 Tweets from @MirrorNow.\n",
      "Getting data for 2020-05-25\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 69 Tweets from @MirrorNow.\n",
      "Getting data for 2020-05-26\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 73 Tweets from @MirrorNow.\n",
      "Getting data for 2020-05-27\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 75 Tweets from @MirrorNow.\n",
      "Getting data for 2020-05-28\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 76 Tweets from @MirrorNow.\n",
      "Getting data for 2020-05-29\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 91 Tweets from @MirrorNow.\n",
      "Getting data for 2020-05-30\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 51 Tweets from @MirrorNow.\n",
      "time taken: 16.28 mins\n",
      "Directory C:\\Users\\rahul\\News channels data\\the_hindu created\n",
      "Getting data for 2020-01-22\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 127 Tweets from @the_hindu.\n",
      "Getting data for 2020-01-23\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 128 Tweets from @the_hindu.\n",
      "Getting data for 2020-01-24\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 112 Tweets from @the_hindu.\n",
      "Getting data for 2020-01-25\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 130 Tweets from @the_hindu.\n",
      "Getting data for 2020-01-26\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 114 Tweets from @the_hindu.\n",
      "Getting data for 2020-01-27\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 120 Tweets from @the_hindu.\n",
      "Getting data for 2020-01-28\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 143 Tweets from @the_hindu.\n",
      "Getting data for 2020-01-29\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 141 Tweets from @the_hindu.\n",
      "Getting data for 2020-01-30\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 146 Tweets from @the_hindu.\n",
      "Getting data for 2020-01-31\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 167 Tweets from @the_hindu.\n",
      "Getting data for 2020-02-01\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 167 Tweets from @the_hindu.\n",
      "Getting data for 2020-02-02\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 98 Tweets from @the_hindu.\n",
      "Getting data for 2020-02-03\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 134 Tweets from @the_hindu.\n",
      "Getting data for 2020-02-04\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 129 Tweets from @the_hindu.\n",
      "Getting data for 2020-02-05\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 118 Tweets from @the_hindu.\n",
      "Getting data for 2020-02-06\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 124 Tweets from @the_hindu.\n",
      "Getting data for 2020-02-07\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 134 Tweets from @the_hindu.\n",
      "Getting data for 2020-02-08\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 124 Tweets from @the_hindu.\n",
      "Getting data for 2020-02-09\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 115 Tweets from @the_hindu.\n",
      "Getting data for 2020-02-10\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 112 Tweets from @the_hindu.\n",
      "Getting data for 2020-02-11\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 140 Tweets from @the_hindu.\n",
      "Getting data for 2020-02-12\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 125 Tweets from @the_hindu.\n",
      "Getting data for 2020-02-13\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 116 Tweets from @the_hindu.\n",
      "Getting data for 2020-02-14\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 119 Tweets from @the_hindu.\n",
      "Getting data for 2020-02-15\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 129 Tweets from @the_hindu.\n",
      "Getting data for 2020-02-16\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 98 Tweets from @the_hindu.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting data for 2020-02-17\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 112 Tweets from @the_hindu.\n",
      "Getting data for 2020-02-18\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 154 Tweets from @the_hindu.\n",
      "Getting data for 2020-02-19\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 133 Tweets from @the_hindu.\n",
      "Getting data for 2020-02-20\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 118 Tweets from @the_hindu.\n",
      "Getting data for 2020-02-21\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 111 Tweets from @the_hindu.\n",
      "Getting data for 2020-02-22\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 77 Tweets from @the_hindu.\n",
      "Getting data for 2020-02-23\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 120 Tweets from @the_hindu.\n",
      "Getting data for 2020-02-24\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 130 Tweets from @the_hindu.\n",
      "Getting data for 2020-02-25\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 169 Tweets from @the_hindu.\n",
      "Getting data for 2020-02-26\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 134 Tweets from @the_hindu.\n",
      "Getting data for 2020-02-27\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 126 Tweets from @the_hindu.\n",
      "Getting data for 2020-02-28\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 126 Tweets from @the_hindu.\n",
      "Getting data for 2020-02-29\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 120 Tweets from @the_hindu.\n",
      "Getting data for 2020-03-01\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 102 Tweets from @the_hindu.\n",
      "Getting data for 2020-03-02\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 130 Tweets from @the_hindu.\n",
      "Getting data for 2020-03-03\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 100 Tweets from @the_hindu.\n",
      "Getting data for 2020-03-04\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 115 Tweets from @the_hindu.\n",
      "Getting data for 2020-03-05\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 159 Tweets from @the_hindu.\n",
      "Getting data for 2020-03-06\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 129 Tweets from @the_hindu.\n",
      "Getting data for 2020-03-07\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 114 Tweets from @the_hindu.\n",
      "Getting data for 2020-03-08\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 106 Tweets from @the_hindu.\n",
      "Getting data for 2020-03-09\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 123 Tweets from @the_hindu.\n",
      "Getting data for 2020-03-10\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 128 Tweets from @the_hindu.\n",
      "Getting data for 2020-03-11\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 115 Tweets from @the_hindu.\n",
      "Getting data for 2020-03-12\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 136 Tweets from @the_hindu.\n",
      "Getting data for 2020-03-13\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 155 Tweets from @the_hindu.\n",
      "Getting data for 2020-03-14\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 99 Tweets from @the_hindu.\n",
      "Getting data for 2020-03-15\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 112 Tweets from @the_hindu.\n",
      "Getting data for 2020-03-16\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 129 Tweets from @the_hindu.\n",
      "Getting data for 2020-03-17\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 126 Tweets from @the_hindu.\n",
      "Getting data for 2020-03-18\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 138 Tweets from @the_hindu.\n",
      "Getting data for 2020-03-19\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 224 Tweets from @the_hindu.\n",
      "Getting data for 2020-03-20\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 156 Tweets from @the_hindu.\n",
      "Getting data for 2020-03-21\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 128 Tweets from @the_hindu.\n",
      "Getting data for 2020-03-22\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 127 Tweets from @the_hindu.\n",
      "Getting data for 2020-03-23\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 156 Tweets from @the_hindu.\n",
      "Getting data for 2020-03-24\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 165 Tweets from @the_hindu.\n",
      "Getting data for 2020-03-25\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 131 Tweets from @the_hindu.\n",
      "Getting data for 2020-03-26\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 132 Tweets from @the_hindu.\n",
      "Getting data for 2020-03-27\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 146 Tweets from @the_hindu.\n",
      "Getting data for 2020-03-28\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 105 Tweets from @the_hindu.\n",
      "Getting data for 2020-03-29\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 138 Tweets from @the_hindu.\n",
      "Getting data for 2020-03-30\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 138 Tweets from @the_hindu.\n",
      "Getting data for 2020-03-31\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 146 Tweets from @the_hindu.\n",
      "Getting data for 2020-04-01\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 168 Tweets from @the_hindu.\n",
      "Getting data for 2020-04-02\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 150 Tweets from @the_hindu.\n",
      "Getting data for 2020-04-03\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 146 Tweets from @the_hindu.\n",
      "Getting data for 2020-04-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 103 Tweets from @the_hindu.\n",
      "Getting data for 2020-04-05\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 122 Tweets from @the_hindu.\n",
      "Getting data for 2020-04-06\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 138 Tweets from @the_hindu.\n",
      "Getting data for 2020-04-07\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 113 Tweets from @the_hindu.\n",
      "Getting data for 2020-04-08\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 121 Tweets from @the_hindu.\n",
      "Getting data for 2020-04-09\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 146 Tweets from @the_hindu.\n",
      "Getting data for 2020-04-10\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 158 Tweets from @the_hindu.\n",
      "Getting data for 2020-04-11\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 128 Tweets from @the_hindu.\n",
      "Getting data for 2020-04-12\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 184 Tweets from @the_hindu.\n",
      "Getting data for 2020-04-13\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 147 Tweets from @the_hindu.\n",
      "Getting data for 2020-04-14\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 194 Tweets from @the_hindu.\n",
      "Getting data for 2020-04-15\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 210 Tweets from @the_hindu.\n",
      "Getting data for 2020-04-16\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 166 Tweets from @the_hindu.\n",
      "Getting data for 2020-04-17\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 166 Tweets from @the_hindu.\n",
      "Getting data for 2020-04-18\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 114 Tweets from @the_hindu.\n",
      "Getting data for 2020-04-19\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 148 Tweets from @the_hindu.\n",
      "Getting data for 2020-04-20\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 151 Tweets from @the_hindu.\n",
      "Getting data for 2020-04-21\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 189 Tweets from @the_hindu.\n",
      "Getting data for 2020-04-22\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 149 Tweets from @the_hindu.\n",
      "Getting data for 2020-04-23\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 144 Tweets from @the_hindu.\n",
      "Getting data for 2020-04-24\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 112 Tweets from @the_hindu.\n",
      "Getting data for 2020-04-25\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 112 Tweets from @the_hindu.\n",
      "Getting data for 2020-04-26\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 138 Tweets from @the_hindu.\n",
      "Getting data for 2020-04-27\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 162 Tweets from @the_hindu.\n",
      "Getting data for 2020-04-28\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 139 Tweets from @the_hindu.\n",
      "Getting data for 2020-04-29\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 170 Tweets from @the_hindu.\n",
      "Getting data for 2020-04-30\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 130 Tweets from @the_hindu.\n",
      "Getting data for 2020-05-01\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 126 Tweets from @the_hindu.\n",
      "Getting data for 2020-05-02\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 125 Tweets from @the_hindu.\n",
      "Getting data for 2020-05-03\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 163 Tweets from @the_hindu.\n",
      "Getting data for 2020-05-04\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 177 Tweets from @the_hindu.\n",
      "Getting data for 2020-05-05\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 141 Tweets from @the_hindu.\n",
      "Getting data for 2020-05-06\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 139 Tweets from @the_hindu.\n",
      "Getting data for 2020-05-07\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 186 Tweets from @the_hindu.\n",
      "Getting data for 2020-05-08\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 147 Tweets from @the_hindu.\n",
      "Getting data for 2020-05-09\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 119 Tweets from @the_hindu.\n",
      "Getting data for 2020-05-10\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 123 Tweets from @the_hindu.\n",
      "Getting data for 2020-05-11\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 155 Tweets from @the_hindu.\n",
      "Getting data for 2020-05-12\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 144 Tweets from @the_hindu.\n",
      "Getting data for 2020-05-13\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 142 Tweets from @the_hindu.\n",
      "Getting data for 2020-05-14\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 149 Tweets from @the_hindu.\n",
      "Getting data for 2020-05-15\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 152 Tweets from @the_hindu.\n",
      "Getting data for 2020-05-16\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 109 Tweets from @the_hindu.\n",
      "Getting data for 2020-05-17\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 146 Tweets from @the_hindu.\n",
      "Getting data for 2020-05-18\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 196 Tweets from @the_hindu.\n",
      "Getting data for 2020-05-19\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 176 Tweets from @the_hindu.\n",
      "Getting data for 2020-05-20\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 147 Tweets from @the_hindu.\n",
      "Getting data for 2020-05-21\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 149 Tweets from @the_hindu.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting data for 2020-05-22\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 156 Tweets from @the_hindu.\n",
      "Getting data for 2020-05-23\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 119 Tweets from @the_hindu.\n",
      "Getting data for 2020-05-24\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 134 Tweets from @the_hindu.\n",
      "Getting data for 2020-05-25\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 151 Tweets from @the_hindu.\n",
      "Getting data for 2020-05-26\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 140 Tweets from @the_hindu.\n",
      "Getting data for 2020-05-27\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 133 Tweets from @the_hindu.\n",
      "Getting data for 2020-05-28\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 137 Tweets from @the_hindu.\n",
      "Getting data for 2020-05-29\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 130 Tweets from @the_hindu.\n",
      "Getting data for 2020-05-30\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 116 Tweets from @the_hindu.\n",
      "time taken: 18.97 mins\n",
      "Directory C:\\Users\\rahul\\News channels data\\DeccanChronicle created\n",
      "Getting data for 2020-01-22\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 7 Tweets from @DeccanChronicle.\n",
      "Getting data for 2020-01-23\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 13 Tweets from @DeccanChronicle.\n",
      "Getting data for 2020-01-24\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 19 Tweets from @DeccanChronicle.\n",
      "Getting data for 2020-01-25\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 5 Tweets from @DeccanChronicle.\n",
      "Getting data for 2020-01-26\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 10 Tweets from @DeccanChronicle.\n",
      "Getting data for 2020-01-27\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 10 Tweets from @DeccanChronicle.\n",
      "Getting data for 2020-01-28\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 6 Tweets from @DeccanChronicle.\n",
      "Getting data for 2020-01-29\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 10 Tweets from @DeccanChronicle.\n",
      "Getting data for 2020-01-30\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @DeccanChronicle.\n",
      "Getting data for 2020-01-31\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 11 Tweets from @DeccanChronicle.\n",
      "Getting data for 2020-02-01\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 29 Tweets from @DeccanChronicle.\n",
      "Getting data for 2020-02-02\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 8 Tweets from @DeccanChronicle.\n",
      "Getting data for 2020-02-03\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 11 Tweets from @DeccanChronicle.\n",
      "Getting data for 2020-02-04\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 13 Tweets from @DeccanChronicle.\n",
      "Getting data for 2020-02-05\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 9 Tweets from @DeccanChronicle.\n",
      "Getting data for 2020-02-06\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 13 Tweets from @DeccanChronicle.\n",
      "Getting data for 2020-02-07\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 11 Tweets from @DeccanChronicle.\n",
      "Getting data for 2020-02-08\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 16 Tweets from @DeccanChronicle.\n",
      "Getting data for 2020-02-09\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 20 Tweets from @DeccanChronicle.\n",
      "Getting data for 2020-02-10\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 17 Tweets from @DeccanChronicle.\n",
      "Getting data for 2020-02-11\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 15 Tweets from @DeccanChronicle.\n",
      "Getting data for 2020-02-12\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 10 Tweets from @DeccanChronicle.\n",
      "Getting data for 2020-02-13\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 15 Tweets from @DeccanChronicle.\n",
      "Getting data for 2020-02-14\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 19 Tweets from @DeccanChronicle.\n",
      "Getting data for 2020-02-15\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 15 Tweets from @DeccanChronicle.\n",
      "Getting data for 2020-02-16\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 11 Tweets from @DeccanChronicle.\n",
      "Getting data for 2020-02-17\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 19 Tweets from @DeccanChronicle.\n",
      "Getting data for 2020-02-18\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 18 Tweets from @DeccanChronicle.\n",
      "Getting data for 2020-02-19\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 9 Tweets from @DeccanChronicle.\n",
      "Getting data for 2020-02-20\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 14 Tweets from @DeccanChronicle.\n",
      "Getting data for 2020-02-21\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 23 Tweets from @DeccanChronicle.\n",
      "Getting data for 2020-02-22\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 22 Tweets from @DeccanChronicle.\n",
      "Getting data for 2020-02-23\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 16 Tweets from @DeccanChronicle.\n",
      "Getting data for 2020-02-24\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 23 Tweets from @DeccanChronicle.\n",
      "Getting data for 2020-02-25\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 9 Tweets from @DeccanChronicle.\n",
      "Getting data for 2020-02-26\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 21 Tweets from @DeccanChronicle.\n",
      "Getting data for 2020-02-27\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 11 Tweets from @DeccanChronicle.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting data for 2020-02-28\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 13 Tweets from @DeccanChronicle.\n",
      "Getting data for 2020-02-29\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 14 Tweets from @DeccanChronicle.\n",
      "Getting data for 2020-03-01\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 16 Tweets from @DeccanChronicle.\n",
      "Getting data for 2020-03-02\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 31 Tweets from @DeccanChronicle.\n",
      "Getting data for 2020-03-03\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 19 Tweets from @DeccanChronicle.\n",
      "Getting data for 2020-03-04\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 27 Tweets from @DeccanChronicle.\n",
      "Getting data for 2020-03-05\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 26 Tweets from @DeccanChronicle.\n",
      "Getting data for 2020-03-06\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 27 Tweets from @DeccanChronicle.\n",
      "Getting data for 2020-03-07\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 23 Tweets from @DeccanChronicle.\n",
      "Getting data for 2020-03-08\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 36 Tweets from @DeccanChronicle.\n",
      "Getting data for 2020-03-09\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 35 Tweets from @DeccanChronicle.\n",
      "Getting data for 2020-03-10\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 20 Tweets from @DeccanChronicle.\n",
      "Getting data for 2020-03-11\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 33 Tweets from @DeccanChronicle.\n",
      "Getting data for 2020-03-12\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 50 Tweets from @DeccanChronicle.\n",
      "Getting data for 2020-03-13\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 59 Tweets from @DeccanChronicle.\n",
      "Getting data for 2020-03-14\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 43 Tweets from @DeccanChronicle.\n",
      "Getting data for 2020-03-15\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 55 Tweets from @DeccanChronicle.\n",
      "Getting data for 2020-03-16\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 64 Tweets from @DeccanChronicle.\n",
      "Getting data for 2020-03-17\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 54 Tweets from @DeccanChronicle.\n",
      "Getting data for 2020-03-18\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 79 Tweets from @DeccanChronicle.\n",
      "Getting data for 2020-03-19\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 68 Tweets from @DeccanChronicle.\n",
      "Getting data for 2020-03-20\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 54 Tweets from @DeccanChronicle.\n",
      "Getting data for 2020-03-21\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 46 Tweets from @DeccanChronicle.\n",
      "Getting data for 2020-03-22\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 48 Tweets from @DeccanChronicle.\n",
      "Getting data for 2020-03-23\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 63 Tweets from @DeccanChronicle.\n",
      "Getting data for 2020-03-24\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 71 Tweets from @DeccanChronicle.\n",
      "Getting data for 2020-03-25\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 39 Tweets from @DeccanChronicle.\n",
      "Getting data for 2020-03-26\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 27 Tweets from @DeccanChronicle.\n",
      "Getting data for 2020-03-27\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 47 Tweets from @DeccanChronicle.\n",
      "Getting data for 2020-03-28\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 43 Tweets from @DeccanChronicle.\n",
      "Getting data for 2020-03-29\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 54 Tweets from @DeccanChronicle.\n",
      "Getting data for 2020-03-30\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 38 Tweets from @DeccanChronicle.\n",
      "Getting data for 2020-03-31\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 28 Tweets from @DeccanChronicle.\n",
      "Getting data for 2020-04-01\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 59 Tweets from @DeccanChronicle.\n",
      "Getting data for 2020-04-02\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 43 Tweets from @DeccanChronicle.\n",
      "Getting data for 2020-04-03\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 48 Tweets from @DeccanChronicle.\n",
      "Getting data for 2020-04-04\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 40 Tweets from @DeccanChronicle.\n",
      "Getting data for 2020-04-05\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 47 Tweets from @DeccanChronicle.\n",
      "Getting data for 2020-04-06\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 45 Tweets from @DeccanChronicle.\n",
      "Getting data for 2020-04-07\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 34 Tweets from @DeccanChronicle.\n",
      "Getting data for 2020-04-08\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 47 Tweets from @DeccanChronicle.\n",
      "Getting data for 2020-04-09\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 41 Tweets from @DeccanChronicle.\n",
      "Getting data for 2020-04-10\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 50 Tweets from @DeccanChronicle.\n",
      "Getting data for 2020-04-11\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 29 Tweets from @DeccanChronicle.\n",
      "Getting data for 2020-04-12\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 42 Tweets from @DeccanChronicle.\n",
      "Getting data for 2020-04-13\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 45 Tweets from @DeccanChronicle.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting data for 2020-04-14\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 44 Tweets from @DeccanChronicle.\n",
      "Getting data for 2020-04-15\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 64 Tweets from @DeccanChronicle.\n",
      "Getting data for 2020-04-16\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 40 Tweets from @DeccanChronicle.\n",
      "Getting data for 2020-04-17\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 42 Tweets from @DeccanChronicle.\n",
      "Getting data for 2020-04-18\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 31 Tweets from @DeccanChronicle.\n",
      "Getting data for 2020-04-19\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 36 Tweets from @DeccanChronicle.\n",
      "Getting data for 2020-04-20\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 52 Tweets from @DeccanChronicle.\n",
      "Getting data for 2020-04-21\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 35 Tweets from @DeccanChronicle.\n",
      "Getting data for 2020-04-22\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 41 Tweets from @DeccanChronicle.\n",
      "Getting data for 2020-04-23\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 43 Tweets from @DeccanChronicle.\n",
      "Getting data for 2020-04-24\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 40 Tweets from @DeccanChronicle.\n",
      "Getting data for 2020-04-25\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 26 Tweets from @DeccanChronicle.\n",
      "Getting data for 2020-04-26\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 43 Tweets from @DeccanChronicle.\n",
      "Getting data for 2020-04-27\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 35 Tweets from @DeccanChronicle.\n",
      "Getting data for 2020-04-28\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 38 Tweets from @DeccanChronicle.\n",
      "Getting data for 2020-04-29\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 39 Tweets from @DeccanChronicle.\n",
      "Getting data for 2020-04-30\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 27 Tweets from @DeccanChronicle.\n",
      "Getting data for 2020-05-01\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 43 Tweets from @DeccanChronicle.\n",
      "Getting data for 2020-05-02\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 44 Tweets from @DeccanChronicle.\n",
      "Getting data for 2020-05-03\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 41 Tweets from @DeccanChronicle.\n",
      "Getting data for 2020-05-04\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 45 Tweets from @DeccanChronicle.\n",
      "Getting data for 2020-05-05\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 53 Tweets from @DeccanChronicle.\n",
      "Getting data for 2020-05-06\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 50 Tweets from @DeccanChronicle.\n",
      "Getting data for 2020-05-07\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 47 Tweets from @DeccanChronicle.\n",
      "Getting data for 2020-05-08\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 50 Tweets from @DeccanChronicle.\n",
      "Getting data for 2020-05-09\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 31 Tweets from @DeccanChronicle.\n",
      "Getting data for 2020-05-10\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 27 Tweets from @DeccanChronicle.\n",
      "Getting data for 2020-05-11\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 41 Tweets from @DeccanChronicle.\n",
      "Getting data for 2020-05-12\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 40 Tweets from @DeccanChronicle.\n",
      "Getting data for 2020-05-13\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 43 Tweets from @DeccanChronicle.\n",
      "Getting data for 2020-05-14\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 37 Tweets from @DeccanChronicle.\n",
      "Getting data for 2020-05-15\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 43 Tweets from @DeccanChronicle.\n",
      "Getting data for 2020-05-16\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 37 Tweets from @DeccanChronicle.\n",
      "Getting data for 2020-05-17\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 34 Tweets from @DeccanChronicle.\n",
      "Getting data for 2020-05-18\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 40 Tweets from @DeccanChronicle.\n",
      "Getting data for 2020-05-19\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 36 Tweets from @DeccanChronicle.\n",
      "Getting data for 2020-05-20\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 51 Tweets from @DeccanChronicle.\n",
      "Getting data for 2020-05-21\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 26 Tweets from @DeccanChronicle.\n",
      "Getting data for 2020-05-22\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 47 Tweets from @DeccanChronicle.\n",
      "Getting data for 2020-05-23\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 26 Tweets from @DeccanChronicle.\n",
      "Getting data for 2020-05-24\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 34 Tweets from @DeccanChronicle.\n",
      "Getting data for 2020-05-25\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 42 Tweets from @DeccanChronicle.\n",
      "Getting data for 2020-05-26\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 34 Tweets from @DeccanChronicle.\n",
      "Getting data for 2020-05-27\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 36 Tweets from @DeccanChronicle.\n",
      "Getting data for 2020-05-28\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 35 Tweets from @DeccanChronicle.\n",
      "Getting data for 2020-05-29\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 35 Tweets from @DeccanChronicle.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting data for 2020-05-30\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 43 Tweets from @DeccanChronicle.\n",
      "time taken: 14.27 mins\n",
      "Directory C:\\Users\\rahul\\News channels data\\DeccanHerald created\n",
      "Getting data for 2020-01-22\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 90 Tweets from @DeccanHerald.\n",
      "Getting data for 2020-01-23\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 143 Tweets from @DeccanHerald.\n",
      "Getting data for 2020-01-24\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 106 Tweets from @DeccanHerald.\n",
      "Getting data for 2020-01-25\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 123 Tweets from @DeccanHerald.\n",
      "Getting data for 2020-01-26\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 96 Tweets from @DeccanHerald.\n",
      "Getting data for 2020-01-27\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 93 Tweets from @DeccanHerald.\n",
      "Getting data for 2020-01-28\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 131 Tweets from @DeccanHerald.\n",
      "Getting data for 2020-01-29\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 110 Tweets from @DeccanHerald.\n",
      "Getting data for 2020-01-30\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 112 Tweets from @DeccanHerald.\n",
      "Getting data for 2020-01-31\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 93 Tweets from @DeccanHerald.\n",
      "Getting data for 2020-02-01\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 131 Tweets from @DeccanHerald.\n",
      "Getting data for 2020-02-02\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 106 Tweets from @DeccanHerald.\n",
      "Getting data for 2020-02-03\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 107 Tweets from @DeccanHerald.\n",
      "Getting data for 2020-02-04\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 109 Tweets from @DeccanHerald.\n",
      "Getting data for 2020-02-05\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 102 Tweets from @DeccanHerald.\n",
      "Getting data for 2020-02-06\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 107 Tweets from @DeccanHerald.\n",
      "Getting data for 2020-02-07\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 100 Tweets from @DeccanHerald.\n",
      "Getting data for 2020-02-08\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 114 Tweets from @DeccanHerald.\n",
      "Getting data for 2020-02-09\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 122 Tweets from @DeccanHerald.\n",
      "Getting data for 2020-02-10\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 99 Tweets from @DeccanHerald.\n",
      "Getting data for 2020-02-11\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 162 Tweets from @DeccanHerald.\n",
      "Getting data for 2020-02-12\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 99 Tweets from @DeccanHerald.\n",
      "Getting data for 2020-02-13\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 114 Tweets from @DeccanHerald.\n",
      "Getting data for 2020-02-14\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 132 Tweets from @DeccanHerald.\n",
      "Getting data for 2020-02-15\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 115 Tweets from @DeccanHerald.\n",
      "Getting data for 2020-02-16\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 98 Tweets from @DeccanHerald.\n",
      "Getting data for 2020-02-17\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 108 Tweets from @DeccanHerald.\n",
      "Getting data for 2020-02-18\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 105 Tweets from @DeccanHerald.\n",
      "Getting data for 2020-02-19\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 109 Tweets from @DeccanHerald.\n",
      "Getting data for 2020-02-20\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 108 Tweets from @DeccanHerald.\n",
      "Getting data for 2020-02-21\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 118 Tweets from @DeccanHerald.\n",
      "Getting data for 2020-02-22\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 121 Tweets from @DeccanHerald.\n",
      "Getting data for 2020-02-23\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 123 Tweets from @DeccanHerald.\n",
      "Getting data for 2020-02-24\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 144 Tweets from @DeccanHerald.\n",
      "Getting data for 2020-02-25\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 114 Tweets from @DeccanHerald.\n",
      "Getting data for 2020-02-26\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 141 Tweets from @DeccanHerald.\n",
      "Getting data for 2020-02-27\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 129 Tweets from @DeccanHerald.\n",
      "Getting data for 2020-02-28\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 106 Tweets from @DeccanHerald.\n",
      "Getting data for 2020-02-29\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 101 Tweets from @DeccanHerald.\n",
      "Getting data for 2020-03-01\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 111 Tweets from @DeccanHerald.\n",
      "Getting data for 2020-03-02\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 135 Tweets from @DeccanHerald.\n",
      "Getting data for 2020-03-03\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 144 Tweets from @DeccanHerald.\n",
      "Getting data for 2020-03-04\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 133 Tweets from @DeccanHerald.\n",
      "Getting data for 2020-03-05\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 138 Tweets from @DeccanHerald.\n",
      "Getting data for 2020-03-06\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 159 Tweets from @DeccanHerald.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting data for 2020-03-07\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 76 Tweets from @DeccanHerald.\n",
      "Getting data for 2020-03-08\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 118 Tweets from @DeccanHerald.\n",
      "Getting data for 2020-03-09\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 120 Tweets from @DeccanHerald.\n",
      "Getting data for 2020-03-10\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 122 Tweets from @DeccanHerald.\n",
      "Getting data for 2020-03-11\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 125 Tweets from @DeccanHerald.\n",
      "Getting data for 2020-03-12\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 122 Tweets from @DeccanHerald.\n",
      "Getting data for 2020-03-13\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 133 Tweets from @DeccanHerald.\n",
      "Getting data for 2020-03-14\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 119 Tweets from @DeccanHerald.\n",
      "Getting data for 2020-03-15\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 124 Tweets from @DeccanHerald.\n",
      "Getting data for 2020-03-16\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 142 Tweets from @DeccanHerald.\n",
      "Getting data for 2020-03-17\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 111 Tweets from @DeccanHerald.\n",
      "Getting data for 2020-03-18\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 103 Tweets from @DeccanHerald.\n",
      "Getting data for 2020-03-19\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 169 Tweets from @DeccanHerald.\n",
      "Getting data for 2020-03-20\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 139 Tweets from @DeccanHerald.\n",
      "Getting data for 2020-03-21\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 132 Tweets from @DeccanHerald.\n",
      "Getting data for 2020-03-22\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 127 Tweets from @DeccanHerald.\n",
      "Getting data for 2020-03-23\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 150 Tweets from @DeccanHerald.\n",
      "Getting data for 2020-03-24\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 170 Tweets from @DeccanHerald.\n",
      "Getting data for 2020-03-25\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 189 Tweets from @DeccanHerald.\n",
      "Getting data for 2020-03-26\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 144 Tweets from @DeccanHerald.\n",
      "Getting data for 2020-03-27\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 185 Tweets from @DeccanHerald.\n",
      "Getting data for 2020-03-28\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 154 Tweets from @DeccanHerald.\n",
      "Getting data for 2020-03-29\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 144 Tweets from @DeccanHerald.\n",
      "Getting data for 2020-03-30\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 169 Tweets from @DeccanHerald.\n",
      "Getting data for 2020-03-31\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 165 Tweets from @DeccanHerald.\n",
      "Getting data for 2020-04-01\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 175 Tweets from @DeccanHerald.\n",
      "Getting data for 2020-04-02\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 162 Tweets from @DeccanHerald.\n",
      "Getting data for 2020-04-03\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 166 Tweets from @DeccanHerald.\n",
      "Getting data for 2020-04-04\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 162 Tweets from @DeccanHerald.\n",
      "Getting data for 2020-04-05\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 167 Tweets from @DeccanHerald.\n",
      "Getting data for 2020-04-06\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 182 Tweets from @DeccanHerald.\n",
      "Getting data for 2020-04-07\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 193 Tweets from @DeccanHerald.\n",
      "Getting data for 2020-04-08\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 189 Tweets from @DeccanHerald.\n",
      "Getting data for 2020-04-09\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 177 Tweets from @DeccanHerald.\n",
      "Getting data for 2020-04-10\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 183 Tweets from @DeccanHerald.\n",
      "Getting data for 2020-04-11\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 140 Tweets from @DeccanHerald.\n",
      "Getting data for 2020-04-12\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 171 Tweets from @DeccanHerald.\n",
      "Getting data for 2020-04-13\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 154 Tweets from @DeccanHerald.\n",
      "Getting data for 2020-04-14\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 166 Tweets from @DeccanHerald.\n",
      "Getting data for 2020-04-15\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 164 Tweets from @DeccanHerald.\n",
      "Getting data for 2020-04-16\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 173 Tweets from @DeccanHerald.\n",
      "Getting data for 2020-04-17\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 193 Tweets from @DeccanHerald.\n",
      "Getting data for 2020-04-18\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 190 Tweets from @DeccanHerald.\n",
      "Getting data for 2020-04-19\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 154 Tweets from @DeccanHerald.\n",
      "Getting data for 2020-04-20\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 171 Tweets from @DeccanHerald.\n",
      "Getting data for 2020-04-21\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 192 Tweets from @DeccanHerald.\n",
      "Getting data for 2020-04-22\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 187 Tweets from @DeccanHerald.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting data for 2020-04-23\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 186 Tweets from @DeccanHerald.\n",
      "Getting data for 2020-04-24\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 143 Tweets from @DeccanHerald.\n",
      "Getting data for 2020-04-25\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 167 Tweets from @DeccanHerald.\n",
      "Getting data for 2020-04-26\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 153 Tweets from @DeccanHerald.\n",
      "Getting data for 2020-04-27\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 164 Tweets from @DeccanHerald.\n",
      "Getting data for 2020-04-28\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 184 Tweets from @DeccanHerald.\n",
      "Getting data for 2020-04-29\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 175 Tweets from @DeccanHerald.\n",
      "Getting data for 2020-04-30\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 170 Tweets from @DeccanHerald.\n",
      "Getting data for 2020-05-01\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 175 Tweets from @DeccanHerald.\n",
      "Getting data for 2020-05-02\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 171 Tweets from @DeccanHerald.\n",
      "Getting data for 2020-05-03\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 137 Tweets from @DeccanHerald.\n",
      "Getting data for 2020-05-04\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 153 Tweets from @DeccanHerald.\n",
      "Getting data for 2020-05-05\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 175 Tweets from @DeccanHerald.\n",
      "Getting data for 2020-05-06\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 174 Tweets from @DeccanHerald.\n",
      "Getting data for 2020-05-07\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 185 Tweets from @DeccanHerald.\n",
      "Getting data for 2020-05-08\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 179 Tweets from @DeccanHerald.\n",
      "Getting data for 2020-05-09\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 198 Tweets from @DeccanHerald.\n",
      "Getting data for 2020-05-10\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 160 Tweets from @DeccanHerald.\n",
      "Getting data for 2020-05-11\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 175 Tweets from @DeccanHerald.\n",
      "Getting data for 2020-05-12\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 187 Tweets from @DeccanHerald.\n",
      "Getting data for 2020-05-13\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 185 Tweets from @DeccanHerald.\n",
      "Getting data for 2020-05-14\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 178 Tweets from @DeccanHerald.\n",
      "Getting data for 2020-05-15\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 203 Tweets from @DeccanHerald.\n",
      "Getting data for 2020-05-16\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 172 Tweets from @DeccanHerald.\n",
      "Getting data for 2020-05-17\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 159 Tweets from @DeccanHerald.\n",
      "Getting data for 2020-05-18\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 155 Tweets from @DeccanHerald.\n",
      "Getting data for 2020-05-19\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 155 Tweets from @DeccanHerald.\n",
      "Getting data for 2020-05-20\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 180 Tweets from @DeccanHerald.\n",
      "Getting data for 2020-05-21\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 162 Tweets from @DeccanHerald.\n",
      "Getting data for 2020-05-22\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 168 Tweets from @DeccanHerald.\n",
      "Getting data for 2020-05-23\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 153 Tweets from @DeccanHerald.\n",
      "Getting data for 2020-05-24\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 146 Tweets from @DeccanHerald.\n",
      "Getting data for 2020-05-25\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 148 Tweets from @DeccanHerald.\n",
      "Getting data for 2020-05-26\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 167 Tweets from @DeccanHerald.\n",
      "Getting data for 2020-05-27\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 172 Tweets from @DeccanHerald.\n",
      "Getting data for 2020-05-28\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 158 Tweets from @DeccanHerald.\n",
      "Getting data for 2020-05-29\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 153 Tweets from @DeccanHerald.\n",
      "Getting data for 2020-05-30\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 155 Tweets from @DeccanHerald.\n",
      "time taken: 19.59 mins\n",
      "Directory C:\\Users\\rahul\\News channels data\\mid_day created\n",
      "Getting data for 2020-01-22\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 69 Tweets from @mid_day.\n",
      "Getting data for 2020-01-23\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 63 Tweets from @mid_day.\n",
      "Getting data for 2020-01-24\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 68 Tweets from @mid_day.\n",
      "Getting data for 2020-01-25\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 51 Tweets from @mid_day.\n",
      "Getting data for 2020-01-26\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 60 Tweets from @mid_day.\n",
      "Getting data for 2020-01-27\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 45 Tweets from @mid_day.\n",
      "Getting data for 2020-01-28\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 59 Tweets from @mid_day.\n",
      "Getting data for 2020-01-29\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 60 Tweets from @mid_day.\n",
      "Getting data for 2020-01-30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 64 Tweets from @mid_day.\n",
      "Getting data for 2020-01-31\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 60 Tweets from @mid_day.\n",
      "Getting data for 2020-02-01\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 65 Tweets from @mid_day.\n",
      "Getting data for 2020-02-02\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 48 Tweets from @mid_day.\n",
      "Getting data for 2020-02-03\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 56 Tweets from @mid_day.\n",
      "Getting data for 2020-02-04\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 61 Tweets from @mid_day.\n",
      "Getting data for 2020-02-05\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 54 Tweets from @mid_day.\n",
      "Getting data for 2020-02-06\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 58 Tweets from @mid_day.\n",
      "Getting data for 2020-02-07\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 49 Tweets from @mid_day.\n",
      "Getting data for 2020-02-08\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 51 Tweets from @mid_day.\n",
      "Getting data for 2020-02-09\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 44 Tweets from @mid_day.\n",
      "Getting data for 2020-02-10\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 76 Tweets from @mid_day.\n",
      "Getting data for 2020-02-11\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 52 Tweets from @mid_day.\n",
      "Getting data for 2020-02-12\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 59 Tweets from @mid_day.\n",
      "Getting data for 2020-02-13\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 61 Tweets from @mid_day.\n",
      "Getting data for 2020-02-14\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 66 Tweets from @mid_day.\n",
      "Getting data for 2020-02-15\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 49 Tweets from @mid_day.\n",
      "Getting data for 2020-02-16\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 49 Tweets from @mid_day.\n",
      "Getting data for 2020-02-17\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 54 Tweets from @mid_day.\n",
      "Getting data for 2020-02-18\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 56 Tweets from @mid_day.\n",
      "Getting data for 2020-02-19\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 59 Tweets from @mid_day.\n",
      "Getting data for 2020-02-20\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 59 Tweets from @mid_day.\n",
      "Getting data for 2020-02-21\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 63 Tweets from @mid_day.\n",
      "Getting data for 2020-02-22\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 43 Tweets from @mid_day.\n",
      "Getting data for 2020-02-23\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 43 Tweets from @mid_day.\n",
      "Getting data for 2020-02-24\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 69 Tweets from @mid_day.\n",
      "Getting data for 2020-02-25\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 64 Tweets from @mid_day.\n",
      "Getting data for 2020-02-26\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 58 Tweets from @mid_day.\n",
      "Getting data for 2020-02-27\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 61 Tweets from @mid_day.\n",
      "Getting data for 2020-02-28\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 56 Tweets from @mid_day.\n",
      "Getting data for 2020-02-29\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 44 Tweets from @mid_day.\n",
      "Getting data for 2020-03-01\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 47 Tweets from @mid_day.\n",
      "Getting data for 2020-03-02\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 57 Tweets from @mid_day.\n",
      "Getting data for 2020-03-03\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 55 Tweets from @mid_day.\n",
      "Getting data for 2020-03-04\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 71 Tweets from @mid_day.\n",
      "Getting data for 2020-03-05\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 56 Tweets from @mid_day.\n",
      "Getting data for 2020-03-06\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 57 Tweets from @mid_day.\n",
      "Getting data for 2020-03-07\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 40 Tweets from @mid_day.\n",
      "Getting data for 2020-03-08\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 44 Tweets from @mid_day.\n",
      "Getting data for 2020-03-09\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 56 Tweets from @mid_day.\n",
      "Getting data for 2020-03-10\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 34 Tweets from @mid_day.\n",
      "Getting data for 2020-03-11\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 51 Tweets from @mid_day.\n",
      "Getting data for 2020-03-12\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 62 Tweets from @mid_day.\n",
      "Getting data for 2020-03-13\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 63 Tweets from @mid_day.\n",
      "Getting data for 2020-03-14\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 50 Tweets from @mid_day.\n",
      "Getting data for 2020-03-15\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 54 Tweets from @mid_day.\n",
      "Getting data for 2020-03-16\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 52 Tweets from @mid_day.\n",
      "Getting data for 2020-03-17\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 61 Tweets from @mid_day.\n",
      "Getting data for 2020-03-18\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 60 Tweets from @mid_day.\n",
      "Getting data for 2020-03-19\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 54 Tweets from @mid_day.\n",
      "Getting data for 2020-03-20\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 62 Tweets from @mid_day.\n",
      "Getting data for 2020-03-21\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 39 Tweets from @mid_day.\n",
      "Getting data for 2020-03-22\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 80 Tweets from @mid_day.\n",
      "Getting data for 2020-03-23\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 55 Tweets from @mid_day.\n",
      "Getting data for 2020-03-24\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 67 Tweets from @mid_day.\n",
      "Getting data for 2020-03-25\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 60 Tweets from @mid_day.\n",
      "Getting data for 2020-03-26\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 68 Tweets from @mid_day.\n",
      "Getting data for 2020-03-27\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 63 Tweets from @mid_day.\n",
      "Getting data for 2020-03-28\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 53 Tweets from @mid_day.\n",
      "Getting data for 2020-03-29\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 61 Tweets from @mid_day.\n",
      "Getting data for 2020-03-30\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 66 Tweets from @mid_day.\n",
      "Getting data for 2020-03-31\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 60 Tweets from @mid_day.\n",
      "Getting data for 2020-04-01\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 68 Tweets from @mid_day.\n",
      "Getting data for 2020-04-02\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 72 Tweets from @mid_day.\n",
      "Getting data for 2020-04-03\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 66 Tweets from @mid_day.\n",
      "Getting data for 2020-04-04\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 53 Tweets from @mid_day.\n",
      "Getting data for 2020-04-05\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 77 Tweets from @mid_day.\n",
      "Getting data for 2020-04-06\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 62 Tweets from @mid_day.\n",
      "Getting data for 2020-04-07\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 63 Tweets from @mid_day.\n",
      "Getting data for 2020-04-08\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 71 Tweets from @mid_day.\n",
      "Getting data for 2020-04-09\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 59 Tweets from @mid_day.\n",
      "Getting data for 2020-04-10\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 62 Tweets from @mid_day.\n",
      "Getting data for 2020-04-11\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 46 Tweets from @mid_day.\n",
      "Getting data for 2020-04-12\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 47 Tweets from @mid_day.\n",
      "Getting data for 2020-04-13\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 62 Tweets from @mid_day.\n",
      "Getting data for 2020-04-14\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 71 Tweets from @mid_day.\n",
      "Getting data for 2020-04-15\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 60 Tweets from @mid_day.\n",
      "Getting data for 2020-04-16\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 60 Tweets from @mid_day.\n",
      "Getting data for 2020-04-17\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 52 Tweets from @mid_day.\n",
      "Getting data for 2020-04-18\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 41 Tweets from @mid_day.\n",
      "Getting data for 2020-04-19\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 51 Tweets from @mid_day.\n",
      "Getting data for 2020-04-20\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 57 Tweets from @mid_day.\n",
      "Getting data for 2020-04-21\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 56 Tweets from @mid_day.\n",
      "Getting data for 2020-04-22\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 59 Tweets from @mid_day.\n",
      "Getting data for 2020-04-23\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 61 Tweets from @mid_day.\n",
      "Getting data for 2020-04-24\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 58 Tweets from @mid_day.\n",
      "Getting data for 2020-04-25\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 46 Tweets from @mid_day.\n",
      "Getting data for 2020-04-26\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 56 Tweets from @mid_day.\n",
      "Getting data for 2020-04-27\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 55 Tweets from @mid_day.\n",
      "Getting data for 2020-04-28\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 55 Tweets from @mid_day.\n",
      "Getting data for 2020-04-29\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 63 Tweets from @mid_day.\n",
      "Getting data for 2020-04-30\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 72 Tweets from @mid_day.\n",
      "Getting data for 2020-05-01\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 52 Tweets from @mid_day.\n",
      "Getting data for 2020-05-02\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 52 Tweets from @mid_day.\n",
      "Getting data for 2020-05-03\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 51 Tweets from @mid_day.\n",
      "Getting data for 2020-05-04\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 54 Tweets from @mid_day.\n",
      "Getting data for 2020-05-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 54 Tweets from @mid_day.\n",
      "Getting data for 2020-05-06\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 63 Tweets from @mid_day.\n",
      "Getting data for 2020-05-07\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 59 Tweets from @mid_day.\n",
      "Getting data for 2020-05-08\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 55 Tweets from @mid_day.\n",
      "Getting data for 2020-05-09\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 41 Tweets from @mid_day.\n",
      "Getting data for 2020-05-10\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 62 Tweets from @mid_day.\n",
      "Getting data for 2020-05-11\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 57 Tweets from @mid_day.\n",
      "Getting data for 2020-05-12\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 71 Tweets from @mid_day.\n",
      "Getting data for 2020-05-13\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 59 Tweets from @mid_day.\n",
      "Getting data for 2020-05-14\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 66 Tweets from @mid_day.\n",
      "Getting data for 2020-05-15\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 61 Tweets from @mid_day.\n",
      "Getting data for 2020-05-16\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 55 Tweets from @mid_day.\n",
      "Getting data for 2020-05-17\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 54 Tweets from @mid_day.\n",
      "Getting data for 2020-05-18\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 54 Tweets from @mid_day.\n",
      "Getting data for 2020-05-19\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 55 Tweets from @mid_day.\n",
      "Getting data for 2020-05-20\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 65 Tweets from @mid_day.\n",
      "Getting data for 2020-05-21\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 62 Tweets from @mid_day.\n",
      "Getting data for 2020-05-22\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 61 Tweets from @mid_day.\n",
      "Getting data for 2020-05-23\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 51 Tweets from @mid_day.\n",
      "Getting data for 2020-05-24\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 53 Tweets from @mid_day.\n",
      "Getting data for 2020-05-25\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 55 Tweets from @mid_day.\n",
      "Getting data for 2020-05-26\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 57 Tweets from @mid_day.\n",
      "Getting data for 2020-05-27\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 60 Tweets from @mid_day.\n",
      "Getting data for 2020-05-28\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 57 Tweets from @mid_day.\n",
      "Getting data for 2020-05-29\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 57 Tweets from @mid_day.\n",
      "Getting data for 2020-05-30\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 51 Tweets from @mid_day.\n",
      "time taken: 15.3 mins\n",
      "Directory C:\\Users\\rahul\\News channels data\\HindustanTimes created\n",
      "Getting data for 2020-01-22\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 508 Tweets from @HindustanTimes.\n",
      "Getting data for 2020-01-23\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 459 Tweets from @HindustanTimes.\n",
      "Getting data for 2020-01-24\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 442 Tweets from @HindustanTimes.\n",
      "Getting data for 2020-01-25\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 358 Tweets from @HindustanTimes.\n",
      "Getting data for 2020-01-26\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 259 Tweets from @HindustanTimes.\n",
      "Getting data for 2020-01-27\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 429 Tweets from @HindustanTimes.\n",
      "Getting data for 2020-01-28\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 442 Tweets from @HindustanTimes.\n",
      "Getting data for 2020-01-29\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 494 Tweets from @HindustanTimes.\n",
      "Getting data for 2020-01-30\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 483 Tweets from @HindustanTimes.\n",
      "Getting data for 2020-01-31\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 427 Tweets from @HindustanTimes.\n",
      "Getting data for 2020-02-01\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 379 Tweets from @HindustanTimes.\n",
      "Getting data for 2020-02-02\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 330 Tweets from @HindustanTimes.\n",
      "Getting data for 2020-02-03\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 438 Tweets from @HindustanTimes.\n",
      "Getting data for 2020-02-04\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 431 Tweets from @HindustanTimes.\n",
      "Getting data for 2020-02-05\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 474 Tweets from @HindustanTimes.\n",
      "Getting data for 2020-02-06\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 443 Tweets from @HindustanTimes.\n",
      "Getting data for 2020-02-07\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 441 Tweets from @HindustanTimes.\n",
      "Getting data for 2020-02-08\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 380 Tweets from @HindustanTimes.\n",
      "Getting data for 2020-02-09\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 351 Tweets from @HindustanTimes.\n",
      "Getting data for 2020-02-10\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 405 Tweets from @HindustanTimes.\n",
      "Getting data for 2020-02-11\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 545 Tweets from @HindustanTimes.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting data for 2020-02-12\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 490 Tweets from @HindustanTimes.\n",
      "Getting data for 2020-02-13\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 628 Tweets from @HindustanTimes.\n",
      "Getting data for 2020-02-14\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 806 Tweets from @HindustanTimes.\n",
      "Getting data for 2020-02-15\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 381 Tweets from @HindustanTimes.\n",
      "Getting data for 2020-02-16\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 368 Tweets from @HindustanTimes.\n",
      "Getting data for 2020-02-17\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 457 Tweets from @HindustanTimes.\n",
      "Getting data for 2020-02-18\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 510 Tweets from @HindustanTimes.\n",
      "Getting data for 2020-02-19\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 498 Tweets from @HindustanTimes.\n",
      "Getting data for 2020-02-20\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 520 Tweets from @HindustanTimes.\n",
      "Getting data for 2020-02-21\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 451 Tweets from @HindustanTimes.\n",
      "Getting data for 2020-02-22\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 384 Tweets from @HindustanTimes.\n",
      "Getting data for 2020-02-23\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 345 Tweets from @HindustanTimes.\n",
      "Getting data for 2020-02-24\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 441 Tweets from @HindustanTimes.\n",
      "Getting data for 2020-02-25\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 456 Tweets from @HindustanTimes.\n",
      "Getting data for 2020-02-26\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 437 Tweets from @HindustanTimes.\n",
      "Getting data for 2020-02-27\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 489 Tweets from @HindustanTimes.\n",
      "Getting data for 2020-02-28\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 472 Tweets from @HindustanTimes.\n",
      "Getting data for 2020-02-29\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 350 Tweets from @HindustanTimes.\n",
      "Getting data for 2020-03-01\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 305 Tweets from @HindustanTimes.\n",
      "Getting data for 2020-03-02\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 420 Tweets from @HindustanTimes.\n",
      "Getting data for 2020-03-03\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 755 Tweets from @HindustanTimes.\n",
      "Getting data for 2020-03-04\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 781 Tweets from @HindustanTimes.\n",
      "Getting data for 2020-03-05\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 480 Tweets from @HindustanTimes.\n",
      "Getting data for 2020-03-06\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 1491 Tweets from @HindustanTimes.\n",
      "Getting data for 2020-03-07\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 380 Tweets from @HindustanTimes.\n",
      "Getting data for 2020-03-08\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 380 Tweets from @HindustanTimes.\n",
      "Getting data for 2020-03-09\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 361 Tweets from @HindustanTimes.\n",
      "Getting data for 2020-03-10\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 188 Tweets from @HindustanTimes.\n",
      "Getting data for 2020-03-11\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 479 Tweets from @HindustanTimes.\n",
      "Getting data for 2020-03-12\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 476 Tweets from @HindustanTimes.\n",
      "Getting data for 2020-03-13\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 475 Tweets from @HindustanTimes.\n",
      "Getting data for 2020-03-14\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 374 Tweets from @HindustanTimes.\n",
      "Getting data for 2020-03-15\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 334 Tweets from @HindustanTimes.\n",
      "Getting data for 2020-03-16\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 487 Tweets from @HindustanTimes.\n",
      "Getting data for 2020-03-17\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 496 Tweets from @HindustanTimes.\n",
      "Getting data for 2020-03-18\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 523 Tweets from @HindustanTimes.\n",
      "Getting data for 2020-03-19\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 487 Tweets from @HindustanTimes.\n",
      "Getting data for 2020-03-20\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 406 Tweets from @HindustanTimes.\n",
      "Getting data for 2020-03-21\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 342 Tweets from @HindustanTimes.\n",
      "Getting data for 2020-03-22\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 297 Tweets from @HindustanTimes.\n",
      "Getting data for 2020-03-23\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 371 Tweets from @HindustanTimes.\n",
      "Getting data for 2020-03-24\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 485 Tweets from @HindustanTimes.\n",
      "Getting data for 2020-03-25\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 481 Tweets from @HindustanTimes.\n",
      "Getting data for 2020-03-26\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 503 Tweets from @HindustanTimes.\n",
      "Getting data for 2020-03-27\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 483 Tweets from @HindustanTimes.\n",
      "Getting data for 2020-03-28\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 449 Tweets from @HindustanTimes.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting data for 2020-03-29\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 461 Tweets from @HindustanTimes.\n",
      "Getting data for 2020-03-30\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 520 Tweets from @HindustanTimes.\n",
      "Getting data for 2020-03-31\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 507 Tweets from @HindustanTimes.\n",
      "Getting data for 2020-04-01\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 487 Tweets from @HindustanTimes.\n",
      "Getting data for 2020-04-02\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 531 Tweets from @HindustanTimes.\n",
      "Getting data for 2020-04-03\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 515 Tweets from @HindustanTimes.\n",
      "Getting data for 2020-04-04\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 452 Tweets from @HindustanTimes.\n",
      "Getting data for 2020-04-05\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 448 Tweets from @HindustanTimes.\n",
      "Getting data for 2020-04-06\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 547 Tweets from @HindustanTimes.\n",
      "Getting data for 2020-04-07\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 546 Tweets from @HindustanTimes.\n",
      "Getting data for 2020-04-08\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 534 Tweets from @HindustanTimes.\n",
      "Getting data for 2020-04-09\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 601 Tweets from @HindustanTimes.\n",
      "Getting data for 2020-04-10\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 506 Tweets from @HindustanTimes.\n",
      "Getting data for 2020-04-11\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 529 Tweets from @HindustanTimes.\n",
      "Getting data for 2020-04-12\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 436 Tweets from @HindustanTimes.\n",
      "Getting data for 2020-04-13\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 534 Tweets from @HindustanTimes.\n",
      "Getting data for 2020-04-14\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 573 Tweets from @HindustanTimes.\n",
      "Getting data for 2020-04-15\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 597 Tweets from @HindustanTimes.\n",
      "Getting data for 2020-04-16\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 631 Tweets from @HindustanTimes.\n",
      "Getting data for 2020-04-17\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 636 Tweets from @HindustanTimes.\n",
      "Getting data for 2020-04-18\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 543 Tweets from @HindustanTimes.\n",
      "Getting data for 2020-04-19\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 527 Tweets from @HindustanTimes.\n",
      "Getting data for 2020-04-20\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 592 Tweets from @HindustanTimes.\n",
      "Getting data for 2020-04-21\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 581 Tweets from @HindustanTimes.\n",
      "Getting data for 2020-04-22\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 639 Tweets from @HindustanTimes.\n",
      "Getting data for 2020-04-23\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 597 Tweets from @HindustanTimes.\n",
      "Getting data for 2020-04-24\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 577 Tweets from @HindustanTimes.\n",
      "Getting data for 2020-04-25\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 566 Tweets from @HindustanTimes.\n",
      "Getting data for 2020-04-26\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 511 Tweets from @HindustanTimes.\n",
      "Getting data for 2020-04-27\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 537 Tweets from @HindustanTimes.\n",
      "Getting data for 2020-04-28\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 656 Tweets from @HindustanTimes.\n",
      "Getting data for 2020-04-29\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 656 Tweets from @HindustanTimes.\n",
      "Getting data for 2020-04-30\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 650 Tweets from @HindustanTimes.\n",
      "Getting data for 2020-05-01\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 623 Tweets from @HindustanTimes.\n",
      "Getting data for 2020-05-02\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 588 Tweets from @HindustanTimes.\n",
      "Getting data for 2020-05-03\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 529 Tweets from @HindustanTimes.\n",
      "Getting data for 2020-05-04\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 591 Tweets from @HindustanTimes.\n",
      "Getting data for 2020-05-05\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 610 Tweets from @HindustanTimes.\n",
      "Getting data for 2020-05-06\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 662 Tweets from @HindustanTimes.\n",
      "Getting data for 2020-05-07\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 648 Tweets from @HindustanTimes.\n",
      "Getting data for 2020-05-08\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 716 Tweets from @HindustanTimes.\n",
      "Getting data for 2020-05-09\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 561 Tweets from @HindustanTimes.\n",
      "Getting data for 2020-05-10\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 481 Tweets from @HindustanTimes.\n",
      "Getting data for 2020-05-11\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 550 Tweets from @HindustanTimes.\n",
      "Getting data for 2020-05-12\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 682 Tweets from @HindustanTimes.\n",
      "Getting data for 2020-05-13\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 610 Tweets from @HindustanTimes.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting data for 2020-05-14\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 581 Tweets from @HindustanTimes.\n",
      "Getting data for 2020-05-15\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 572 Tweets from @HindustanTimes.\n",
      "Getting data for 2020-05-16\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 551 Tweets from @HindustanTimes.\n",
      "Getting data for 2020-05-17\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 470 Tweets from @HindustanTimes.\n",
      "Getting data for 2020-05-18\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 540 Tweets from @HindustanTimes.\n",
      "Getting data for 2020-05-19\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 580 Tweets from @HindustanTimes.\n",
      "Getting data for 2020-05-20\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 655 Tweets from @HindustanTimes.\n",
      "Getting data for 2020-05-21\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 600 Tweets from @HindustanTimes.\n",
      "Getting data for 2020-05-22\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 609 Tweets from @HindustanTimes.\n",
      "Getting data for 2020-05-23\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 558 Tweets from @HindustanTimes.\n",
      "Getting data for 2020-05-24\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 463 Tweets from @HindustanTimes.\n",
      "Getting data for 2020-05-25\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 526 Tweets from @HindustanTimes.\n",
      "Getting data for 2020-05-26\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 515 Tweets from @HindustanTimes.\n",
      "Getting data for 2020-05-27\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 566 Tweets from @HindustanTimes.\n",
      "Getting data for 2020-05-28\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 564 Tweets from @HindustanTimes.\n",
      "Getting data for 2020-05-29\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 569 Tweets from @HindustanTimes.\n",
      "Getting data for 2020-05-30\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 553 Tweets from @HindustanTimes.\n",
      "time taken: 33.66 mins\n",
      "Directory C:\\Users\\rahul\\News channels data\\IndianExpress created\n",
      "Getting data for 2020-01-22\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 192 Tweets from @IndianExpress.\n",
      "Getting data for 2020-01-23\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 160 Tweets from @IndianExpress.\n",
      "Getting data for 2020-01-24\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 182 Tweets from @IndianExpress.\n",
      "Getting data for 2020-01-25\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 176 Tweets from @IndianExpress.\n",
      "Getting data for 2020-01-26\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 130 Tweets from @IndianExpress.\n",
      "Getting data for 2020-01-27\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 188 Tweets from @IndianExpress.\n",
      "Getting data for 2020-01-28\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 190 Tweets from @IndianExpress.\n",
      "Getting data for 2020-01-29\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 171 Tweets from @IndianExpress.\n",
      "Getting data for 2020-01-30\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 166 Tweets from @IndianExpress.\n",
      "Getting data for 2020-01-31\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 152 Tweets from @IndianExpress.\n",
      "Getting data for 2020-02-01\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 266 Tweets from @IndianExpress.\n",
      "Getting data for 2020-02-02\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 194 Tweets from @IndianExpress.\n",
      "Getting data for 2020-02-03\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 192 Tweets from @IndianExpress.\n",
      "Getting data for 2020-02-04\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 133 Tweets from @IndianExpress.\n",
      "Getting data for 2020-02-05\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 173 Tweets from @IndianExpress.\n",
      "Getting data for 2020-02-06\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 137 Tweets from @IndianExpress.\n",
      "Getting data for 2020-02-07\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 148 Tweets from @IndianExpress.\n",
      "Getting data for 2020-02-08\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 125 Tweets from @IndianExpress.\n",
      "Getting data for 2020-02-09\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 144 Tweets from @IndianExpress.\n",
      "Getting data for 2020-02-10\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 156 Tweets from @IndianExpress.\n",
      "Getting data for 2020-02-11\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 273 Tweets from @IndianExpress.\n",
      "Getting data for 2020-02-12\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 179 Tweets from @IndianExpress.\n",
      "Getting data for 2020-02-13\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 195 Tweets from @IndianExpress.\n",
      "Getting data for 2020-02-14\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 180 Tweets from @IndianExpress.\n",
      "Getting data for 2020-02-15\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 169 Tweets from @IndianExpress.\n",
      "Getting data for 2020-02-16\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 133 Tweets from @IndianExpress.\n",
      "Getting data for 2020-02-17\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 145 Tweets from @IndianExpress.\n",
      "Getting data for 2020-02-18\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 197 Tweets from @IndianExpress.\n",
      "Getting data for 2020-02-19\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 190 Tweets from @IndianExpress.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting data for 2020-02-20\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 192 Tweets from @IndianExpress.\n",
      "Getting data for 2020-02-21\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 166 Tweets from @IndianExpress.\n",
      "Getting data for 2020-02-22\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 187 Tweets from @IndianExpress.\n",
      "Getting data for 2020-02-23\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 149 Tweets from @IndianExpress.\n",
      "Getting data for 2020-02-24\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 206 Tweets from @IndianExpress.\n",
      "Getting data for 2020-02-25\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 215 Tweets from @IndianExpress.\n",
      "Getting data for 2020-02-26\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 170 Tweets from @IndianExpress.\n",
      "Getting data for 2020-02-27\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 170 Tweets from @IndianExpress.\n",
      "Getting data for 2020-02-28\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 198 Tweets from @IndianExpress.\n",
      "Getting data for 2020-02-29\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 156 Tweets from @IndianExpress.\n",
      "Getting data for 2020-03-01\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 158 Tweets from @IndianExpress.\n",
      "Getting data for 2020-03-02\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 140 Tweets from @IndianExpress.\n",
      "Getting data for 2020-03-03\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 205 Tweets from @IndianExpress.\n",
      "Getting data for 2020-03-04\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 164 Tweets from @IndianExpress.\n",
      "Getting data for 2020-03-05\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 186 Tweets from @IndianExpress.\n",
      "Getting data for 2020-03-06\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 192 Tweets from @IndianExpress.\n",
      "Getting data for 2020-03-07\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 172 Tweets from @IndianExpress.\n",
      "Getting data for 2020-03-08\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 151 Tweets from @IndianExpress.\n",
      "Getting data for 2020-03-09\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 142 Tweets from @IndianExpress.\n",
      "Getting data for 2020-03-10\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 95 Tweets from @IndianExpress.\n",
      "Getting data for 2020-03-11\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 167 Tweets from @IndianExpress.\n",
      "Getting data for 2020-03-12\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 173 Tweets from @IndianExpress.\n",
      "Getting data for 2020-03-13\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 163 Tweets from @IndianExpress.\n",
      "Getting data for 2020-03-14\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 148 Tweets from @IndianExpress.\n",
      "Getting data for 2020-03-15\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 136 Tweets from @IndianExpress.\n",
      "Getting data for 2020-03-16\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 179 Tweets from @IndianExpress.\n",
      "Getting data for 2020-03-17\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 234 Tweets from @IndianExpress.\n",
      "Getting data for 2020-03-18\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 192 Tweets from @IndianExpress.\n",
      "Getting data for 2020-03-19\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 220 Tweets from @IndianExpress.\n",
      "Getting data for 2020-03-20\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 182 Tweets from @IndianExpress.\n",
      "Getting data for 2020-03-21\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 141 Tweets from @IndianExpress.\n",
      "Getting data for 2020-03-22\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 102 Tweets from @IndianExpress.\n",
      "Getting data for 2020-03-23\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 149 Tweets from @IndianExpress.\n",
      "Getting data for 2020-03-24\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 215 Tweets from @IndianExpress.\n",
      "Getting data for 2020-03-25\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 235 Tweets from @IndianExpress.\n",
      "Getting data for 2020-03-26\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 219 Tweets from @IndianExpress.\n",
      "Getting data for 2020-03-27\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 157 Tweets from @IndianExpress.\n",
      "Getting data for 2020-03-28\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 139 Tweets from @IndianExpress.\n",
      "Getting data for 2020-03-29\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 162 Tweets from @IndianExpress.\n",
      "Getting data for 2020-03-30\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 171 Tweets from @IndianExpress.\n",
      "Getting data for 2020-03-31\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 234 Tweets from @IndianExpress.\n",
      "Getting data for 2020-04-01\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 229 Tweets from @IndianExpress.\n",
      "Getting data for 2020-04-02\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 256 Tweets from @IndianExpress.\n",
      "Getting data for 2020-04-03\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 154 Tweets from @IndianExpress.\n",
      "Getting data for 2020-04-04\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 174 Tweets from @IndianExpress.\n",
      "Getting data for 2020-04-05\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 138 Tweets from @IndianExpress.\n",
      "Getting data for 2020-04-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 194 Tweets from @IndianExpress.\n",
      "Getting data for 2020-04-07\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 217 Tweets from @IndianExpress.\n",
      "Getting data for 2020-04-08\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 181 Tweets from @IndianExpress.\n",
      "Getting data for 2020-04-09\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 179 Tweets from @IndianExpress.\n",
      "Getting data for 2020-04-10\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 190 Tweets from @IndianExpress.\n",
      "Getting data for 2020-04-11\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 140 Tweets from @IndianExpress.\n",
      "Getting data for 2020-04-12\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 136 Tweets from @IndianExpress.\n",
      "Getting data for 2020-04-13\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 170 Tweets from @IndianExpress.\n",
      "Getting data for 2020-04-14\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 194 Tweets from @IndianExpress.\n",
      "Getting data for 2020-04-15\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 302 Tweets from @IndianExpress.\n",
      "Getting data for 2020-04-16\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 583 Tweets from @IndianExpress.\n",
      "Getting data for 2020-04-17\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 352 Tweets from @IndianExpress.\n",
      "Getting data for 2020-04-18\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 312 Tweets from @IndianExpress.\n",
      "Getting data for 2020-04-19\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 533 Tweets from @IndianExpress.\n",
      "Getting data for 2020-04-20\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 784 Tweets from @IndianExpress.\n",
      "Getting data for 2020-04-21\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 472 Tweets from @IndianExpress.\n",
      "Getting data for 2020-04-22\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 370 Tweets from @IndianExpress.\n",
      "Getting data for 2020-04-23\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 397 Tweets from @IndianExpress.\n",
      "Getting data for 2020-04-24\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 312 Tweets from @IndianExpress.\n",
      "Getting data for 2020-04-25\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 367 Tweets from @IndianExpress.\n",
      "Getting data for 2020-04-26\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 274 Tweets from @IndianExpress.\n",
      "Getting data for 2020-04-27\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 356 Tweets from @IndianExpress.\n",
      "Getting data for 2020-04-28\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 466 Tweets from @IndianExpress.\n",
      "Getting data for 2020-04-29\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 422 Tweets from @IndianExpress.\n",
      "Getting data for 2020-04-30\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 301 Tweets from @IndianExpress.\n",
      "Getting data for 2020-05-01\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 359 Tweets from @IndianExpress.\n",
      "Getting data for 2020-05-02\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 362 Tweets from @IndianExpress.\n",
      "Getting data for 2020-05-03\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 461 Tweets from @IndianExpress.\n",
      "Getting data for 2020-05-04\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 350 Tweets from @IndianExpress.\n",
      "Getting data for 2020-05-05\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 442 Tweets from @IndianExpress.\n",
      "Getting data for 2020-05-06\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 494 Tweets from @IndianExpress.\n",
      "Getting data for 2020-05-07\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 509 Tweets from @IndianExpress.\n",
      "Getting data for 2020-05-08\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 392 Tweets from @IndianExpress.\n",
      "Getting data for 2020-05-09\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 474 Tweets from @IndianExpress.\n",
      "Getting data for 2020-05-10\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 371 Tweets from @IndianExpress.\n",
      "Getting data for 2020-05-11\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 323 Tweets from @IndianExpress.\n",
      "Getting data for 2020-05-12\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 300 Tweets from @IndianExpress.\n",
      "Getting data for 2020-05-13\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 166 Tweets from @IndianExpress.\n",
      "Getting data for 2020-05-14\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 154 Tweets from @IndianExpress.\n",
      "Getting data for 2020-05-15\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 152 Tweets from @IndianExpress.\n",
      "Getting data for 2020-05-16\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 189 Tweets from @IndianExpress.\n",
      "Getting data for 2020-05-17\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 155 Tweets from @IndianExpress.\n",
      "Getting data for 2020-05-18\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 129 Tweets from @IndianExpress.\n",
      "Getting data for 2020-05-19\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 177 Tweets from @IndianExpress.\n",
      "Getting data for 2020-05-20\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 165 Tweets from @IndianExpress.\n",
      "Getting data for 2020-05-21\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 172 Tweets from @IndianExpress.\n",
      "Getting data for 2020-05-22\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 145 Tweets from @IndianExpress.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting data for 2020-05-23\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 151 Tweets from @IndianExpress.\n",
      "Getting data for 2020-05-24\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 110 Tweets from @IndianExpress.\n",
      "Getting data for 2020-05-25\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 134 Tweets from @IndianExpress.\n",
      "Getting data for 2020-05-26\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 176 Tweets from @IndianExpress.\n",
      "Getting data for 2020-05-27\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 159 Tweets from @IndianExpress.\n",
      "Getting data for 2020-05-28\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 153 Tweets from @IndianExpress.\n",
      "Getting data for 2020-05-29\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 135 Tweets from @IndianExpress.\n",
      "Getting data for 2020-05-30\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 134 Tweets from @IndianExpress.\n",
      "time taken: 22.31 mins\n",
      "Directory C:\\Users\\rahul\\News channels data\\NewIndianXpress created\n",
      "Getting data for 2020-01-22\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 72 Tweets from @NewIndianXpress.\n",
      "Getting data for 2020-01-23\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 71 Tweets from @NewIndianXpress.\n",
      "Getting data for 2020-01-24\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 72 Tweets from @NewIndianXpress.\n",
      "Getting data for 2020-01-25\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 70 Tweets from @NewIndianXpress.\n",
      "Getting data for 2020-01-26\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 67 Tweets from @NewIndianXpress.\n",
      "Getting data for 2020-01-27\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 77 Tweets from @NewIndianXpress.\n",
      "Getting data for 2020-01-28\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 59 Tweets from @NewIndianXpress.\n",
      "Getting data for 2020-01-29\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 80 Tweets from @NewIndianXpress.\n",
      "Getting data for 2020-01-30\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 81 Tweets from @NewIndianXpress.\n",
      "Getting data for 2020-01-31\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 78 Tweets from @NewIndianXpress.\n",
      "Getting data for 2020-02-01\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 100 Tweets from @NewIndianXpress.\n",
      "Getting data for 2020-02-02\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 58 Tweets from @NewIndianXpress.\n",
      "Getting data for 2020-02-03\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 69 Tweets from @NewIndianXpress.\n",
      "Getting data for 2020-02-04\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 61 Tweets from @NewIndianXpress.\n",
      "Getting data for 2020-02-05\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 66 Tweets from @NewIndianXpress.\n",
      "Getting data for 2020-02-06\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 73 Tweets from @NewIndianXpress.\n",
      "Getting data for 2020-02-07\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 59 Tweets from @NewIndianXpress.\n",
      "Getting data for 2020-02-08\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 75 Tweets from @NewIndianXpress.\n",
      "Getting data for 2020-02-09\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 61 Tweets from @NewIndianXpress.\n",
      "Getting data for 2020-02-10\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 67 Tweets from @NewIndianXpress.\n",
      "Getting data for 2020-02-11\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 92 Tweets from @NewIndianXpress.\n",
      "Getting data for 2020-02-12\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 59 Tweets from @NewIndianXpress.\n",
      "Getting data for 2020-02-13\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 56 Tweets from @NewIndianXpress.\n",
      "Getting data for 2020-02-14\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 48 Tweets from @NewIndianXpress.\n",
      "Getting data for 2020-02-15\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 51 Tweets from @NewIndianXpress.\n",
      "Getting data for 2020-02-16\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 52 Tweets from @NewIndianXpress.\n",
      "Getting data for 2020-02-17\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 71 Tweets from @NewIndianXpress.\n",
      "Getting data for 2020-02-18\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 54 Tweets from @NewIndianXpress.\n",
      "Getting data for 2020-02-19\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 72 Tweets from @NewIndianXpress.\n",
      "Getting data for 2020-02-20\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 61 Tweets from @NewIndianXpress.\n",
      "Getting data for 2020-02-21\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 70 Tweets from @NewIndianXpress.\n",
      "Getting data for 2020-02-22\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 73 Tweets from @NewIndianXpress.\n",
      "Getting data for 2020-02-23\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 80 Tweets from @NewIndianXpress.\n",
      "Getting data for 2020-02-24\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 95 Tweets from @NewIndianXpress.\n",
      "Getting data for 2020-02-25\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 90 Tweets from @NewIndianXpress.\n",
      "Getting data for 2020-02-26\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 96 Tweets from @NewIndianXpress.\n",
      "Getting data for 2020-02-27\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 98 Tweets from @NewIndianXpress.\n",
      "Getting data for 2020-02-28\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 96 Tweets from @NewIndianXpress.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting data for 2020-02-29\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 77 Tweets from @NewIndianXpress.\n",
      "Getting data for 2020-03-01\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 74 Tweets from @NewIndianXpress.\n",
      "Getting data for 2020-03-02\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 96 Tweets from @NewIndianXpress.\n",
      "Getting data for 2020-03-03\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 76 Tweets from @NewIndianXpress.\n",
      "Getting data for 2020-03-04\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 83 Tweets from @NewIndianXpress.\n",
      "Getting data for 2020-03-05\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 100 Tweets from @NewIndianXpress.\n",
      "Getting data for 2020-03-06\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 82 Tweets from @NewIndianXpress.\n",
      "Getting data for 2020-03-07\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 77 Tweets from @NewIndianXpress.\n",
      "Getting data for 2020-03-08\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 78 Tweets from @NewIndianXpress.\n",
      "Getting data for 2020-03-09\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 89 Tweets from @NewIndianXpress.\n",
      "Getting data for 2020-03-10\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 75 Tweets from @NewIndianXpress.\n",
      "Getting data for 2020-03-11\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 93 Tweets from @NewIndianXpress.\n",
      "Getting data for 2020-03-12\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 75 Tweets from @NewIndianXpress.\n",
      "Getting data for 2020-03-13\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 83 Tweets from @NewIndianXpress.\n",
      "Getting data for 2020-03-14\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 75 Tweets from @NewIndianXpress.\n",
      "Getting data for 2020-03-15\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 77 Tweets from @NewIndianXpress.\n",
      "Getting data for 2020-03-16\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 86 Tweets from @NewIndianXpress.\n",
      "Getting data for 2020-03-17\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 83 Tweets from @NewIndianXpress.\n",
      "Getting data for 2020-03-18\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 83 Tweets from @NewIndianXpress.\n",
      "Getting data for 2020-03-19\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 107 Tweets from @NewIndianXpress.\n",
      "Getting data for 2020-03-20\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 83 Tweets from @NewIndianXpress.\n",
      "Getting data for 2020-03-21\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 82 Tweets from @NewIndianXpress.\n",
      "Getting data for 2020-03-22\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 94 Tweets from @NewIndianXpress.\n",
      "Getting data for 2020-03-23\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 87 Tweets from @NewIndianXpress.\n",
      "Getting data for 2020-03-24\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 96 Tweets from @NewIndianXpress.\n",
      "Getting data for 2020-03-25\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 80 Tweets from @NewIndianXpress.\n",
      "Getting data for 2020-03-26\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 108 Tweets from @NewIndianXpress.\n",
      "Getting data for 2020-03-27\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 106 Tweets from @NewIndianXpress.\n",
      "Getting data for 2020-03-28\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 103 Tweets from @NewIndianXpress.\n",
      "Getting data for 2020-03-29\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 104 Tweets from @NewIndianXpress.\n",
      "Getting data for 2020-03-30\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 113 Tweets from @NewIndianXpress.\n",
      "Getting data for 2020-03-31\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 100 Tweets from @NewIndianXpress.\n",
      "Getting data for 2020-04-01\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 102 Tweets from @NewIndianXpress.\n",
      "Getting data for 2020-04-02\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 117 Tweets from @NewIndianXpress.\n",
      "Getting data for 2020-04-03\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 120 Tweets from @NewIndianXpress.\n",
      "Getting data for 2020-04-04\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 116 Tweets from @NewIndianXpress.\n",
      "Getting data for 2020-04-05\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 129 Tweets from @NewIndianXpress.\n",
      "Getting data for 2020-04-06\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 123 Tweets from @NewIndianXpress.\n",
      "Getting data for 2020-04-07\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 115 Tweets from @NewIndianXpress.\n",
      "Getting data for 2020-04-08\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 115 Tweets from @NewIndianXpress.\n",
      "Getting data for 2020-04-09\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 116 Tweets from @NewIndianXpress.\n",
      "Getting data for 2020-04-10\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 104 Tweets from @NewIndianXpress.\n",
      "Getting data for 2020-04-11\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 104 Tweets from @NewIndianXpress.\n",
      "Getting data for 2020-04-12\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 112 Tweets from @NewIndianXpress.\n",
      "Getting data for 2020-04-13\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 122 Tweets from @NewIndianXpress.\n",
      "Getting data for 2020-04-14\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 112 Tweets from @NewIndianXpress.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting data for 2020-04-15\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 110 Tweets from @NewIndianXpress.\n",
      "Getting data for 2020-04-16\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 115 Tweets from @NewIndianXpress.\n",
      "Getting data for 2020-04-17\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 102 Tweets from @NewIndianXpress.\n",
      "Getting data for 2020-04-18\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 104 Tweets from @NewIndianXpress.\n",
      "Getting data for 2020-04-19\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 100 Tweets from @NewIndianXpress.\n",
      "Getting data for 2020-04-20\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 96 Tweets from @NewIndianXpress.\n",
      "Getting data for 2020-04-21\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 112 Tweets from @NewIndianXpress.\n",
      "Getting data for 2020-04-22\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 100 Tweets from @NewIndianXpress.\n",
      "Getting data for 2020-04-23\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 106 Tweets from @NewIndianXpress.\n",
      "Getting data for 2020-04-24\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 101 Tweets from @NewIndianXpress.\n",
      "Getting data for 2020-04-25\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 100 Tweets from @NewIndianXpress.\n",
      "Getting data for 2020-04-26\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 104 Tweets from @NewIndianXpress.\n",
      "Getting data for 2020-04-27\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 107 Tweets from @NewIndianXpress.\n",
      "Getting data for 2020-04-28\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 106 Tweets from @NewIndianXpress.\n",
      "Getting data for 2020-04-29\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 94 Tweets from @NewIndianXpress.\n",
      "Getting data for 2020-04-30\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 101 Tweets from @NewIndianXpress.\n",
      "Getting data for 2020-05-01\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 101 Tweets from @NewIndianXpress.\n",
      "Getting data for 2020-05-02\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 98 Tweets from @NewIndianXpress.\n",
      "Getting data for 2020-05-03\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 100 Tweets from @NewIndianXpress.\n",
      "Getting data for 2020-05-04\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 100 Tweets from @NewIndianXpress.\n",
      "Getting data for 2020-05-05\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 95 Tweets from @NewIndianXpress.\n",
      "Getting data for 2020-05-06\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 94 Tweets from @NewIndianXpress.\n",
      "Getting data for 2020-05-07\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 119 Tweets from @NewIndianXpress.\n",
      "Getting data for 2020-05-08\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 90 Tweets from @NewIndianXpress.\n",
      "Getting data for 2020-05-09\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 94 Tweets from @NewIndianXpress.\n",
      "Getting data for 2020-05-10\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 91 Tweets from @NewIndianXpress.\n",
      "Getting data for 2020-05-11\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 106 Tweets from @NewIndianXpress.\n",
      "Getting data for 2020-05-12\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 113 Tweets from @NewIndianXpress.\n",
      "Getting data for 2020-05-13\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 90 Tweets from @NewIndianXpress.\n",
      "Getting data for 2020-05-14\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 106 Tweets from @NewIndianXpress.\n",
      "Getting data for 2020-05-15\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 111 Tweets from @NewIndianXpress.\n",
      "Getting data for 2020-05-16\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 110 Tweets from @NewIndianXpress.\n",
      "Getting data for 2020-05-17\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 90 Tweets from @NewIndianXpress.\n",
      "Getting data for 2020-05-18\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 95 Tweets from @NewIndianXpress.\n",
      "Getting data for 2020-05-19\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 104 Tweets from @NewIndianXpress.\n",
      "Getting data for 2020-05-20\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 107 Tweets from @NewIndianXpress.\n",
      "Getting data for 2020-05-21\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 113 Tweets from @NewIndianXpress.\n",
      "Getting data for 2020-05-22\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 103 Tweets from @NewIndianXpress.\n",
      "Getting data for 2020-05-23\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 95 Tweets from @NewIndianXpress.\n",
      "Getting data for 2020-05-24\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 99 Tweets from @NewIndianXpress.\n",
      "Getting data for 2020-05-25\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 106 Tweets from @NewIndianXpress.\n",
      "Getting data for 2020-05-26\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 109 Tweets from @NewIndianXpress.\n",
      "Getting data for 2020-05-27\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 107 Tweets from @NewIndianXpress.\n",
      "Getting data for 2020-05-28\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 124 Tweets from @NewIndianXpress.\n",
      "Getting data for 2020-05-29\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 110 Tweets from @NewIndianXpress.\n",
      "Getting data for 2020-05-30\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 91 Tweets from @NewIndianXpress.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken: 16.84 mins\n",
      "Directory C:\\Users\\rahul\\News channels data\\ttindia created\n",
      "Getting data for 2020-01-22\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 56 Tweets from @ttindia.\n",
      "Getting data for 2020-01-23\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 51 Tweets from @ttindia.\n",
      "Getting data for 2020-01-24\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 38 Tweets from @ttindia.\n",
      "Getting data for 2020-01-25\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 38 Tweets from @ttindia.\n",
      "Getting data for 2020-01-26\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 47 Tweets from @ttindia.\n",
      "Getting data for 2020-01-27\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 41 Tweets from @ttindia.\n",
      "Getting data for 2020-01-28\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 56 Tweets from @ttindia.\n",
      "Getting data for 2020-01-29\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 51 Tweets from @ttindia.\n",
      "Getting data for 2020-01-30\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 3 Tweets from @ttindia.\n",
      "Getting data for 2020-01-31\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 61 Tweets from @ttindia.\n",
      "Getting data for 2020-02-01\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 88 Tweets from @ttindia.\n",
      "Getting data for 2020-02-02\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 47 Tweets from @ttindia.\n",
      "Getting data for 2020-02-03\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 39 Tweets from @ttindia.\n",
      "Getting data for 2020-02-04\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 49 Tweets from @ttindia.\n",
      "Getting data for 2020-02-05\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 50 Tweets from @ttindia.\n",
      "Getting data for 2020-02-06\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 42 Tweets from @ttindia.\n",
      "Getting data for 2020-02-07\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 48 Tweets from @ttindia.\n",
      "Getting data for 2020-02-08\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 68 Tweets from @ttindia.\n",
      "Getting data for 2020-02-09\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 25 Tweets from @ttindia.\n",
      "Getting data for 2020-02-10\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 43 Tweets from @ttindia.\n",
      "Getting data for 2020-02-11\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 84 Tweets from @ttindia.\n",
      "Getting data for 2020-02-12\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 44 Tweets from @ttindia.\n",
      "Getting data for 2020-02-13\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 32 Tweets from @ttindia.\n",
      "Getting data for 2020-02-14\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 45 Tweets from @ttindia.\n",
      "Getting data for 2020-02-15\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 35 Tweets from @ttindia.\n",
      "Getting data for 2020-02-16\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 38 Tweets from @ttindia.\n",
      "Getting data for 2020-02-17\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 36 Tweets from @ttindia.\n",
      "Getting data for 2020-02-18\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 41 Tweets from @ttindia.\n",
      "Getting data for 2020-02-19\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 38 Tweets from @ttindia.\n",
      "Getting data for 2020-02-20\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 41 Tweets from @ttindia.\n",
      "Getting data for 2020-02-21\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 43 Tweets from @ttindia.\n",
      "Getting data for 2020-02-22\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 2 Tweets from @ttindia.\n",
      "Getting data for 2020-02-23\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 45 Tweets from @ttindia.\n",
      "Getting data for 2020-02-24\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 38 Tweets from @ttindia.\n",
      "Getting data for 2020-02-25\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 44 Tweets from @ttindia.\n",
      "Getting data for 2020-02-26\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 40 Tweets from @ttindia.\n",
      "Getting data for 2020-02-27\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 45 Tweets from @ttindia.\n",
      "Getting data for 2020-02-28\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 46 Tweets from @ttindia.\n",
      "Getting data for 2020-02-29\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 43 Tweets from @ttindia.\n",
      "Getting data for 2020-03-01\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 32 Tweets from @ttindia.\n",
      "Getting data for 2020-03-02\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 42 Tweets from @ttindia.\n",
      "Getting data for 2020-03-03\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 38 Tweets from @ttindia.\n",
      "Getting data for 2020-03-04\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 42 Tweets from @ttindia.\n",
      "Getting data for 2020-03-05\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 39 Tweets from @ttindia.\n",
      "Getting data for 2020-03-06\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 33 Tweets from @ttindia.\n",
      "Getting data for 2020-03-07\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 28 Tweets from @ttindia.\n",
      "Getting data for 2020-03-08\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 46 Tweets from @ttindia.\n",
      "Getting data for 2020-03-09\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 37 Tweets from @ttindia.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting data for 2020-03-10\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 33 Tweets from @ttindia.\n",
      "Getting data for 2020-03-11\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 37 Tweets from @ttindia.\n",
      "Getting data for 2020-03-12\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 42 Tweets from @ttindia.\n",
      "Getting data for 2020-03-13\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 31 Tweets from @ttindia.\n",
      "Getting data for 2020-03-14\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 44 Tweets from @ttindia.\n",
      "Getting data for 2020-03-15\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 34 Tweets from @ttindia.\n",
      "Getting data for 2020-03-16\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 36 Tweets from @ttindia.\n",
      "Getting data for 2020-03-17\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 39 Tweets from @ttindia.\n",
      "Getting data for 2020-03-18\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 30 Tweets from @ttindia.\n",
      "Getting data for 2020-03-19\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 33 Tweets from @ttindia.\n",
      "Getting data for 2020-03-20\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 28 Tweets from @ttindia.\n",
      "Getting data for 2020-03-21\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 32 Tweets from @ttindia.\n",
      "Getting data for 2020-03-22\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 30 Tweets from @ttindia.\n",
      "Getting data for 2020-03-23\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 29 Tweets from @ttindia.\n",
      "Getting data for 2020-03-24\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 38 Tweets from @ttindia.\n",
      "Getting data for 2020-03-25\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 33 Tweets from @ttindia.\n",
      "Getting data for 2020-03-26\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 28 Tweets from @ttindia.\n",
      "Getting data for 2020-03-27\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 26 Tweets from @ttindia.\n",
      "Getting data for 2020-03-28\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 20 Tweets from @ttindia.\n",
      "Getting data for 2020-03-29\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 40 Tweets from @ttindia.\n",
      "Getting data for 2020-03-30\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 30 Tweets from @ttindia.\n",
      "Getting data for 2020-03-31\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 30 Tweets from @ttindia.\n",
      "Getting data for 2020-04-01\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 33 Tweets from @ttindia.\n",
      "Getting data for 2020-04-02\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 25 Tweets from @ttindia.\n",
      "Getting data for 2020-04-03\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 28 Tweets from @ttindia.\n",
      "Getting data for 2020-04-04\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 11 Tweets from @ttindia.\n",
      "Getting data for 2020-04-05\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 27 Tweets from @ttindia.\n",
      "Getting data for 2020-04-06\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 23 Tweets from @ttindia.\n",
      "Getting data for 2020-04-07\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 28 Tweets from @ttindia.\n",
      "Getting data for 2020-04-08\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 23 Tweets from @ttindia.\n",
      "Getting data for 2020-04-09\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 22 Tweets from @ttindia.\n",
      "Getting data for 2020-04-10\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 23 Tweets from @ttindia.\n",
      "Getting data for 2020-04-11\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 28 Tweets from @ttindia.\n",
      "Getting data for 2020-04-12\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 12 Tweets from @ttindia.\n",
      "Getting data for 2020-04-13\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 23 Tweets from @ttindia.\n",
      "Getting data for 2020-04-14\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 23 Tweets from @ttindia.\n",
      "Getting data for 2020-04-15\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 26 Tweets from @ttindia.\n",
      "Getting data for 2020-04-16\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 21 Tweets from @ttindia.\n",
      "Getting data for 2020-04-17\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 21 Tweets from @ttindia.\n",
      "Getting data for 2020-04-18\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 21 Tweets from @ttindia.\n",
      "Getting data for 2020-04-19\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 25 Tweets from @ttindia.\n",
      "Getting data for 2020-04-20\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 23 Tweets from @ttindia.\n",
      "Getting data for 2020-04-21\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 21 Tweets from @ttindia.\n",
      "Getting data for 2020-04-22\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 23 Tweets from @ttindia.\n",
      "Getting data for 2020-04-23\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 23 Tweets from @ttindia.\n",
      "Getting data for 2020-04-24\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 24 Tweets from @ttindia.\n",
      "Getting data for 2020-04-25\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 21 Tweets from @ttindia.\n",
      "Getting data for 2020-04-26\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 25 Tweets from @ttindia.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting data for 2020-04-27\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 23 Tweets from @ttindia.\n",
      "Getting data for 2020-04-28\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 25 Tweets from @ttindia.\n",
      "Getting data for 2020-04-29\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 23 Tweets from @ttindia.\n",
      "Getting data for 2020-04-30\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 27 Tweets from @ttindia.\n",
      "Getting data for 2020-05-01\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 28 Tweets from @ttindia.\n",
      "Getting data for 2020-05-02\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 22 Tweets from @ttindia.\n",
      "Getting data for 2020-05-03\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 27 Tweets from @ttindia.\n",
      "Getting data for 2020-05-04\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 24 Tweets from @ttindia.\n",
      "Getting data for 2020-05-05\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 20 Tweets from @ttindia.\n",
      "Getting data for 2020-05-06\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 26 Tweets from @ttindia.\n",
      "Getting data for 2020-05-07\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 28 Tweets from @ttindia.\n",
      "Getting data for 2020-05-08\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 29 Tweets from @ttindia.\n",
      "Getting data for 2020-05-09\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 24 Tweets from @ttindia.\n",
      "Getting data for 2020-05-10\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 26 Tweets from @ttindia.\n",
      "Getting data for 2020-05-11\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 22 Tweets from @ttindia.\n",
      "Getting data for 2020-05-12\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 47 Tweets from @ttindia.\n",
      "Getting data for 2020-05-13\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 33 Tweets from @ttindia.\n",
      "Getting data for 2020-05-14\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 34 Tweets from @ttindia.\n",
      "Getting data for 2020-05-15\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 33 Tweets from @ttindia.\n",
      "Getting data for 2020-05-16\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 34 Tweets from @ttindia.\n",
      "Getting data for 2020-05-17\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 44 Tweets from @ttindia.\n",
      "Getting data for 2020-05-18\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 22 Tweets from @ttindia.\n",
      "Getting data for 2020-05-19\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 21 Tweets from @ttindia.\n",
      "Getting data for 2020-05-20\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 27 Tweets from @ttindia.\n",
      "Getting data for 2020-05-21\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 17 Tweets from @ttindia.\n",
      "Getting data for 2020-05-22\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 21 Tweets from @ttindia.\n",
      "Getting data for 2020-05-23\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 17 Tweets from @ttindia.\n",
      "Getting data for 2020-05-24\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 28 Tweets from @ttindia.\n",
      "Getting data for 2020-05-25\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 19 Tweets from @ttindia.\n",
      "Getting data for 2020-05-26\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 24 Tweets from @ttindia.\n",
      "Getting data for 2020-05-27\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 25 Tweets from @ttindia.\n",
      "Getting data for 2020-05-28\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 24 Tweets from @ttindia.\n",
      "Getting data for 2020-05-29\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 23 Tweets from @ttindia.\n",
      "Getting data for 2020-05-30\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 21 Tweets from @ttindia.\n",
      "time taken: 14.09 mins\n",
      "Directory C:\\Users\\rahul\\News channels data\\thetribunechd created\n",
      "Getting data for 2020-01-22\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 127 Tweets from @thetribunechd.\n",
      "Getting data for 2020-01-23\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 118 Tweets from @thetribunechd.\n",
      "Getting data for 2020-01-24\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 110 Tweets from @thetribunechd.\n",
      "Getting data for 2020-01-25\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 107 Tweets from @thetribunechd.\n",
      "Getting data for 2020-01-26\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 137 Tweets from @thetribunechd.\n",
      "Getting data for 2020-01-27\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 55 Tweets from @thetribunechd.\n",
      "Getting data for 2020-01-28\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 131 Tweets from @thetribunechd.\n",
      "Getting data for 2020-01-29\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 120 Tweets from @thetribunechd.\n",
      "Getting data for 2020-01-30\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 99 Tweets from @thetribunechd.\n",
      "Getting data for 2020-01-31\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 92 Tweets from @thetribunechd.\n",
      "Getting data for 2020-02-01\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 231 Tweets from @thetribunechd.\n",
      "Getting data for 2020-02-02\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 96 Tweets from @thetribunechd.\n",
      "Getting data for 2020-02-03\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 104 Tweets from @thetribunechd.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting data for 2020-02-04\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 75 Tweets from @thetribunechd.\n",
      "Getting data for 2020-02-05\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 150 Tweets from @thetribunechd.\n",
      "Getting data for 2020-02-06\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 153 Tweets from @thetribunechd.\n",
      "Getting data for 2020-02-07\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 130 Tweets from @thetribunechd.\n",
      "Getting data for 2020-02-08\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 134 Tweets from @thetribunechd.\n",
      "Getting data for 2020-02-09\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 95 Tweets from @thetribunechd.\n",
      "Getting data for 2020-02-10\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 148 Tweets from @thetribunechd.\n",
      "Getting data for 2020-02-11\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 127 Tweets from @thetribunechd.\n",
      "Getting data for 2020-02-12\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 126 Tweets from @thetribunechd.\n",
      "Getting data for 2020-02-13\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 117 Tweets from @thetribunechd.\n",
      "Getting data for 2020-02-14\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 125 Tweets from @thetribunechd.\n",
      "Getting data for 2020-02-15\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 97 Tweets from @thetribunechd.\n",
      "Getting data for 2020-02-16\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 96 Tweets from @thetribunechd.\n",
      "Getting data for 2020-02-17\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 115 Tweets from @thetribunechd.\n",
      "Getting data for 2020-02-18\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 116 Tweets from @thetribunechd.\n",
      "Getting data for 2020-02-19\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 100 Tweets from @thetribunechd.\n",
      "Getting data for 2020-02-20\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 112 Tweets from @thetribunechd.\n",
      "Getting data for 2020-02-21\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 103 Tweets from @thetribunechd.\n",
      "Getting data for 2020-02-22\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 104 Tweets from @thetribunechd.\n",
      "Getting data for 2020-02-23\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 85 Tweets from @thetribunechd.\n",
      "Getting data for 2020-02-24\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 150 Tweets from @thetribunechd.\n",
      "Getting data for 2020-02-25\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 143 Tweets from @thetribunechd.\n",
      "Getting data for 2020-02-26\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 103 Tweets from @thetribunechd.\n",
      "Getting data for 2020-02-27\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 105 Tweets from @thetribunechd.\n",
      "Getting data for 2020-02-28\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 196 Tweets from @thetribunechd.\n",
      "Getting data for 2020-02-29\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 102 Tweets from @thetribunechd.\n",
      "Getting data for 2020-03-01\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 77 Tweets from @thetribunechd.\n",
      "Getting data for 2020-03-02\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 102 Tweets from @thetribunechd.\n",
      "Getting data for 2020-03-03\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 104 Tweets from @thetribunechd.\n",
      "Getting data for 2020-03-04\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 133 Tweets from @thetribunechd.\n",
      "Getting data for 2020-03-05\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 109 Tweets from @thetribunechd.\n",
      "Getting data for 2020-03-06\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 127 Tweets from @thetribunechd.\n",
      "Getting data for 2020-03-07\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 116 Tweets from @thetribunechd.\n",
      "Getting data for 2020-03-08\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 90 Tweets from @thetribunechd.\n",
      "Getting data for 2020-03-09\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 112 Tweets from @thetribunechd.\n",
      "Getting data for 2020-03-10\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 72 Tweets from @thetribunechd.\n",
      "Getting data for 2020-03-11\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 72 Tweets from @thetribunechd.\n",
      "Getting data for 2020-03-12\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 142 Tweets from @thetribunechd.\n",
      "Getting data for 2020-03-13\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 144 Tweets from @thetribunechd.\n",
      "Getting data for 2020-03-14\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 135 Tweets from @thetribunechd.\n",
      "Getting data for 2020-03-15\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 82 Tweets from @thetribunechd.\n",
      "Getting data for 2020-03-16\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 123 Tweets from @thetribunechd.\n",
      "Getting data for 2020-03-17\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 134 Tweets from @thetribunechd.\n",
      "Getting data for 2020-03-18\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 142 Tweets from @thetribunechd.\n",
      "Getting data for 2020-03-19\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 143 Tweets from @thetribunechd.\n",
      "Getting data for 2020-03-20\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 127 Tweets from @thetribunechd.\n",
      "Getting data for 2020-03-21\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 139 Tweets from @thetribunechd.\n",
      "Getting data for 2020-03-22\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 98 Tweets from @thetribunechd.\n",
      "Getting data for 2020-03-23\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 120 Tweets from @thetribunechd.\n",
      "Getting data for 2020-03-24\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 132 Tweets from @thetribunechd.\n",
      "Getting data for 2020-03-25\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 113 Tweets from @thetribunechd.\n",
      "Getting data for 2020-03-26\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 125 Tweets from @thetribunechd.\n",
      "Getting data for 2020-03-27\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 133 Tweets from @thetribunechd.\n",
      "Getting data for 2020-03-28\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 128 Tweets from @thetribunechd.\n",
      "Getting data for 2020-03-29\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 176 Tweets from @thetribunechd.\n",
      "Getting data for 2020-03-30\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 152 Tweets from @thetribunechd.\n",
      "Getting data for 2020-03-31\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 129 Tweets from @thetribunechd.\n",
      "Getting data for 2020-04-01\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 114 Tweets from @thetribunechd.\n",
      "Getting data for 2020-04-02\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 122 Tweets from @thetribunechd.\n",
      "Getting data for 2020-04-03\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 124 Tweets from @thetribunechd.\n",
      "Getting data for 2020-04-04\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 137 Tweets from @thetribunechd.\n",
      "Getting data for 2020-04-05\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 109 Tweets from @thetribunechd.\n",
      "Getting data for 2020-04-06\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 126 Tweets from @thetribunechd.\n",
      "Getting data for 2020-04-07\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 127 Tweets from @thetribunechd.\n",
      "Getting data for 2020-04-08\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 126 Tweets from @thetribunechd.\n",
      "Getting data for 2020-04-09\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 114 Tweets from @thetribunechd.\n",
      "Getting data for 2020-04-10\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 138 Tweets from @thetribunechd.\n",
      "Getting data for 2020-04-11\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 112 Tweets from @thetribunechd.\n",
      "Getting data for 2020-04-12\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 122 Tweets from @thetribunechd.\n",
      "Getting data for 2020-04-13\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 71 Tweets from @thetribunechd.\n",
      "Getting data for 2020-04-14\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 154 Tweets from @thetribunechd.\n",
      "Getting data for 2020-04-15\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 105 Tweets from @thetribunechd.\n",
      "Getting data for 2020-04-16\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 111 Tweets from @thetribunechd.\n",
      "Getting data for 2020-04-17\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 137 Tweets from @thetribunechd.\n",
      "Getting data for 2020-04-18\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 115 Tweets from @thetribunechd.\n",
      "Getting data for 2020-04-19\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 114 Tweets from @thetribunechd.\n",
      "Getting data for 2020-04-20\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 73 Tweets from @thetribunechd.\n",
      "Getting data for 2020-04-21\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 108 Tweets from @thetribunechd.\n",
      "Getting data for 2020-04-22\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 100 Tweets from @thetribunechd.\n",
      "Getting data for 2020-04-23\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 142 Tweets from @thetribunechd.\n",
      "Getting data for 2020-04-24\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 138 Tweets from @thetribunechd.\n",
      "Getting data for 2020-04-25\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 144 Tweets from @thetribunechd.\n",
      "Getting data for 2020-04-26\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 128 Tweets from @thetribunechd.\n",
      "Getting data for 2020-04-27\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 128 Tweets from @thetribunechd.\n",
      "Getting data for 2020-04-28\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 139 Tweets from @thetribunechd.\n",
      "Getting data for 2020-04-29\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 128 Tweets from @thetribunechd.\n",
      "Getting data for 2020-04-30\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 132 Tweets from @thetribunechd.\n",
      "Getting data for 2020-05-01\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 141 Tweets from @thetribunechd.\n",
      "Getting data for 2020-05-02\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 114 Tweets from @thetribunechd.\n",
      "Getting data for 2020-05-03\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 102 Tweets from @thetribunechd.\n",
      "Getting data for 2020-05-04\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 132 Tweets from @thetribunechd.\n",
      "Getting data for 2020-05-05\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 133 Tweets from @thetribunechd.\n",
      "Getting data for 2020-05-06\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 121 Tweets from @thetribunechd.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting data for 2020-05-07\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 118 Tweets from @thetribunechd.\n",
      "Getting data for 2020-05-08\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 113 Tweets from @thetribunechd.\n",
      "Getting data for 2020-05-09\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 111 Tweets from @thetribunechd.\n",
      "Getting data for 2020-05-10\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 114 Tweets from @thetribunechd.\n",
      "Getting data for 2020-05-11\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 114 Tweets from @thetribunechd.\n",
      "Getting data for 2020-05-12\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 137 Tweets from @thetribunechd.\n",
      "Getting data for 2020-05-13\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 138 Tweets from @thetribunechd.\n",
      "Getting data for 2020-05-14\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 137 Tweets from @thetribunechd.\n",
      "Getting data for 2020-05-15\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 128 Tweets from @thetribunechd.\n",
      "Getting data for 2020-05-16\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 104 Tweets from @thetribunechd.\n",
      "Getting data for 2020-05-17\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 115 Tweets from @thetribunechd.\n",
      "Getting data for 2020-05-18\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 156 Tweets from @thetribunechd.\n",
      "Getting data for 2020-05-19\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 132 Tweets from @thetribunechd.\n",
      "Getting data for 2020-05-20\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 150 Tweets from @thetribunechd.\n",
      "Getting data for 2020-05-21\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 129 Tweets from @thetribunechd.\n",
      "Getting data for 2020-05-22\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 145 Tweets from @thetribunechd.\n",
      "Getting data for 2020-05-23\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 124 Tweets from @thetribunechd.\n",
      "Getting data for 2020-05-24\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 95 Tweets from @thetribunechd.\n",
      "Getting data for 2020-05-25\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 126 Tweets from @thetribunechd.\n",
      "Getting data for 2020-05-26\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 131 Tweets from @thetribunechd.\n",
      "Getting data for 2020-05-27\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 107 Tweets from @thetribunechd.\n",
      "Getting data for 2020-05-28\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 132 Tweets from @thetribunechd.\n",
      "Getting data for 2020-05-29\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 137 Tweets from @thetribunechd.\n",
      "Getting data for 2020-05-30\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 99 Tweets from @thetribunechd.\n",
      "time taken: 17.81 mins\n",
      "time taken: 564.54 mins\n"
     ]
    }
   ],
   "source": [
    "t = time.time()\n",
    "news_channels = [\"indiatoday\", \"ndtv\", \"newsx\", \"TIMESNOW\", \"republic\", \"CNBCTV18news\", \"CNNnews18\", \\\n",
    "                 \"OpIndia_com\", \"toi\", \"AltNews\", \"TheNewIndian_in\", \"firstpost\", \"fpjindia\", \"newslaundry\", \\\n",
    "                 \"TheQuint\", \"ScoopWhoop\", \"scroll_in\", \"SwarajyaMag\", \"ThePrintIndia\", \"thewire_in\", \\\n",
    "                 \"MirrorNow\", \"the_hindu\", \"DeccanChronicle\", \"DeccanHerald\", \"mid_day\", \"HindustanTimes\", \\\n",
    "                 \"IndianExpress\", \"NewIndianXpress\", \"ttindia\", \"thetribunechd\"]\n",
    "for channel in news_channels:\n",
    "    t_1 = time.time()\n",
    "    my_scraper(\"2020-01-22\",\"2020-05-30\", channel)\n",
    "    print(\"time taken: {} mins\".format(round((time.time() - t_1)/60, 2)))\n",
    "print(\"time taken: {} mins\".format(round((time.time() - t)/60, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"C:\\\\Users\\\\rahul\\\\Complete thesis data\\\\august cleaned data\\\\august cleaned Delhi\\\\cleaned 2020-04-01.csv.pkl\", \"rb\") as f:\n",
    "    delhi_1st = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"C:\\\\Users\\\\rahul\\\\Complete thesis data\\\\august cleaned data\\\\august cleaned Delhi\\\\Delhi covid_tweet_ids.pkl\", \"rb\") as f:\n",
    "    delhi_covid_tweets = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "delhi_1st = pd.read_csv(\"C:\\\\Users\\\\rahul\\\\Complete thesis data\\\\Raw data\\\\Delhi\\\\2020-04-01.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "delhi_covid = delhi_1st.where(delhi_1st[\"id\"].isin(delhi_covid_tweets)).dropna(subset = [\"id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "delhi_covid.drop_duplicates(subset = [\"id\"], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2371, 36)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delhi_covid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "delhi_covid = pd.concat([delhi_covid, test_en], axis = 0, ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "delhi_covid.drop_duplicates(subset = [\"id\"], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2652, 36)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delhi_covid.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:Thesis]",
   "language": "python",
   "name": "conda-env-Thesis-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
