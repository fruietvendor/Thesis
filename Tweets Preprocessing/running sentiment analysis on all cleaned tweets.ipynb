{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a92aa71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import csv\n",
    "from time import time\n",
    "import pickle\n",
    "import logging\n",
    "logging.basicConfig(format=\"%(levelname)s - %(asctime)s: %(message)s\", datefmt= '%H:%M:%S', level=logging.INFO)\n",
    "from emot.emo_unicode import UNICODE_EMOJI, EMOTICONS_EMO\n",
    "from gensim.models import Word2Vec\n",
    "import multiprocessing\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0dd47b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading the trained classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e9ed2a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "cls = pickle.load(open(\"classifier.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0025fd86",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading the word2vec model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3eff3954",
   "metadata": {},
   "outputs": [],
   "source": [
    "wv_model = pickle.load(open(\"wv_model.pkl\", \"rb\"))\n",
    "wv = wv_model.wv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "51233714",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading the emoji vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "df0193f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = pickle.load(open(\"emoji vectorizer.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0fd87692",
   "metadata": {},
   "outputs": [],
   "source": [
    "#predicting sentiment for all the scraped tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5e8c222e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a class that accepts the state_name, file_name, unique_ids of the state, and the classifier\n",
    "#it loads every file, creates the emoji matrix for the dataframe, uses word2vec model to vectorize all the \n",
    "#tweets in the df, then predicts and stores the sentiment of every tweet under the \"polarity_new\" column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8d37263a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class sentiment_analyzer:\n",
    "    \n",
    "    def __init__(self, _folder, _file, ids_list,_classifier):\n",
    "        self.folder = _folder\n",
    "        self.file = _file\n",
    "        self.filepath = os.path.join(os.path.abspath(self.folder), self.file)\n",
    "        self.pipe = _classifier\n",
    "        self.ids_list = ids_list\n",
    "        self.df = self.load_df()\n",
    "        self.emojis_array = self.emoji_vectorize()\n",
    "        self.corpus = self.vectorize_data()\n",
    "        self.predicted = self.predict_score()\n",
    "        self.output = self.save_output()\n",
    "        \n",
    "    #load the particular file as a dataframe    \n",
    "    def load_df(self):\n",
    "        with open(self.filepath, \"rb\") as f:\n",
    "            _df = pickle.load(f)\n",
    "        _df = _df.where(_df[\"id\"].isin(self.ids_list)).dropna(subset = [\"id\"])\n",
    "        _df.reset_index(drop = True, inplace = True)\n",
    "        return _df\n",
    "    \n",
    "    #load the emoji vectorizer trained before and create a (,162) vector representating the emojis in the tweet\n",
    "    #for every tweet to create a (df.shape[0], 162) matrix\n",
    "    def emoji_vectorize(self):\n",
    "        _emojis = vectorizer.transform(self.df[\"emojis\"].values)\n",
    "        return _emojis.toarray()\n",
    "    \n",
    "    #create a (0, 300) matrix for the day. split the tweet into tokens and create a (300,0) matrix for the tweet. \n",
    "    #if the token is in the word2vec model vocab, add the (300,) vector into the matrix, else add a (300,) 0-vector\n",
    "    #average the matrix across the y-axis to get a (300,) vector representating the tweet.\n",
    "    #add this (,300) vector to the day matrix. to this matrix, add the (df.shape[0], 162) matrix and the \n",
    "    #(df.shape[0], 1) \"caps share\" vector to create final matrix for the day\n",
    "    def vectorize_data(self):\n",
    "        corpus_mat = np.empty((0, 300))\n",
    "        for _sentence in self.df[\"cleaned_tweet\"]:\n",
    "            sentence_mat = np.empty((300, 0))\n",
    "            for _word in _sentence.split():\n",
    "                if _word in wv.key_to_index.keys():\n",
    "                    sentence_mat = np.column_stack([sentence_mat, wv[_word]])\n",
    "                else:\n",
    "                    sentence_mat = np.column_stack([sentence_mat, np.zeros(300)])\n",
    "            sentence_vec = np.mean(sentence_mat, axis = 1)\n",
    "            corpus_mat = np.vstack([corpus_mat, sentence_vec])\n",
    "        corpus = np.column_stack([corpus_mat, self.emojis_array])\n",
    "        corpus = np.column_stack([corpus, self.df[\"caps_share\"].values])\n",
    "        return corpus\n",
    "    \n",
    "    #predict the sentiment of each tweet, and add the column containing sentiment score of each tweet to the\n",
    "    #original dataframe\n",
    "    def predict_score(self):\n",
    "        try:\n",
    "            _predict = self.pipe.predict(self.corpus)\n",
    "            self.df[\"polarity_new\"] = _predict\n",
    "        except:\n",
    "            pass\n",
    "        return self.df\n",
    "    \n",
    "    \n",
    "    def save_output(self):\n",
    "        with open(self.filepath, \"wb\") as f:\n",
    "            pickle.dump(self.predicted, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceb66c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply the class above to every file, in every state in the \"Cleaned Data\" folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "37f9c885",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rahul\\miniconda3\\envs\\thesis\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3474: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "C:\\Users\\rahul\\miniconda3\\envs\\thesis\\lib\\site-packages\\numpy\\core\\_methods.py:181: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ret = um.true_divide(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Andhra_Pradesh completed\n",
      "time taken: 40.08 mins\n",
      "time taken: 40.08 mins\n"
     ]
    }
   ],
   "source": [
    "t = time()\n",
    "state_list = os.listdir(\"Cleaned Data\")\n",
    "for state in state_list:\n",
    "    t_1 = time()\n",
    "    path = os.path.join(\"Cleaned Data\", state)\n",
    "    file_list = [file for file in os.listdir(path) if \".csv\" in file]\n",
    "    ids = pickle.load(open(os.path.join(path, \"{} ids.pkl\".format(state.split()[-1])), \"rb\"))\n",
    "    for file in file_list:\n",
    "        sentiment_analyzer(path, file, ids, cls)\n",
    "    print(\"{} completed\".format(state.split()[-1]))\n",
    "    print(\"time taken: {} mins\".format(round((time() - t_1)/60, 2)))\n",
    "print(\"time taken: {} mins\".format(round((time() - t)/60, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fd8d34ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pickle.load(open(\"Cleaned Data\\\\cleaned Andhra_Pradesh\\\\cleaned 2020-01-22.csv.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "017b457b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1195, 16)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6ca1b94f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>conversation_id</th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>user_id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>retweets_count</th>\n",
       "      <th>replies_count</th>\n",
       "      <th>likes_count</th>\n",
       "      <th>retweet</th>\n",
       "      <th>caps_share</th>\n",
       "      <th>cleaned_tweet</th>\n",
       "      <th>target</th>\n",
       "      <th>hashtag</th>\n",
       "      <th>emojis</th>\n",
       "      <th>polarity_new</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.220133e+18</td>\n",
       "      <td>1.220133e+18</td>\n",
       "      <td>2020-01-23</td>\n",
       "      <td>00:57:35</td>\n",
       "      <td>6.341111e+07</td>\n",
       "      <td>Follow @tokslabossmua on YouTube: thanks so mu...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.086957</td>\n",
       "      <td>follow on youtube thanks so much dossier perfu...</td>\n",
       "      <td>tokslabossmua</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.220077e+18</td>\n",
       "      <td>1.220077e+18</td>\n",
       "      <td>2020-01-22</td>\n",
       "      <td>21:12:47</td>\n",
       "      <td>3.309983e+09</td>\n",
       "      <td>Enjoy</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>enjoy</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.220059e+18</td>\n",
       "      <td>1.220059e+18</td>\n",
       "      <td>2020-01-22</td>\n",
       "      <td>19:59:54</td>\n",
       "      <td>1.032304e+18</td>\n",
       "      <td>#JustAskSachin Sir what is u r stands on CAA  ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.212329</td>\n",
       "      <td>sir what is You stands on caa while ago You ha...</td>\n",
       "      <td></td>\n",
       "      <td>justasksachin</td>\n",
       "      <td></td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.220054e+18</td>\n",
       "      <td>1.220054e+18</td>\n",
       "      <td>2020-01-22</td>\n",
       "      <td>19:43:49</td>\n",
       "      <td>8.816434e+07</td>\n",
       "      <td>THINKING OF A SEA CHANGE ? HERE IS YOUR OPPORT...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.385714</td>\n",
       "      <td>thinking of sea change here is your opportunity</td>\n",
       "      <td></td>\n",
       "      <td>residentialplot land forsale beachroad visakha...</td>\n",
       "      <td></td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.220051e+18</td>\n",
       "      <td>1.220011e+18</td>\n",
       "      <td>2020-01-22</td>\n",
       "      <td>19:30:00</td>\n",
       "      <td>1.160402e+18</td>\n",
       "      <td>@turagasudhakar @BeSriSri @prasana_kumar @saib...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.054795</td>\n",
       "      <td>ok how deciding there in andhra three capital ...</td>\n",
       "      <td>turagasudhakar besrisri prasana_kumar saibolli...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             id  conversation_id        date      time       user_id  \\\n",
       "0  1.220133e+18     1.220133e+18  2020-01-23  00:57:35  6.341111e+07   \n",
       "1  1.220077e+18     1.220077e+18  2020-01-22  21:12:47  3.309983e+09   \n",
       "2  1.220059e+18     1.220059e+18  2020-01-22  19:59:54  1.032304e+18   \n",
       "3  1.220054e+18     1.220054e+18  2020-01-22  19:43:49  8.816434e+07   \n",
       "4  1.220051e+18     1.220011e+18  2020-01-22  19:30:00  1.160402e+18   \n",
       "\n",
       "                                               tweet  retweets_count  \\\n",
       "0  Follow @tokslabossmua on YouTube: thanks so mu...             0.0   \n",
       "1                                              Enjoy             0.0   \n",
       "2  #JustAskSachin Sir what is u r stands on CAA  ...             0.0   \n",
       "3  THINKING OF A SEA CHANGE ? HERE IS YOUR OPPORT...             0.0   \n",
       "4  @turagasudhakar @BeSriSri @prasana_kumar @saib...             0.0   \n",
       "\n",
       "   replies_count  likes_count retweet  caps_share  \\\n",
       "0            0.0          0.0   False    0.086957   \n",
       "1            0.0          0.0   False    0.166667   \n",
       "2            0.0          0.0   False    0.212329   \n",
       "3            0.0          0.0   False    0.385714   \n",
       "4            0.0          0.0   False    0.054795   \n",
       "\n",
       "                                       cleaned_tweet  \\\n",
       "0  follow on youtube thanks so much dossier perfu...   \n",
       "1                                              enjoy   \n",
       "2  sir what is You stands on caa while ago You ha...   \n",
       "3    thinking of sea change here is your opportunity   \n",
       "4  ok how deciding there in andhra three capital ...   \n",
       "\n",
       "                                              target  \\\n",
       "0                                      tokslabossmua   \n",
       "1                                                      \n",
       "2                                                      \n",
       "3                                                      \n",
       "4  turagasudhakar besrisri prasana_kumar saibolli...   \n",
       "\n",
       "                                             hashtag emojis  polarity_new  \n",
       "0                                                                     1.0  \n",
       "1                                                                     1.0  \n",
       "2                                      justasksachin                  1.0  \n",
       "3  residentialplot land forsale beachroad visakha...                  1.0  \n",
       "4                                                                     1.0  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:thesis]",
   "language": "python",
   "name": "conda-env-thesis-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
