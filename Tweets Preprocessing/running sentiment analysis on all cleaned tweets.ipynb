{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9a92aa71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import csv\n",
    "from time import time\n",
    "import logging\n",
    "logging.basicConfig(format=\"%(levelname)s - %(asctime)s: %(message)s\", datefmt= '%H:%M:%S', level=logging.INFO)\n",
    "from emot.emo_unicode import UNICODE_EMOJI, EMOTICONS_EMO\n",
    "from gensim.models import Word2Vec\n",
    "import multiprocessing\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0dd47b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading the trained classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9ed2a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "cls = pickle.load(open(\"classifier.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0025fd86",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading the word2vec model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eff3954",
   "metadata": {},
   "outputs": [],
   "source": [
    "wv_model = pickle.load(open(\"wv_model.pkl\", \"rb\"))\n",
    "wv = wv_model.wv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "51233714",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading the emoji vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df0193f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = pickle.load(open(\"emoji vectorizer.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0fd87692",
   "metadata": {},
   "outputs": [],
   "source": [
    "#predicting sentiment for all the scraped tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5e8c222e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a class that accepts the state_name, file_name, unique_ids of the state, and the classifier\n",
    "#it loads every file, creates the emoji matrix for the dataframe, uses word2vec model to vectorize all the \n",
    "#tweets in the df, then predicts and stores the sentiment of every tweet under the \"polarity_new\" column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8d37263a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class sentiment_analyzer:\n",
    "    \n",
    "    def __init__(self, _folder, _file, ids_list,_classifier):\n",
    "        self.folder = _folder\n",
    "        self.file = _file\n",
    "        self.filepath = os.path.join(os.path.abspath(self.folder), self.file)\n",
    "        self.pipe = _classifier\n",
    "        self.ids_list = ids_list\n",
    "        self.df = self.load_df()\n",
    "        self.emojis_array = self.emoji_vectorize()\n",
    "        self.corpus = self.vectorize_data()\n",
    "        self.predicted = self.predict_score()\n",
    "        self.output = self.save_output()\n",
    "        \n",
    "        \n",
    "    def load_df(self):\n",
    "        with open(self.filepath, \"rb\") as f:\n",
    "            _df = pickle.load(f)\n",
    "        _df = _df.where(_df[\"id\"].isin(self.ids_list)).dropna(subset = [\"id\"])\n",
    "        _df.reset_index(drop = True, inplace = True)\n",
    "        return _df\n",
    "    \n",
    "    \n",
    "    def emoji_vectorize(self):\n",
    "        _emojis = vectorizer.transform(self.df[\"emojis\"].values)\n",
    "        return _emojis.toarray()\n",
    "    \n",
    "        \n",
    "    def vectorize_data(self):\n",
    "        corpus_mat = np.empty((0, 300))\n",
    "        for _sentence in self.df[\"cleaned_tweet\"]:\n",
    "            sentence_mat = np.empty((300, 0))\n",
    "            for _word in _sentence.split():\n",
    "                if _word in wv.key_to_index.keys():\n",
    "                    sentence_mat = np.column_stack([sentence_mat, wv[_word]])\n",
    "                else:\n",
    "                    sentence_mat = np.column_stack([sentence_mat, np.zeros(300)])\n",
    "            sentence_vec = np.mean(sentence_mat, axis = 1)\n",
    "            corpus_mat = np.vstack([corpus_mat, sentence_vec])\n",
    "        corpus = np.column_stack([corpus_mat, self.emojis_array])\n",
    "        corpus = np.column_stack([corpus, self.df[\"caps_share\"].values])\n",
    "        return corpus\n",
    "    \n",
    "    \n",
    "    def predict_score(self):\n",
    "        try:\n",
    "            _predict = self.pipe.predict(self.corpus)\n",
    "            self.df[\"polarity_new\"] = _predict\n",
    "        except:\n",
    "            pass\n",
    "        return self.df\n",
    "    \n",
    "    \n",
    "    def save_output(self):\n",
    "        with open(self.filepath, \"wb\") as f:\n",
    "            pickle.dump(self.predicted, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37f9c885",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = time()\n",
    "state_list = os.listdir(\"Cleaned Data\")\n",
    "for state in state_list:\n",
    "    t_1 = time()\n",
    "    path = os.path.join(\"Cleaned Data\", state)\n",
    "    file_list = [file for file in os.listdir(path) if \".csv\" in file]\n",
    "    ids = pickle.load(open(os.path.join(path, \"{} ids.pkl\".format(state.split()[-1])), \"rb\"))\n",
    "    for file in file_list:\n",
    "        sentiment_analyzer(path, file, ids, cls)\n",
    "    print(\"{} completed\".format(state.split()[-1]))\n",
    "    print(\"time taken: {} mins\".format(round((time() - t_1)/60, 2)))\n",
    "print(\"time taken: {} mins\".format(round((time() - t)/60, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd8d34ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:thesis]",
   "language": "python",
   "name": "conda-env-thesis-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
